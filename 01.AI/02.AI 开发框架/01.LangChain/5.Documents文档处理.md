---
title: LangChainå®æˆ˜æ•™ç¨‹(ç¬¬äº”å‘¨):Documentsæ–‡æ¡£å¤„ç†
date: 2025-01-14
permalink: /ai/langchain/week5-documents.html
tags:
  - LangChain
categories:
  - LangChain
---

# ç¬¬5å‘¨ï¼šDocuments æ–‡æ¡£å¤„ç†

::: tip æœ¬å‘¨å­¦ä¹ ç›®æ ‡
- ğŸ“„ æŒæ¡æ–‡æ¡£åŠ è½½ï¼ˆDocumentLoaderï¼‰
- âœ‚ï¸ ç†è§£æ–‡æ¡£åˆ†å‰²ï¼ˆTextSplitterï¼‰ç­–ç•¥
- ğŸ” å­¦ä¹ æ–‡æ¡£æ£€ç´¢åŸºç¡€
- ğŸ¯ å¤„ç†å¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆPDFã€Wordã€Markdownï¼‰
- ğŸ’¡ æ„å»ºæ–‡æ¡£é—®ç­”ç³»ç»Ÿ
:::

## ä¸€ã€æ–‡æ¡£å¤„ç†åŸºç¡€

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦æ–‡æ¡£å¤„ç†ï¼Ÿ

åœ¨æ„å»º RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿæ—¶ï¼Œæ–‡æ¡£å¤„ç†æ˜¯å…³é”®æ­¥éª¤ï¼š

```mermaid
graph LR
    A[åŸå§‹æ–‡æ¡£] --> B[åŠ è½½<br/>DocumentLoader]
    B --> C[åˆ†å‰²<br/>TextSplitter]
    C --> D[å‘é‡åŒ–<br/>Embeddings]
    D --> E[å­˜å‚¨<br/>Vector Store]
    E --> F[æ£€ç´¢+ç”Ÿæˆ<br/>RAG]

    style A fill:#FFE0B2
    style F fill:#C8E6C9
```

**æ ¸å¿ƒé—®é¢˜ï¼š**
1. **ä¸Šä¸‹æ–‡çª—å£é™åˆ¶**ï¼šLLM æ— æ³•å¤„ç†è¶…é•¿æ–‡æ¡£
2. **æ£€ç´¢æ•ˆç‡**ï¼šéœ€è¦å¿«é€Ÿæ‰¾åˆ°ç›¸å…³å†…å®¹
3. **æ ¼å¼å¤šæ ·æ€§**ï¼šPDFã€Wordã€HTML ç­‰æ ¼å¼ä¸åŒ

### 1.2 Document å¯¹è±¡

LangChain çš„ **Document** æ˜¯æ–‡æ¡£çš„æ ‡å‡†è¡¨ç¤ºï¼š

```python
"""
Document å¯¹è±¡ç»“æ„
"""
from langchain.schema import Document

# åˆ›å»º Document
doc = Document(
    page_content="è¿™æ˜¯æ–‡æ¡£çš„å®é™…å†…å®¹",  # å¿…éœ€ï¼šæ–‡æœ¬å†…å®¹
    metadata={                          # å¯é€‰ï¼šå…ƒæ•°æ®
        "source": "example.pdf",
        "page": 1,
        "author": "å¼ ä¸‰"
    }
)

print(f"å†…å®¹ï¼š{doc.page_content}")
print(f"å…ƒæ•°æ®ï¼š{doc.metadata}")
```


## ä¸‰ã€æ–‡æ¡£åˆ†å‰²ï¼ˆTextSplitterï¼‰

### 3.1 ä¸ºä»€ä¹ˆè¦åˆ†å‰²æ–‡æ¡£ï¼Ÿ

**é—®é¢˜ï¼š**
- LLM ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼ˆGPT-3.5: 4K, GPT-4: 8K/32Kï¼‰
- é•¿æ–‡æ¡£æ— æ³•ä¸€æ¬¡å¤„ç†
- æ£€ç´¢éœ€è¦ç²¾ç¡®åŒ¹é…ç›¸å…³ç‰‡æ®µ

**è§£å†³æ–¹æ¡ˆï¼š**
å°†é•¿æ–‡æ¡£åˆ†å‰²æˆæ›´å°çš„å—ï¼ˆchunksï¼‰

```mermaid
graph LR
    A[é•¿æ–‡æ¡£<br/>10000 å­—] --> B[åˆ†å‰²å™¨]
    B --> C[Chunk 1<br/>500 å­—]
    B --> D[Chunk 2<br/>500 å­—]
    B --> E[Chunk 3<br/>500 å­—]
    B --> F[...]

    style A fill:#FFE0B2
    style C fill:#C8E6C9
    style D fill:#C8E6C9
    style E fill:#C8E6C9
    style F fill:#C8E6C9
```

### 3.2 CharacterTextSplitter

æœ€åŸºç¡€çš„åˆ†å‰²å™¨ï¼ŒæŒ‰å­—ç¬¦æ•°åˆ†å‰²ï¼š

```python
"""
CharacterTextSplitter ç¤ºä¾‹
"""
from langchain.text_splitter import CharacterTextSplitter

text = """LangChain æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚
å®ƒæä¾›äº†æ ‡å‡†åŒ–çš„æ¥å£å’Œå·¥å…·é“¾ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾æ„å»ºå¤æ‚çš„ AI åº”ç”¨ã€‚

LangChain çš„æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ï¼š
1. Modelsï¼šä¸ LLM äº¤äº’çš„æ¥å£
2. Promptsï¼šç®¡ç†å’Œä¼˜åŒ–è¾“å…¥æ–‡æœ¬
3. Memoryï¼šå­˜å‚¨å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡
4. Chainsï¼šç»„åˆå¤šä¸ªç»„ä»¶çš„æµç¨‹
5. Agentsï¼šæ ¹æ®è¾“å…¥åŠ¨æ€å†³å®šè¡ŒåŠ¨çš„æ™ºèƒ½ä½“
"""

# åˆ›å»ºåˆ†å‰²å™¨
splitter = CharacterTextSplitter(
    separator="\n\n",         # åˆ†å‰²ç¬¦ï¼ˆä¼˜å…ˆæŒ‰æ­¤åˆ†å‰²ï¼‰
    chunk_size=100,           # æ¯å—æœ€å¤§å­—ç¬¦æ•°
    chunk_overlap=20,         # å—ä¹‹é—´é‡å å­—ç¬¦æ•°
    length_function=len       # è®¡ç®—é•¿åº¦çš„å‡½æ•°
)

chunks = splitter.split_text(text)

print(f"åˆ†å‰²æˆ {len(chunks)} å—ï¼š")
for i, chunk in enumerate(chunks, 1):
    print(f"\nå— {i} ({len(chunk)} å­—ç¬¦):")
    print(chunk)
    print("-" * 60)
```

**å…³é”®å‚æ•°ï¼š**
- `chunk_size`ï¼šæ¯å—çš„ç›®æ ‡å¤§å°
- `chunk_overlap`ï¼šé‡å éƒ¨åˆ†ï¼Œé¿å…åˆ‡æ–­è¯­ä¹‰

```python
# å¯è§†åŒ–é‡å 
"""
åŸæ–‡ï¼šABCDEFGHIJ
chunk_size=5, chunk_overlap=2

å—1: ABCDE
å—2:    DEFGH  ï¼ˆä¸å—1é‡å  DEï¼‰
å—3:       GHIJ  ï¼ˆä¸å—2é‡å  GHï¼‰
"""
```

### 3.3 RecursiveCharacterTextSplitterï¼ˆæ¨èï¼‰

é€’å½’åœ°æŒ‰å¤šä¸ªåˆ†éš”ç¬¦å°è¯•åˆ†å‰²ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§ï¼š

```python
"""
RecursiveCharacterTextSplitter ç¤ºä¾‹
æ¨èä½¿ç”¨ï¼Œæ™ºèƒ½ä¿æŒæ®µè½å’Œå¥å­å®Œæ•´
"""
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = """# LangChain å…¥é—¨æŒ‡å—

## ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ

LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ã€‚å®ƒå¸®åŠ©å¼€å‘è€…æ„å»º AI åº”ç”¨ã€‚

## æ ¸å¿ƒæ¦‚å¿µ

LangChain åŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š
- Models
- Prompts
- Memory

æ¯ä¸ªç»„ä»¶éƒ½æœ‰ç‰¹å®šä½œç”¨ã€‚"""

splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=20,
    separators=["\n\n", "\n", "ã€‚", " ", ""]  # åˆ†å‰²ä¼˜å…ˆçº§
)

chunks = splitter.split_text(text)

for i, chunk in enumerate(chunks, 1):
    print(f"å— {i}:\n{chunk}\n{'='*60}")
```

**åˆ†å‰²ç­–ç•¥ï¼š**
1. å…ˆå°è¯•æŒ‰ `\n\n`ï¼ˆæ®µè½ï¼‰åˆ†å‰²
2. å¦‚æœå—ä»ç„¶å¤ªå¤§ï¼ŒæŒ‰ `\n`ï¼ˆè¡Œï¼‰åˆ†å‰²
3. å†å¤§å°±æŒ‰ `ã€‚`ï¼ˆå¥å­ï¼‰åˆ†å‰²
4. æœ€åæŒ‰ç©ºæ ¼æˆ–å­—ç¬¦åˆ†å‰²

### 3.4 TokenTextSplitter

æŒ‰ Token æ•°é‡åˆ†å‰²ï¼ˆæ›´ç²¾ç¡®ï¼‰ï¼š

```python
"""
TokenTextSplitter ç¤ºä¾‹
é€‚ç”¨äºéœ€è¦ç²¾ç¡®æ§åˆ¶ Token æ•°çš„åœºæ™¯
"""
from langchain.text_splitter import TokenTextSplitter

text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬..." * 100

splitter = TokenTextSplitter(
    chunk_size=100,      # æœ€å¤§ 100 tokens
    chunk_overlap=10     # é‡å  10 tokens
)

chunks = splitter.split_text(text)
print(f"åˆ†å‰²æˆ {len(chunks)} å—")

# éªŒè¯ token æ•°
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")

for i, chunk in enumerate(chunks[:3], 1):
    token_count = len(encoding.encode(chunk))
    print(f"å— {i}: {token_count} tokens")
```

### 3.5 Markdown å’Œä»£ç åˆ†å‰²å™¨

```python
"""
MarkdownTextSplitterï¼šä¿æŒ Markdown ç»“æ„
"""
from langchain.text_splitter import MarkdownTextSplitter

markdown_text = """# æ ‡é¢˜1

## å°æ ‡é¢˜1.1
å†…å®¹1

## å°æ ‡é¢˜1.2
å†…å®¹2

# æ ‡é¢˜2
å†…å®¹3"""

splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=0)
chunks = splitter.split_text(markdown_text)

for chunk in chunks:
    print(f"å—:\n{chunk}\n{'='*60}")
```

```python
"""
ä»£ç åˆ†å‰²å™¨ï¼šæŒ‰è¯­è¨€æ™ºèƒ½åˆ†å‰²
"""
from langchain.text_splitter import (
    Language,
    RecursiveCharacterTextSplitter
)

# Python ä»£ç åˆ†å‰²
python_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON,
    chunk_size=50,
    chunk_overlap=0
)

code = """
def hello():
    print("Hello")

def world():
    print("World")

class MyClass:
    def __init__(self):
        self.value = 0
"""

chunks = python_splitter.split_text(code)
for i, chunk in enumerate(chunks, 1):
    print(f"ä»£ç å— {i}:\n{chunk}\n{'='*60}")
```

### 3.6 åˆ†å‰²ç­–ç•¥å¯¹æ¯”

| åˆ†å‰²å™¨ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|--------|------|------|---------|
| **CharacterTextSplitter** | ç®€å•ç›´æ¥ | å¯èƒ½åˆ‡æ–­è¯­ä¹‰ | ç®€å•æ–‡æœ¬ |
| **RecursiveCharacterTextSplitter** | ä¿æŒè¯­ä¹‰å®Œæ•´ | ç¨æ…¢ | å¤§å¤šæ•°åœºæ™¯ï¼ˆæ¨èï¼‰ |
| **TokenTextSplitter** | ç²¾ç¡®æ§åˆ¶ Token | éœ€è¦ç¼–ç å™¨ | ä¸¥æ ¼ Token é™åˆ¶ |
| **MarkdownTextSplitter** | ä¿æŒç»“æ„ | ä»…é™ Markdown | Markdown æ–‡æ¡£ |
| **Language-specific** | ä»£ç è¯­ä¹‰å®Œæ•´ | ä»…é™ä»£ç  | ä»£ç æ–‡æ¡£ |


## äº”ã€æœ¬å‘¨ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šå¤šæ ¼å¼æ–‡æ¡£åŠ è½½å™¨ï¼ˆéš¾åº¦ï¼šâ­â­ï¼‰

**ä»»åŠ¡**ï¼šåˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„æ–‡æ¡£åŠ è½½å™¨ï¼Œè‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹ï¼ˆtxtã€pdfã€docxï¼‰å¹¶åŠ è½½ã€‚

<details>
<summary>æŸ¥çœ‹æç¤º</summary>

æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ä¸åŒçš„ Loaderã€‚
</details>

### ç»ƒä¹ 2ï¼šæ™ºèƒ½åˆ†å‰²å‚æ•°é€‰æ‹©ï¼ˆéš¾åº¦ï¼šâ­â­ï¼‰

**ä»»åŠ¡**ï¼šæ ¹æ®æ–‡æ¡£é•¿åº¦å’Œç±»å‹ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„ `chunk_size` å’Œ `chunk_overlap`ã€‚

<details>
<summary>æŸ¥çœ‹æç¤º</summary>

- çŸ­æ–‡æ¡£ï¼ˆ<1000å­—ï¼‰ï¼šchunk_size=200
- ä¸­ç­‰æ–‡æ¡£ï¼ˆ1000-5000å­—ï¼‰ï¼šchunk_size=500
- é•¿æ–‡æ¡£ï¼ˆ>5000å­—ï¼‰ï¼šchunk_size=1000
</details>

### ç»ƒä¹ 3ï¼šæ–‡æ¡£å¯¹æ¯”ç³»ç»Ÿï¼ˆéš¾åº¦ï¼šâ­â­â­ï¼‰

**ä»»åŠ¡**ï¼šæ„å»ºä¸€ä¸ªç³»ç»Ÿï¼Œæ¯”è¾ƒä¸¤ä¸ªæ–‡æ¡£çš„å¼‚åŒã€‚

**è¦æ±‚**ï¼š
1. åŠ è½½ä¸¤ä¸ªæ–‡æ¡£
2. æå–å…³é”®ä¿¡æ¯
3. å¯¹æ¯”å·®å¼‚
4. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š


::: tip å­¦ä¹ å»ºè®®
1. **å¤šå®éªŒåˆ†å‰²å‚æ•°**ï¼šä¸åŒæ–‡æ¡£ç±»å‹éœ€è¦ä¸åŒå‚æ•°
2. **å…³æ³¨è¯­ä¹‰å®Œæ•´æ€§**ï¼šä¼˜å…ˆä½¿ç”¨ RecursiveCharacterTextSplitter
3. **æµ‹è¯•çœŸå®æ–‡æ¡£**ï¼šç”¨å®é™…é¡¹ç›®ä¸­çš„æ–‡æ¡£æµ‹è¯•
4. **ç›‘æ§ Token ä½¿ç”¨**ï¼šåˆ†å‰²åæ³¨æ„ Token æ•°é‡
:::

**æœ¬å‘¨å®Œæˆï¼å‡†å¤‡è¿›å…¥è®°å¿†ç³»ç»Ÿï¼ğŸš€**
