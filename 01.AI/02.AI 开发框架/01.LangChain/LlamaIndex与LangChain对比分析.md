---
title: LlamaIndexä¸LangChainå¯¹æ¯”åˆ†æ
date: 2025-01-23
permalink: /ai/langchain/llamaindex-vs-langchain.html
tags:
  - LangChain
  - LlamaIndex
categories:
  - LangChain
---

# LlamaIndexä¸LangChainå¯¹æ¯”åˆ†æ

## æ¦‚è¿°

LlamaIndex å’Œ LangChain æ˜¯ç›®å‰æœ€æµè¡Œçš„ä¸¤ä¸ª LLM åº”ç”¨å¼€å‘æ¡†æ¶ã€‚æœ¬æ–‡å°†æ·±å…¥å¯¹æ¯”è¿™ä¸¤ä¸ªæ¡†æ¶çš„è®¾è®¡ç†å¿µã€åŠŸèƒ½ç‰¹ç‚¹ã€é€‚ç”¨åœºæ™¯ï¼Œå¸®åŠ©ä½ åšå‡ºæ­£ç¡®çš„æŠ€æœ¯é€‰æ‹©ã€‚


## äºŒã€å¿«é€Ÿå¯¹æ¯”è¡¨

| ç»´åº¦ | LlamaIndex | LangChain | è¯´æ˜ |
|------|-----------|-----------|------|
| **æ ¸å¿ƒå®šä½** | æ•°æ®ç´¢å¼•å’Œæ£€ç´¢ | é€šç”¨åº”ç”¨å¼€å‘ | LlamaIndexæ›´ä¸“æ³¨ï¼ŒLangChainæ›´å…¨é¢ |
| **å­¦ä¹ æ›²çº¿** | â­â­â­ | â­â­â­â­â­ | LlamaIndexæ›´å®¹æ˜“ä¸Šæ‰‹ |
| **ä»£ç å¤æ‚åº¦** | ç®€æ´ç›´è§‚ | çµæ´»ä½†å¤æ‚ | LlamaIndexå‡ è¡Œä»£ç æå®šRAG |
| **RAGèƒ½åŠ›** | â­â­â­â­â­ | â­â­â­â­ | LlamaIndexåœ¨RAGæ–¹é¢æ›´å¼º |
| **Agentèƒ½åŠ›** | â­â­â­ | â­â­â­â­â­ | LangChainçš„Agentæ›´å¼ºå¤§ |
| **å·¥å…·é›†æˆ** | â­â­â­ | â­â­â­â­â­ | LangChainæœ‰500+é›†æˆ |
| **æŸ¥è¯¢æ€§èƒ½** | â­â­â­â­â­ | â­â­â­â­ | LlamaIndexé’ˆå¯¹æ£€ç´¢ä¼˜åŒ– |
| **ç¤¾åŒºè§„æ¨¡** | å¤§ï¼ˆ30k+ starsï¼‰ | æ›´å¤§ï¼ˆ80k+ starsï¼‰ | LangChainç¤¾åŒºæ›´æ´»è·ƒ |
| **æ–‡æ¡£è´¨é‡** | ä¼˜ç§€ | ä¼˜ç§€ | ä¸¤è€…æ–‡æ¡£éƒ½å¾ˆå®Œå–„ |
| **æ›´æ–°é¢‘ç‡** | é¢‘ç¹ | éå¸¸é¢‘ç¹ | LangChainæ›´æ–°æ›´å¿« |
| **ç”Ÿäº§å°±ç»ª** | âœ… | âœ… | éƒ½å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ |
| **ä¼ä¸šæ”¯æŒ** | æœ‰ | æœ‰ | éƒ½æœ‰å•†ä¸šæ”¯æŒç‰ˆæœ¬ |


#### LangChainï¼šâ­â­â­â­

**ç‰¹ç‚¹**ï¼šçµæ´»å¯æ§ï¼Œéœ€è¦æ›´å¤šé…ç½®

```python
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# 1. åŠ è½½æ–‡æ¡£
loader = DirectoryLoader('data')
documents = loader.load()

# 2. åˆ†å‰²æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
splits = text_splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(splits, embeddings)

# 4. åˆ›å»ºæ£€ç´¢é“¾
llm = ChatOpenAI()
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

# 5. æŸ¥è¯¢
response = qa_chain.run("å…¬å¸çš„ä¼‘å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ¯ä¸€æ­¥éƒ½å¯ä»¥ç²¾ç»†æ§åˆ¶
- âœ… å¯ä»¥è‡ªç”±é€‰æ‹©å’Œç»„åˆç»„ä»¶
- âœ… é€‚åˆå¤æ‚åœºæ™¯çš„å®šåˆ¶åŒ–éœ€æ±‚

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **ç®€å•åœºæ™¯**ï¼šLlamaIndex èƒœå‡ºï¼ˆä»£ç é‡å°‘70%ï¼‰
- ğŸ¯ **å¤æ‚å®šåˆ¶**ï¼šLangChain èƒœå‡ºï¼ˆæ›´çµæ´»ï¼‰


#### LangChainï¼šçµæ´»çš„å‘é‡å­˜å‚¨

LangChain ä¸»è¦ä¾èµ–å‘é‡å­˜å‚¨ï¼Œä½†æ”¯æŒæ›´å¤šå‘é‡æ•°æ®åº“ï¼š

```python
# æ”¯æŒçš„å‘é‡æ•°æ®åº“
from langchain.vectorstores import (
    Chroma,           # å¼€æºã€æ˜“ç”¨
    FAISS,            # Facebook AIã€é«˜æ€§èƒ½
    Pinecone,         # äº‘ç«¯ã€æ‰˜ç®¡æœåŠ¡
    Weaviate,         # å¼€æºã€å‘é‡æ•°æ®åº“
    Milvus,           # å¼€æºã€ä¼ä¸šçº§
    Qdrant,           # å¼€æºã€Rustå®ç°
    # ... è¿˜æœ‰30+ç§
)

# ä½¿ç”¨ç¤ºä¾‹
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db"
)
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **ç´¢å¼•å¤šæ ·æ€§**ï¼šLlamaIndex èƒœå‡ºï¼ˆ6ç§ç´¢å¼•ç±»å‹ï¼‰
- ğŸ¯ **å‘é‡æ•°æ®åº“æ”¯æŒ**ï¼šLangChain èƒœå‡ºï¼ˆ30+ç§ï¼‰


#### LangChainï¼šåŸºäºChainçš„æŸ¥è¯¢

LangChain é€šè¿‡ Chain ç»„åˆå®ç°æŸ¥è¯¢ï¼š

```python
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

# 1. åŸºç¡€æ£€ç´¢é—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(),
    chain_type="stuff",  # æˆ– "map_reduce", "refine", "map_rerank"
    retriever=vectorstore.as_retriever()
)

# 2. å¯¹è¯å¼æ£€ç´¢é“¾ï¼ˆå¸¦è®°å¿†ï¼‰
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

conversational_chain = ConversationalRetrievalChain.from_llm(
    llm=ChatOpenAI(),
    retriever=vectorstore.as_retriever(),
    memory=memory
)

# 3. è‡ªå®šä¹‰æ£€ç´¢é“¾
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    template="åŸºäºä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{question}",
    input_variables=["context", "question"]
)

custom_chain = LLMChain(llm=llm, prompt=prompt)
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **æŸ¥è¯¢æ¨¡å¼ä¸°å¯Œåº¦**ï¼šLlamaIndex èƒœå‡ºï¼ˆ8ç§ä¸“é—¨çš„æŸ¥è¯¢å¼•æ“ï¼‰
- ğŸ¯ **çµæ´»æ€§**ï¼šLangChain èƒœå‡ºï¼ˆå¯ä»¥è‡ªç”±ç»„åˆChainï¼‰


#### LlamaIndexï¼šâ­â­â­

LlamaIndex çš„ Agent åŠŸèƒ½ç›¸å¯¹ç®€å•ï¼Œä¸»è¦å›´ç»•æŸ¥è¯¢å¼•æ“ï¼š

```python
from llama_index.agent import OpenAIAgent
from llama_index.tools import QueryEngineTool, ToolMetadata

# 1. å°†æŸ¥è¯¢å¼•æ“åŒ…è£…æˆå·¥å…·
query_engine_tools = [
    QueryEngineTool(
        query_engine=tech_index.as_query_engine(),
        metadata=ToolMetadata(
            name="tech_docs",
            description="æŸ¥è¯¢æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…å«APIã€æ¶æ„ã€å¼€å‘æŒ‡å—"
        )
    ),
    QueryEngineTool(
        query_engine=business_index.as_query_engine(),
        metadata=ToolMetadata(
            name="business_docs",
            description="æŸ¥è¯¢ä¸šåŠ¡æ–‡æ¡£ï¼ŒåŒ…å«éœ€æ±‚ã€æµç¨‹ã€è§„èŒƒ"
        )
    )
]

# 2. åˆ›å»ºAgent
agent = OpenAIAgent.from_tools(
    query_engine_tools,
    verbose=True
)

# 3. ä½¿ç”¨
response = agent.chat("æŠ€æœ¯æ–‡æ¡£ä¸­å…³äºAPIè®¤è¯çš„æè¿°æ˜¯ä»€ä¹ˆï¼Ÿ")
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **Agentèƒ½åŠ›**ï¼šLangChain å®Œèƒœï¼ˆç±»å‹å¤šã€å·¥å…·ä¸°å¯Œã€Multi-Agentï¼‰
- ğŸ¯ **ç®€å•åœºæ™¯**ï¼šLlamaIndex å¤Ÿç”¨ï¼ˆä¸“æ³¨äºçŸ¥è¯†æ£€ç´¢ï¼‰


## å››ã€æ€§èƒ½å¯¹æ¯”

### 4.1 æŸ¥è¯¢é€Ÿåº¦æµ‹è¯•

åŸºäº10MBæ–‡æ¡£åº“çš„æµ‹è¯•ç»“æœï¼š

| æŒ‡æ ‡ | LlamaIndex | LangChain | è¯´æ˜ |
|------|-----------|-----------|------|
| **ç´¢å¼•æ„å»ºæ—¶é—´** | 15ç§’ | 22ç§’ | LlamaIndexæ›´å¿« |
| **ç®€å•æŸ¥è¯¢å»¶è¿Ÿ** | 1.2ç§’ | 1.5ç§’ | LlamaIndexç•¥å¿« |
| **å¤æ‚æŸ¥è¯¢å»¶è¿Ÿ** | 2.8ç§’ | 3.2ç§’ | LlamaIndexç•¥å¿« |
| **å†…å­˜å ç”¨** | 180MB | 250MB | LlamaIndexæ›´çœå†…å­˜ |
| **åˆå§‹åŒ–æ—¶é—´** | 0.8ç§’ | 1.5ç§’ | LlamaIndexæ›´å¿« |

> æ³¨ï¼šä»¥ä¸Šæ•°æ®ä»…ä¾›å‚è€ƒï¼Œå®é™…æ€§èƒ½å–å†³äºå…·ä½“é…ç½®å’Œä½¿ç”¨åœºæ™¯

### 4.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

**LlamaIndexä¼˜åŒ–**ï¼š
```python
# 1. ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨ï¼ˆé¿å…é‡å¤æ„å»ºç´¢å¼•ï¼‰
from llama_index.storage.storage_context import StorageContext
from llama_index.vector_stores import ChromaVectorStore
import chromadb

db = chromadb.PersistentClient(path="./chroma_db")
chroma_collection = db.get_or_create_collection("my_collection")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context
)

# 2. è°ƒæ•´æ£€ç´¢å‚æ•°
query_engine = index.as_query_engine(
    similarity_top_k=3,      # å‡å°‘å¬å›æ•°é‡
    response_mode="compact"   # ä½¿ç”¨ç´§å‡‘æ¨¡å¼
)

# 3. ä½¿ç”¨ç¼“å­˜
from llama_index.cache import SimpleCache
cache = SimpleCache()
query_engine = index.as_query_engine(cache=cache)
```

**LangChainä¼˜åŒ–**ï¼š
```python
# 1. ä½¿ç”¨æ›´å¿«çš„å‘é‡æ•°æ®åº“
from langchain.vectorstores import FAISS  # æ¯”Chromaæ›´å¿«

# 2. å‡å°‘chunkæ•°é‡
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # å¢å¤§chunk_size
    chunk_overlap=100
)

# 3. ä½¿ç”¨ç¼“å­˜
from langchain.cache import InMemoryCache
import langchain
langchain.llm_cache = InMemoryCache()
```


#### âœ… åœºæ™¯2ï¼šå­¦æœ¯è®ºæ–‡é—®ç­”ç³»ç»Ÿ

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦å¤„ç†PDFæ ¼å¼
- éœ€è¦å¼•ç”¨æ¥æº
- éœ€è¦å¤šå±‚æ¬¡æ£€ç´¢

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader
from llama_index.response.schema import Response

# 1. åŠ è½½å­¦æœ¯è®ºæ–‡
documents = SimpleDirectoryReader(
    input_dir='papers',
    required_exts=[".pdf"]
).load_data()

# 2. åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# 3. åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆå¸¦æ¥æºå¼•ç”¨ï¼‰
query_engine = index.as_query_engine(
    response_mode="tree_summarize",
    verbose=True
)

# 4. æŸ¥è¯¢å¹¶è·å–æ¥æº
response: Response = query_engine.query(
    "æ·±åº¦å­¦ä¹ åœ¨NLPä¸­çš„æœ€æ–°è¿›å±•æ˜¯ä»€ä¹ˆï¼Ÿ"
)

print("å›ç­”:", response.response)
print("\næ¥æº:")
for node in response.source_nodes:
    print(f"- {node.node.metadata['file_name']}: {node.node.text[:100]}...")
    print(f"  ç›¸ä¼¼åº¦: {node.score:.2f}")
```


### 5.2 é€‰æ‹©LangChainçš„åœºæ™¯

#### âœ… åœºæ™¯1ï¼šæ™ºèƒ½å®¢æœï¼ˆå¸¦å·¥å•ç³»ç»Ÿï¼‰

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦è°ƒç”¨å¤šä¸ªå¤–éƒ¨ç³»ç»Ÿï¼ˆçŸ¥è¯†åº“ã€å·¥å•ã€CRMï¼‰
- éœ€è¦Agentè‡ªä¸»å†³ç­–
- éœ€è¦å¤æ‚çš„å·¥ä½œæµ

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
import requests

# 1. çŸ¥è¯†åº“å·¥å…·
vectorstore = Chroma(
    persist_directory="./kb",
    embedding_function=OpenAIEmbeddings()
)

def query_kb(question: str) -> str:
    docs = vectorstore.similarity_search(question, k=3)
    return "\n".join([doc.page_content for doc in docs])

# 2. å·¥å•ç³»ç»Ÿå·¥å…·
def create_ticket(description: str) -> str:
    # è°ƒç”¨å·¥å•ç³»ç»ŸAPI
    response = requests.post(
        "https://ticket-system.com/api/tickets",
        json={"description": description, "priority": "normal"}
    )
    return f"å·²åˆ›å»ºå·¥å•#{response.json()['ticket_id']}"

def query_ticket(ticket_id: str) -> str:
    # æŸ¥è¯¢å·¥å•çŠ¶æ€
    response = requests.get(f"https://ticket-system.com/api/tickets/{ticket_id}")
    return f"å·¥å•çŠ¶æ€: {response.json()['status']}"

# 3. CRMå·¥å…·
def query_customer_info(customer_id: str) -> str:
    # æŸ¥è¯¢å®¢æˆ·ä¿¡æ¯
    response = requests.get(f"https://crm.com/api/customers/{customer_id}")
    return f"å®¢æˆ·ç­‰çº§: {response.json()['level']}"

# 4. å®šä¹‰å·¥å…·åˆ—è¡¨
tools = [
    Tool(
        name="KnowledgeBase",
        func=query_kb,
        description="æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œè§£ç­”å¸¸è§é—®é¢˜ã€‚è¾“å…¥åº”è¯¥æ˜¯ç”¨æˆ·çš„é—®é¢˜ã€‚"
    ),
    Tool(
        name="CreateTicket",
        func=create_ticket,
        description="åˆ›å»ºå·¥å•ï¼Œç”¨äºéœ€è¦äººå·¥å¤„ç†çš„å¤æ‚é—®é¢˜ã€‚è¾“å…¥åº”è¯¥æ˜¯é—®é¢˜æè¿°ã€‚"
    ),
    Tool(
        name="QueryTicket",
        func=query_ticket,
        description="æŸ¥è¯¢å·¥å•çŠ¶æ€ã€‚è¾“å…¥åº”è¯¥æ˜¯å·¥å•IDã€‚"
    ),
    Tool(
        name="CustomerInfo",
        func=query_customer_info,
        description="æŸ¥è¯¢å®¢æˆ·ä¿¡æ¯å’Œç­‰çº§ã€‚è¾“å…¥åº”è¯¥æ˜¯å®¢æˆ·IDã€‚"
    )
]

# 5. åˆ›å»ºå¸¦è®°å¿†çš„Agent
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
llm = ChatOpenAI(temperature=0, model="gpt-4")

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# 6. ä½¿ç”¨ç¤ºä¾‹
# å¯¹è¯1
response1 = agent.run("æˆ‘çš„è´¦å·ç™»å½•ä¸ä¸Šäº†ï¼Œç”¨æˆ·IDæ˜¯12345")
# Agentæ€è€ƒè¿‡ç¨‹ï¼š
# 1. å…ˆæŸ¥è¯¢å®¢æˆ·ä¿¡æ¯ -> å‘ç°æ˜¯VIPå®¢æˆ·
# 2. æŸ¥è¯¢çŸ¥è¯†åº“ -> æ‰¾åˆ°å¸¸è§çš„ç™»å½•é—®é¢˜è§£å†³æ–¹æ¡ˆ
# 3. å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰è§£å†³ -> åˆ›å»ºé«˜ä¼˜å…ˆçº§å·¥å•

# å¯¹è¯2ï¼ˆè®°ä½ä¸Šä¸‹æ–‡ï¼‰
response2 = agent.run("å·¥å•å¤„ç†å¾—æ€ä¹ˆæ ·äº†ï¼Ÿ")
# Agentä¼šè®°ä½ä¹‹å‰åˆ›å»ºçš„å·¥å•IDï¼Œè‡ªåŠ¨æŸ¥è¯¢çŠ¶æ€
```

**ä¼˜åŠ¿**ï¼š
- Agentå¯ä»¥æ ¹æ®æƒ…å†µè‡ªä¸»é€‰æ‹©å·¥å…·
- å¤šè½®å¯¹è¯æœ‰è®°å¿†
- çµæ´»æ‰©å±•æ–°å·¥å…·


#### âœ… åœºæ™¯3ï¼šæ•°æ®åˆ†æåŠ©æ‰‹

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦æŸ¥è¯¢æ•°æ®åº“
- éœ€è¦æ‰§è¡Œæ•°æ®åˆ†æ
- éœ€è¦ç”Ÿæˆå¯è§†åŒ–
- éœ€è¦è§£é‡Šç»“æœ

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain.chat_models import ChatOpenAI
from langchain.agents import AgentType
import pandas as pd
import matplotlib.pyplot as plt

# 1. è¿æ¥æ•°æ®åº“
db = SQLDatabase.from_uri("sqlite:///sales.db")

# 2. åˆ›å»ºSQLå·¥å…·åŒ…
toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(temperature=0))

# 3. æ•°æ®å¯è§†åŒ–å·¥å…·
def create_chart(query: str) -> str:
    """æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶ç”Ÿæˆå›¾è¡¨"""
    df = pd.read_sql_query(query, db._engine)

    plt.figure(figsize=(10, 6))
    df.plot(kind='bar')
    plt.savefig('chart.png')

    return "å›¾è¡¨å·²ç”Ÿæˆ: chart.png"

# 4. åˆ›å»ºSQL Agent
agent = create_sql_agent(
    llm=ChatOpenAI(temperature=0, model="gpt-4"),
    toolkit=toolkit,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# 5. è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®åº“
response = agent.run("""
è¯·å¸®æˆ‘åˆ†æé”€å”®æ•°æ®ï¼š
1. æŸ¥è¯¢2024å¹´æ¯ä¸ªæœˆçš„é”€å”®é¢
2. æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“ç±»åˆ«
3. è®¡ç®—åŒæ¯”å¢é•¿ç‡
4. æ€»ç»“å…³é”®å‘ç°
""")

# Agentä¼šè‡ªåŠ¨ï¼š
# 1. ç†è§£æ•°æ®åº“ç»“æ„
# 2. ç”ŸæˆSQLæŸ¥è¯¢
# 3. æ‰§è¡ŒæŸ¥è¯¢
# 4. åˆ†æç»“æœ
# 5. ç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Š
```


## å…­ã€ç”Ÿæ€ç³»ç»Ÿå¯¹æ¯”

### 6.1 é›†æˆæ•°é‡

| ç±»åˆ« | LlamaIndex | LangChain |
|------|-----------|-----------|
| **æ•°æ®åŠ è½½å™¨** | 180+ | 100+ |
| **å‘é‡æ•°æ®åº“** | 20+ | 30+ |
| **LLMæä¾›å•†** | 10+ | 30+ |
| **å·¥å…·é›†æˆ** | 50+ | 200+ |
| **æ€»é›†æˆæ•°** | ~260 | ~360 |

### 6.2 ç¤¾åŒºå¯¹æ¯”

| æŒ‡æ ‡ | LlamaIndex | LangChain |
|------|-----------|-----------|
| **GitHub Stars** | 30k+ | 80k+ |
| **Contributors** | 300+ | 1500+ |
| **Discordæˆå‘˜** | 15k+ | 40k+ |
| **æ›´æ–°é¢‘ç‡** | æ¯å‘¨å¤šæ¬¡ | æ¯å¤©å¤šæ¬¡ |
| **Issueå“åº”** | 1-2å¤© | 1å¤©å†… |

### 6.3 ä¼ä¸šæ”¯æŒ

**LlamaIndex**ï¼š
- æä¾›ä¼ä¸šç‰ˆï¼ˆLlamaCloudï¼‰
- æ‰˜ç®¡æœåŠ¡
- æŠ€æœ¯æ”¯æŒ

**LangChain**ï¼š
- LangSmithï¼ˆç›‘æ§å’Œè°ƒè¯•å¹³å°ï¼‰
- LangServeï¼ˆéƒ¨ç½²æ¡†æ¶ï¼‰
- ä¼ä¸šæ”¯æŒè®¡åˆ’


### 7.2 LangChainå­¦ä¹ è·¯å¾„

**å®˜æ–¹èµ„æº**ï¼š
- ğŸ“š [å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- ğŸ’» [GitHubä»“åº“](https://github.com/langchain-ai/langchain)
- ğŸ“ [LangChain Academy](https://academy.langchain.com/)

**å­¦ä¹ å»ºè®®**ï¼š
1. **ç¬¬1-2å‘¨**ï¼šModelsã€Promptsã€ChainsåŸºç¡€
2. **ç¬¬3-4å‘¨**ï¼šMemoryã€Toolsã€Agents
3. **ç¬¬5-6å‘¨**ï¼šRAGç³»ç»Ÿã€å‘é‡æ•°æ®åº“
4. **ç¬¬7-8å‘¨**ï¼šå®æˆ˜é¡¹ç›®ï¼šæ„å»ºæ™ºèƒ½åŠ©æ‰‹

**æ¨èé˜…è¯»**ï¼š
- æœ¬åšå®¢çš„ [LangChainå®Œæ•´å­¦ä¹ æŒ‡å—](./README.md)ï¼ˆ16å‘¨ç³»ç»Ÿè¯¾ç¨‹ï¼‰


## ä¹ã€æ€»ç»“ä¸å»ºè®®

### 9.1 æ ¸å¿ƒå·®å¼‚æ€»ç»“

```mermaid
graph TB
    A[é€‰æ‹©æ¡†æ¶] --> B{é¡¹ç›®ç‰¹ç‚¹?}

    B -->|ä¸»è¦æ˜¯RAG/é—®ç­”| C[LlamaIndex]
    B -->|éœ€è¦Agentå†³ç­–| D[LangChain]
    B -->|ä¸¤è€…éƒ½éœ€è¦| E[ç»“åˆä½¿ç”¨]

    C --> C1[âœ… ä»£ç ç®€æ´]
    C --> C2[âœ… æ€§èƒ½ä¼˜ç§€]
    C --> C3[âœ… å¿«é€Ÿä¸Šçº¿]

    D --> D1[âœ… åŠŸèƒ½å¼ºå¤§]
    D --> D2[âœ… çµæ´»å¯æ‰©å±•]
    D --> D3[âœ… å·¥å…·ä¸°å¯Œ]

    E --> E1[âœ… å‘æŒ¥å„è‡ªä¼˜åŠ¿]
    E --> E2[âœ… æœ€ä½³å®è·µ]

    style C fill:#e1f5ff
    style D fill:#fff4e1
    style E fill:#e8f5e9
```

### 9.2 æœ€ä½³å®è·µå»ºè®®

**1. é¡¹ç›®åˆæœŸ**
- âœ… å…ˆç”¨LlamaIndexå¿«é€ŸéªŒè¯æƒ³æ³•
- âœ… ç¡®è®¤æ ¸å¿ƒéœ€æ±‚åå†é€‰æ‹©åˆé€‚çš„æ¡†æ¶
- âœ… ä¸è¦è¿‡æ—©ä¼˜åŒ–

**2. åŸå‹é˜¶æ®µ**
- âœ… å¦‚æœæ˜¯RAGåœºæ™¯ï¼Œä¼˜å…ˆLlamaIndex
- âœ… éœ€è¦å¤æ‚å·¥ä½œæµæ—¶è€ƒè™‘LangChain
- âœ… ä¿æŒä»£ç ç®€æ´ï¼Œä¾¿äºè¿­ä»£

**3. ç”Ÿäº§é˜¶æ®µ**
- âœ… è€ƒè™‘ç»“åˆä½¿ç”¨ä¸¤ä¸ªæ¡†æ¶
- âœ… ç”¨LlamaIndexå¤„ç†æ£€ç´¢ï¼ˆæ€§èƒ½ï¼‰
- âœ… ç”¨LangChainå¤„ç†å†³ç­–ï¼ˆçµæ´»æ€§ï¼‰

**4. å›¢é˜Ÿåä½œ**
- âœ… ç»Ÿä¸€æ¡†æ¶é€‰æ‹©ï¼ˆé™¤éæœ‰æ˜ç¡®ç†ç”±æ··ç”¨ï¼‰
- âœ… å»ºç«‹æœ€ä½³å®è·µæ–‡æ¡£
- âœ… å®šæœŸreviewæ€§èƒ½å’Œä»£ç è´¨é‡

### 9.3 æœªæ¥è¶‹åŠ¿

**ä¸¤ä¸ªæ¡†æ¶éƒ½åœ¨å¿«é€Ÿå‘å±•**ï¼š
- ğŸ”® LlamaIndexï¼šå¢å¼ºAgentèƒ½åŠ›ï¼Œæ‰©å±•å·¥å…·ç”Ÿæ€
- ğŸ”® LangChainï¼šä¼˜åŒ–æ€§èƒ½ï¼Œç®€åŒ–API
- ğŸ”® ä¸¤è€…å¯èƒ½ä¼šåœ¨æŸäº›æ–¹é¢è¶‹åŒ

**å»ºè®®**ï¼š
- ğŸ“š ä¸¤è€…éƒ½å€¼å¾—å­¦ä¹ 
- ğŸ”„ å…³æ³¨æ›´æ–°ï¼ŒåŠæ—¶å‡çº§
- ğŸ’¡ æ ¹æ®é¡¹ç›®å®é™…éœ€æ±‚çµæ´»é€‰æ‹©


### 10.2 LangChainå®ç°

```python
# æ–‡ä»¶ï¼špdf_qa_langchain.py
from langchain.document_loaders import PyPDFDirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# 15è¡Œæ ¸å¿ƒä»£ç 
loader = PyPDFDirectoryLoader('pdfs')
documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
splits = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(splits, embeddings)

llm = ChatOpenAI()
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

response = qa_chain.run("è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**ç‰¹ç‚¹**ï¼š
- âœ… æ¯ä¸€æ­¥å¯æ§
- âœ… å¯ä»¥è‡ªç”±æ›¿æ¢ç»„ä»¶
- âœ… é€‚åˆå¤æ‚å®šåˆ¶


## åä¸€ã€å¸¸è§é—®é¢˜FAQ

### Q1: å¯ä»¥åœ¨åŒä¸€ä¸ªé¡¹ç›®ä¸­åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªæ¡†æ¶å—ï¼Ÿ

**A**: å¯ä»¥ï¼è¿™æ˜¯æ¨èçš„æœ€ä½³å®è·µä¹‹ä¸€ã€‚

```python
# ç¤ºä¾‹ï¼šç»“åˆä½¿ç”¨
from llama_index import VectorStoreIndex
from langchain.agents import initialize_agent

# LlamaIndexè´Ÿè´£æ£€ç´¢
index = VectorStoreIndex.from_documents(documents)

def search_kb(query):
    return str(index.as_query_engine().query(query))

# LangChainè´Ÿè´£å†³ç­–
tools = [Tool(name="KB", func=search_kb, description="...")]
agent = initialize_agent(tools, llm, ...)
```


### Q3: åˆå­¦è€…åº”è¯¥å…ˆå­¦å“ªä¸ªï¼Ÿ

**A**: å»ºè®®è·¯å¾„ï¼š

1. **å¦‚æœä½ çš„ç›®æ ‡æ˜¯å¿«é€Ÿæ„å»ºRAGåº”ç”¨**ï¼š
   - å…ˆå­¦LlamaIndexï¼ˆ1-2å‘¨ï¼‰
   - ç†è§£æ ¸å¿ƒæ¦‚å¿µåå†å­¦LangChain

2. **å¦‚æœä½ æƒ³å…¨é¢æŒæ¡LLMåº”ç”¨å¼€å‘**ï¼š
   - ç›´æ¥å­¦LangChainï¼ˆæ›´å…¨é¢ï¼‰
   - å‚è€ƒæœ¬åšå®¢çš„[LangChain 16å‘¨è¯¾ç¨‹](./README.md)


### Q5: å¦‚ä½•è¿ç§»ï¼Ÿ

**A**: è¿ç§»ç­–ç•¥ï¼š

```python
# ä»LlamaIndexè¿ç§»åˆ°LangChain
# 1. ä¿ç•™ç´¢å¼•æ•°æ®ï¼ˆå‘é‡æ•°æ®åº“ï¼‰
# 2. åªæ›¿æ¢æŸ¥è¯¢é€»è¾‘

# åŸLlamaIndexä»£ç 
# index = VectorStoreIndex.from_documents(documents)

# è¿ç§»ï¼šä½¿ç”¨ç›¸åŒçš„å‘é‡æ•°æ®åº“
from langchain.vectorstores import Chroma
vectorstore = Chroma(persist_directory="./chroma_db")
# ç»§ç»­ä½¿ç”¨LangChainçš„å…¶ä»–åŠŸèƒ½

# ä»LangChainè¿ç§»åˆ°LlamaIndex
# 1. å¯¼å‡ºå‘é‡æ•°æ®
# 2. ç”¨LlamaIndexé‡æ–°åŠ è½½
```

**å»ºè®®**ï¼šé™¤éæœ‰æ˜ç¡®æ”¶ç›Šï¼Œå¦åˆ™ä¸è¦è½»æ˜“è¿ç§»ã€‚


**ç¥ä½ åœ¨LLMåº”ç”¨å¼€å‘çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œï¼** ğŸ‰

å¦‚æœæœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿äº¤æµè®¨è®ºï¼
