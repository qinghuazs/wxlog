---
title: Week4 Chains Basics
date: 2025-11-18
permalink: /ai/langchain/week4-chains-basics.html
categories:
  - AI
---

# ç¬¬4å‘¨ï¼šChains åŸºç¡€

::: tip æœ¬å‘¨å­¦ä¹ ç›®æ ‡
- ğŸ”— ç†è§£ Chain çš„æ¦‚å¿µå’Œä½œç”¨
- ğŸ› ï¸ æŒæ¡ LLMChainã€SequentialChain ç­‰åŸºç¡€ Chain
- ğŸš€ å­¦ä¹  LCEL (LangChain Expression Language)
- ğŸ¯ èƒ½å¤Ÿç»„åˆå¤šä¸ªç»„ä»¶æ„å»ºå¤æ‚æµç¨‹
- ğŸ’¡ å®ç°å®é™…ä¸šåŠ¡åœºæ™¯çš„ Chain åº”ç”¨
:::

## ä¸€ã€Chain åŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯ Chainï¼Ÿ

**Chainï¼ˆé“¾ï¼‰** æ˜¯ LangChain çš„æ ¸å¿ƒæŠ½è±¡ï¼Œç”¨äºå°†å¤šä¸ªç»„ä»¶ï¼ˆLLMã€Promptsã€Toolsç­‰ï¼‰æŒ‰ç…§ç‰¹å®šé¡ºåºè¿æ¥èµ·æ¥ï¼Œå½¢æˆå®Œæ•´çš„å·¥ä½œæµç¨‹ã€‚

```mermaid
graph LR
    A[è¾“å…¥] --> B[æ­¥éª¤1: Prompt]
    B --> C[æ­¥éª¤2: LLM]
    C --> D[æ­¥éª¤3: Parser]
    D --> E[è¾“å‡º]

    style A fill:#E3F2FD
    style E fill:#C8E6C9
    style B fill:#FFF9C4
    style C fill:#FFE0B2
    style D fill:#F8BBD0
```

#### ä¸ºä»€ä¹ˆéœ€è¦ Chainï¼Ÿ

**å¯¹æ¯”ï¼šæ—  Chain vs æœ‰ Chain**

```python
"""
åœºæ™¯ï¼šç¿»è¯‘å¹¶æ€»ç»“ä¸€æ®µæ–‡æœ¬
"""
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

llm = ChatOpenAI(model="gpt-3.5-turbo")

# âŒ æ–¹å¼1ï¼šæ‰‹åŠ¨ç®¡ç†å¤šä¸ªæ­¥éª¤ï¼ˆç¹çï¼‰
def manual_translate_and_summarize(text: str) -> str:
    # æ­¥éª¤1ï¼šç¿»è¯‘
    translate_prompt = f"å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{text}"
    translation = llm.invoke([HumanMessage(content=translate_prompt)])

    # æ­¥éª¤2ï¼šæ€»ç»“
    summary_prompt = f"æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š\n{translation.content}"
    summary = llm.invoke([HumanMessage(content=summary_prompt)])

    return summary.content

# âœ… æ–¹å¼2ï¼šä½¿ç”¨ Chainï¼ˆä¼˜é›…ï¼‰
from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.prompts import PromptTemplate

# å®šä¹‰ç¿»è¯‘é“¾
translate_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template("å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{text}")
)

# å®šä¹‰æ€»ç»“é“¾
summary_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template("æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š\n{text}")
)

# ç»„åˆæˆé¡ºåºé“¾
overall_chain = SimpleSequentialChain(
    chains=[translate_chain, summary_chain],
    verbose=True  # æ˜¾ç¤ºä¸­é—´æ­¥éª¤
)

# ä½¿ç”¨
result = overall_chain.run("äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œï¼Œå®ƒåœ¨åŒ»ç–—ã€æ•™è‚²ã€äº¤é€šç­‰é¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚")
```

**Chain çš„ä¼˜åŠ¿ï¼š**

| ç‰¹æ€§ | æ‰‹åŠ¨ç®¡ç† | ä½¿ç”¨ Chain |
|------|---------|-----------|
| **ä»£ç å¤ç”¨** | âŒ é‡å¤ä»£ç å¤š | âœ… é«˜åº¦å¤ç”¨ |
| **å¯ç»´æŠ¤æ€§** | âŒ éš¾ä»¥ç»´æŠ¤ | âœ… ç»“æ„æ¸…æ™° |
| **è°ƒè¯•** | âŒ éš¾ä»¥è¿½è¸ª | âœ… å†…ç½®è°ƒè¯•æ”¯æŒ |
| **æ‰©å±•æ€§** | âŒ ä¿®æ”¹å›°éš¾ | âœ… æ˜“äºæ‰©å±• |
| **é”™è¯¯å¤„ç†** | âŒ æ‰‹åŠ¨å¤„ç† | âœ… è‡ªåŠ¨å¤„ç† |

### 1.2 Chain çš„ç±»å‹

LangChain æä¾›äº†å¤šç§é¢„å®šä¹‰çš„ Chainï¼š

```mermaid
graph TB
    A[Chain ç±»å‹] --> B[åŸºç¡€ Chain]
    A --> C[é¡ºåº Chain]
    A --> D[è·¯ç”± Chain]
    A --> E[ç‰¹æ®Šç”¨é€” Chain]

    B --> B1[LLMChain<br/>æœ€åŸºç¡€çš„é“¾]
    B --> B2[TransformChain<br/>æ•°æ®è½¬æ¢é“¾]

    C --> C1[SimpleSequentialChain<br/>ç®€å•é¡ºåºé“¾]
    C --> C2[SequentialChain<br/>å¤æ‚é¡ºåºé“¾]

    D --> D1[RouterChain<br/>æ¡ä»¶è·¯ç”±]
    D --> D2[MultiPromptChain<br/>å¤šæç¤ºè·¯ç”±]

    E --> E1[ConversationChain<br/>å¯¹è¯é“¾]
    E --> E2[RetrievalQA<br/>é—®ç­”é“¾]
    E --> E3[SummarizationChain<br/>æ‘˜è¦é“¾]

    style A fill:#E3F2FD
    style B fill:#BBDEFB
    style C fill:#90CAF9
    style D fill:#64B5F6
    style E fill:#42A5F5
```


## ä¸‰ã€é¡ºåº Chain

### 3.1 SimpleSequentialChain

**SimpleSequentialChain** ç”¨äºç®€å•çš„é¡ºåºæ‰§è¡Œï¼Œæ¯ä¸ª Chain çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªçš„è¾“å…¥ã€‚

```python
"""
SimpleSequentialChain ç¤ºä¾‹ï¼šæ–‡ç« ç”Ÿæˆæµæ°´çº¿
æµç¨‹ï¼šç”Ÿæˆå¤§çº² -> æ‰©å†™ç¬¬ä¸€æ®µ -> æ¶¦è‰²æ–‡æœ¬
"""
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.prompts import PromptTemplate

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

# Chain 1: ç”Ÿæˆå¤§çº²
outline_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(
        "ä¸ºä¸»é¢˜'{topic}'ç”Ÿæˆä¸€ä¸ª3ç‚¹å¤§çº²"
    )
)

# Chain 2: æ‰©å†™ç¬¬ä¸€æ®µ
expand_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(
        "æ ¹æ®ä»¥ä¸‹å¤§çº²ï¼Œæ‰©å†™ç¬¬ä¸€æ®µï¼ˆ100å­—å·¦å³ï¼‰ï¼š\n{outline}"
    )
)

# Chain 3: æ¶¦è‰²æ–‡æœ¬
polish_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(
        "æ¶¦è‰²ä»¥ä¸‹æ–‡æœ¬ï¼Œä½¿å…¶æ›´åŠ æµç•…ï¼š\n{text}"
    )
)

# ç»„åˆæˆé¡ºåºé“¾
overall_chain = SimpleSequentialChain(
    chains=[outline_chain, expand_chain, polish_chain],
    verbose=True
)

# è¿è¡Œ
result = overall_chain.run("äººå·¥æ™ºèƒ½çš„æœªæ¥")
print(f"\næœ€ç»ˆç»“æœï¼š\n{result}")
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
> Entering new SimpleSequentialChain chain...

1. äººå·¥æ™ºèƒ½çš„å®šä¹‰å’Œå‘å±•å†ç¨‹
2. å½“å‰äººå·¥æ™ºèƒ½çš„ä¸»è¦åº”ç”¨é¢†åŸŸ
3. æœªæ¥äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿å’ŒæŒ‘æˆ˜

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯æŒ‡è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æŠ€æœ¯...ï¼ˆç¬¬ä¸€æ®µæ‰©å†™ï¼‰

ç»è¿‡æ¶¦è‰²çš„æ–‡æœ¬ï¼š
äººå·¥æ™ºèƒ½ä½œä¸ºè®¡ç®—æœºç§‘å­¦çš„å‰æ²¿é¢†åŸŸ...ï¼ˆæ¶¦è‰²åçš„æ–‡æœ¬ï¼‰

> Finished chain.
```

::: warning æ³¨æ„
SimpleSequentialChain çš„é™åˆ¶ï¼š
- åªèƒ½æœ‰ä¸€ä¸ªè¾“å…¥å’Œä¸€ä¸ªè¾“å‡º
- æ¯ä¸ª Chain çš„è¾“å‡ºå¿…é¡»æ˜¯å­—ç¬¦ä¸²
- ä¸èƒ½ä¿ç•™ä¸­é—´ç»“æœ
:::

### 3.2 SequentialChain

**SequentialChain** æ˜¯æ›´å¼ºå¤§çš„é¡ºåºé“¾ï¼Œæ”¯æŒï¼š
- å¤šä¸ªè¾“å…¥å’Œè¾“å‡º
- ä¿ç•™ä¸­é—´ç»“æœ
- æ›´çµæ´»çš„æ•°æ®æµ

```python
"""
SequentialChain ç¤ºä¾‹ï¼šå•†å“è¯„è®ºåˆ†æ
æµç¨‹ï¼šæå–å…³é”®è¯ -> æƒ…æ„Ÿåˆ†æ -> ç”Ÿæˆå›å¤
"""
from langchain.chains import LLMChain, SequentialChain
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)

# Chain 1: æå–å…³é”®è¯
keyword_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["review"],
        template="ä»ä»¥ä¸‹è¯„è®ºä¸­æå–3-5ä¸ªå…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼š\n{review}\n\nå…³é”®è¯ï¼š"
    ),
    output_key="keywords"  # æŒ‡å®šè¾“å‡ºé”®å
)

# Chain 2: æƒ…æ„Ÿåˆ†æ
sentiment_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["review"],
        template="åˆ¤æ–­ä»¥ä¸‹è¯„è®ºçš„æƒ…æ„Ÿï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ï¼š\n{review}\n\næƒ…æ„Ÿï¼š"
    ),
    output_key="sentiment"
)

# Chain 3: ç”Ÿæˆå›å¤
reply_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["review", "keywords", "sentiment"],
        template="""ä½œä¸ºå®¢æœï¼Œæ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå›å¤ï¼š

è¯„è®ºï¼š{review}
å…³é”®è¯ï¼š{keywords}
æƒ…æ„Ÿï¼š{sentiment}

å›å¤ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š"""
    ),
    output_key="reply"
)

# ç»„åˆæˆ SequentialChain
overall_chain = SequentialChain(
    chains=[keyword_chain, sentiment_chain, reply_chain],
    input_variables=["review"],  # åˆå§‹è¾“å…¥
    output_variables=["keywords", "sentiment", "reply"],  # éœ€è¦ä¿ç•™çš„è¾“å‡º
    verbose=True
)

# æµ‹è¯•
review = "è¿™ä¸ªäº§å“è´¨é‡å¾ˆå¥½ï¼Œç‰©æµä¹Ÿå¾ˆå¿«ï¼Œä½†æ˜¯ä»·æ ¼æœ‰ç‚¹è´µã€‚å®¢æœæ€åº¦ä¸é”™ã€‚"
result = overall_chain.invoke({"review": review})

print("\n" + "=" * 60)
print("åˆ†æç»“æœï¼š")
print(f"å…³é”®è¯ï¼š{result['keywords']}")
print(f"æƒ…æ„Ÿï¼š{result['sentiment']}")
print(f"å›å¤ï¼š{result['reply']}")
print("=" * 60)
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
============================================================
åˆ†æç»“æœï¼š
å…³é”®è¯ï¼šè´¨é‡å¥½, ç‰©æµå¿«, ä»·æ ¼è´µ, å®¢æœæ€åº¦
æƒ…æ„Ÿï¼šæ­£é¢
å›å¤ï¼šæ„Ÿè°¢æ‚¨çš„è®¤å¯ï¼æˆ‘ä»¬ä¼šç»§ç»­ä¿æŒä¼˜è´¨çš„äº§å“å’ŒæœåŠ¡ï¼ŒåŒæ—¶ä¹Ÿä¼šè€ƒè™‘ä»·æ ¼ä¼˜åŒ–ã€‚
============================================================
```

### 3.3 é¡ºåºé“¾çš„æ•°æ®æµ

```mermaid
graph LR
    A[è¾“å…¥: review] --> B[Chain 1<br/>æå–å…³é”®è¯]
    B --> C[è¾“å‡º: keywords]
    A --> D[Chain 2<br/>æƒ…æ„Ÿåˆ†æ]
    D --> E[è¾“å‡º: sentiment]

    A --> F[Chain 3<br/>ç”Ÿæˆå›å¤]
    C --> F
    E --> F
    F --> G[è¾“å‡º: reply]

    style A fill:#E3F2FD
    style G fill:#C8E6C9
    style B fill:#FFE0B2
    style D fill:#FFE0B2
    style F fill:#FFE0B2
```


## äº”ã€å®æˆ˜é¡¹ç›®

### 5.1 é¡¹ç›®ï¼šæ™ºèƒ½æ–‡ç« ç”Ÿæˆç³»ç»Ÿ

```python
"""
é¡¹ç›®ï¼šæ™ºèƒ½æ–‡ç« ç”Ÿæˆç³»ç»Ÿ
åŠŸèƒ½ï¼š
1. ç”Ÿæˆæ–‡ç« å¤§çº²
2. é€æ®µæ‰©å†™
3. æ·»åŠ æ€»ç»“
4. æ ¼å¼åŒ–è¾“å‡º
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough

class ArticleGenerator:
    """æ–‡ç« ç”Ÿæˆå™¨"""

    def __init__(self, model: str = "gpt-3.5-turbo"):
        self.llm = ChatOpenAI(model=model, temperature=0.7)

    def generate_outline(self, topic: str, num_points: int = 3) -> str:
        """ç”Ÿæˆå¤§çº²"""
        chain = (
            ChatPromptTemplate.from_template(
                "ä¸ºä¸»é¢˜'{topic}'ç”Ÿæˆ{num_points}ç‚¹å¤§çº²ï¼Œæ¯ç‚¹ç”¨ä¸€è¡Œï¼Œæ ¼å¼ï¼š\n1. ...\n2. ..."
            )
            | self.llm
            | StrOutputParser()
        )
        return chain.invoke({"topic": topic, "num_points": num_points})

    def expand_point(self, point: str) -> str:
        """æ‰©å†™å•ä¸ªè¦ç‚¹"""
        chain = (
            ChatPromptTemplate.from_template(
                "å°†ä»¥ä¸‹è¦ç‚¹æ‰©å†™æˆä¸€æ®µè¯ï¼ˆ100-150å­—ï¼‰ï¼š\n{point}"
            )
            | self.llm
            | StrOutputParser()
        )
        return chain.invoke({"point": point})

    def generate_conclusion(self, article: str) -> str:
        """ç”Ÿæˆç»“è®º"""
        chain = (
            ChatPromptTemplate.from_template(
                "ä¸ºä»¥ä¸‹æ–‡ç« å†™ä¸€ä¸ªç®€çŸ­çš„ç»“è®ºï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š\n\n{article}"
            )
            | self.llm
            | StrOutputParser()
        )
        return chain.invoke({"article": article})

    def generate_article(self, topic: str, num_points: int = 3) -> dict:
        """
        ç”Ÿæˆå®Œæ•´æ–‡ç« 

        è¿”å›:
            åŒ…å« title, outline, body, conclusion çš„å­—å…¸
        """
        print(f"æ­£åœ¨ç”Ÿæˆæ–‡ç« ï¼š{topic}")

        # æ­¥éª¤1ï¼šç”Ÿæˆå¤§çº²
        print("  [1/4] ç”Ÿæˆå¤§çº²...")
        outline = self.generate_outline(topic, num_points)
        print(f"  å¤§çº²ï¼š\n{outline}\n")

        # æ­¥éª¤2ï¼šæ‰©å†™æ¯ä¸ªè¦ç‚¹
        print("  [2/4] æ‰©å†™è¦ç‚¹...")
        points = [line.strip() for line in outline.split("\n") if line.strip()]
        paragraphs = []

        for i, point in enumerate(points, 1):
            print(f"    æ‰©å†™ç¬¬ {i} ç‚¹...")
            paragraph = self.expand_point(point)
            paragraphs.append(paragraph)

        body = "\n\n".join(paragraphs)

        # æ­¥éª¤3ï¼šç”Ÿæˆç»“è®º
        print("  [3/4] ç”Ÿæˆç»“è®º...")
        conclusion = self.generate_conclusion(body)

        # æ­¥éª¤4ï¼šæ ¼å¼åŒ–
        print("  [4/4] æ ¼å¼åŒ–è¾“å‡º...")
        full_article = f"""# {topic}

## å¤§çº²
{outline}

## æ­£æ–‡
{body}

## ç»“è®º
{conclusion}
"""

        return {
            "title": topic,
            "outline": outline,
            "body": body,
            "conclusion": conclusion,
            "full_article": full_article
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    generator = ArticleGenerator()

    result = generator.generate_article(
        topic="äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
        num_points=3
    )

    print("\n" + "=" * 60)
    print(result["full_article"])
    print("=" * 60)
```

### 5.2 é¡¹ç›®ï¼šå¤šè¯­è¨€ç¿»è¯‘æ ¡å¯¹ç³»ç»Ÿ

```python
"""
é¡¹ç›®ï¼šå¤šè¯­è¨€ç¿»è¯‘æ ¡å¯¹ç³»ç»Ÿ
åŠŸèƒ½ï¼š
1. ç¿»è¯‘æ–‡æœ¬
2. å›è¯‘æ ¡å¯¹
3. è¯„ä¼°ç¿»è¯‘è´¨é‡
4. æä¾›æ”¹è¿›å»ºè®®
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableParallel

class TranslationReviewer:
    """ç¿»è¯‘æ ¡å¯¹ç³»ç»Ÿ"""

    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)

    def translate(self, text: str, target_language: str) -> str:
        """ç¿»è¯‘æ–‡æœ¬"""
        chain = (
            ChatPromptTemplate.from_template(
                "å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{target_language}ï¼š\n{text}"
            )
            | self.llm
            | StrOutputParser()
        )
        return chain.invoke({"text": text, "target_language": target_language})

    def back_translate(self, text: str, original_language: str) -> str:
        """å›è¯‘æ–‡æœ¬"""
        chain = (
            ChatPromptTemplate.from_template(
                "å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{original_language}ï¼š\n{text}"
            )
            | self.llm
            | StrOutputParser()
        )
        return chain.invoke({"text": text, "original_language": original_language})

    def evaluate_quality(self, original: str, back_translated: str) -> dict:
        """è¯„ä¼°ç¿»è¯‘è´¨é‡"""
        chain = (
            ChatPromptTemplate.from_template(
                """æ¯”è¾ƒåŸæ–‡å’Œå›è¯‘æ–‡æœ¬ï¼Œè¯„ä¼°ç¿»è¯‘è´¨é‡ï¼š

åŸæ–‡ï¼š{original}
å›è¯‘ï¼š{back_translated}

è¯·æä¾›ï¼š
1. ç›¸ä¼¼åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰
2. ä¸»è¦å·®å¼‚
3. æ”¹è¿›å»ºè®®

æ ¼å¼ï¼š
è¯„åˆ†: XX
å·®å¼‚: ...
å»ºè®®: ..."""
            )
            | self.llm
            | StrOutputParser()
        )
        evaluation = chain.invoke({
            "original": original,
            "back_translated": back_translated
        })

        # è§£æè¯„ä¼°ç»“æœ
        lines = evaluation.split("\n")
        score = None
        differences = ""
        suggestions = ""

        for line in lines:
            if "è¯„åˆ†" in line or "score" in line.lower():
                import re
                match = re.search(r'\d+', line)
                if match:
                    score = int(match.group())
            elif "å·®å¼‚" in line or "difference" in line.lower():
                differences = line.split(":", 1)[1].strip() if ":" in line else ""
            elif "å»ºè®®" in line or "suggestion" in line.lower():
                suggestions = line.split(":", 1)[1].strip() if ":" in line else ""

        return {
            "score": score or 0,
            "differences": differences,
            "suggestions": suggestions,
            "full_evaluation": evaluation
        }

    def review_translation(
        self,
        text: str,
        target_language: str,
        original_language: str = "ä¸­æ–‡"
    ) -> dict:
        """
        å®Œæ•´çš„ç¿»è¯‘æ ¡å¯¹æµç¨‹

        è¿”å›:
            åŒ…å«ç¿»è¯‘ç»“æœå’Œè´¨é‡è¯„ä¼°çš„å­—å…¸
        """
        print(f"å¼€å§‹ç¿»è¯‘æ ¡å¯¹æµç¨‹...")
        print(f"  åŸæ–‡ï¼š{text}")

        # æ­¥éª¤1ï¼šç¿»è¯‘
        print(f"\n[1/3] ç¿»è¯‘æˆ{target_language}...")
        translation = self.translate(text, target_language)
        print(f"  è¯‘æ–‡ï¼š{translation}")

        # æ­¥éª¤2ï¼šå›è¯‘
        print(f"\n[2/3] å›è¯‘æˆ{original_language}...")
        back_translation = self.back_translate(translation, original_language)
        print(f"  å›è¯‘ï¼š{back_translation}")

        # æ­¥éª¤3ï¼šè¯„ä¼°
        print(f"\n[3/3] è¯„ä¼°ç¿»è¯‘è´¨é‡...")
        evaluation = self.evaluate_quality(text, back_translation)

        print(f"\nè¯„ä¼°ç»“æœï¼š")
        print(f"  ç›¸ä¼¼åº¦è¯„åˆ†ï¼š{evaluation['score']}/100")
        print(f"  ä¸»è¦å·®å¼‚ï¼š{evaluation['differences']}")
        print(f"  æ”¹è¿›å»ºè®®ï¼š{evaluation['suggestions']}")

        return {
            "original": text,
            "translation": translation,
            "back_translation": back_translation,
            "evaluation": evaluation
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    reviewer = TranslationReviewer()

    result = reviewer.review_translation(
        text="äººå·¥æ™ºèƒ½æ­£åœ¨æ·±åˆ»æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼å’Œå·¥ä½œæ–¹å¼ã€‚",
        target_language="è‹±æ–‡",
        original_language="ä¸­æ–‡"
    )

    print("\n" + "=" * 60)
    print("å®Œæ•´æŠ¥å‘Šï¼š")
    print(f"åŸæ–‡ï¼š{result['original']}")
    print(f"è¯‘æ–‡ï¼š{result['translation']}")
    print(f"å›è¯‘ï¼š{result['back_translation']}")
    print(f"è´¨é‡è¯„åˆ†ï¼š{result['evaluation']['score']}/100")
    print("=" * 60)
```


## ä¸ƒã€æœ¬å‘¨æ€»ç»“

### 7.1 çŸ¥è¯†ç‚¹æ¸…å•

- [x] Chain çš„æ¦‚å¿µå’Œä½œç”¨
- [x] LLMChain åŸºç¡€ç”¨æ³•
- [x] SimpleSequentialChain å’Œ SequentialChain
- [x] LCEL è¯­æ³•å’Œé«˜çº§ç‰¹æ€§
- [x] å¹¶è¡Œæ‰§è¡Œå’Œæ¡ä»¶åˆ†æ”¯
- [x] å®æˆ˜é¡¹ç›®å¼€å‘

### 7.2 Chain é€‰æ‹©æŒ‡å—

```mermaid
graph TD
    A[é€‰æ‹© Chain] --> B{å‡ ä¸ªæ­¥éª¤?}
    B -->|å•æ­¥éª¤| C[LLMChain]
    B -->|å¤šæ­¥éª¤| D{éœ€è¦ä¿ç•™ä¸­é—´ç»“æœ?}

    D -->|ä¸éœ€è¦| E[SimpleSequentialChain]
    D -->|éœ€è¦| F[SequentialChain æˆ– LCEL]

    F --> G{æ˜¯å¦æœ‰æ¡ä»¶åˆ†æ”¯?}
    G -->|æœ‰| H[LCEL + RunnableBranch]
    G -->|æ— | I[LCEL æˆ– SequentialChain]

    style C fill:#C8E6C9
    style E fill:#FFE082
    style F fill:#FFE082
    style H fill:#81C784
    style I fill:#81C784
```

### 7.3 ä¸‹å‘¨é¢„ä¹ 

**ç¬¬5å‘¨ä¸»é¢˜ï¼šDocuments æ–‡æ¡£å¤„ç†**

é¢„ä¹ å†…å®¹ï¼š
1. DocumentLoader çš„ä½œç”¨
2. TextSplitter çš„åˆ†å‰²ç­–ç•¥
3. å¦‚ä½•å¤„ç† PDFã€Word ç­‰æ–‡ä»¶

**æ€è€ƒé—®é¢˜**ï¼š
- ä¸ºä»€ä¹ˆè¦åˆ†å‰²æ–‡æ¡£ï¼Ÿ
- å¦‚ä½•é€‰æ‹©åˆé€‚çš„åˆ†å‰²å¤§å°ï¼Ÿ

---

::: tip å­¦ä¹ å»ºè®®
1. **å¤šç»ƒä¹  LCEL**ï¼šè¿™æ˜¯æœªæ¥çš„ä¸»æµè¯­æ³•
2. **ç†è§£æ•°æ®æµ**ï¼šææ¸…æ¥šæ¯ä¸ª Chain çš„è¾“å…¥è¾“å‡º
3. **æ¨¡å—åŒ–æ€ç»´**ï¼šæŠŠå¤æ‚ä»»åŠ¡åˆ†è§£æˆå°çš„ Chain
4. **å®æˆ˜ä¸ºä¸»**ï¼šé€šè¿‡å®é™…é¡¹ç›®å·©å›ºçŸ¥è¯†
:::

**æœ¬å‘¨å®Œæˆï¼ç»§ç»­åŠ æ²¹ï¼ğŸš€**
