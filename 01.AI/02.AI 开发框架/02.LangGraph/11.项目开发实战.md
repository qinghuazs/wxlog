---
title: LangGraphå®æˆ˜æ•™ç¨‹(ç¬¬11ç« ):é¡¹ç›®å¼€å‘å®æˆ˜
date: 2025-02-04
permalink: /ai/langgraph/11.é¡¹ç›®å¼€å‘å®æˆ˜.html
categories:
  - LangGraph
tags:
  - LangGraph
---

# é¡¹ç›®å¼€å‘å®æˆ˜

## ä¸€ã€é¡¹ç›®ä¸€ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

### 1.1 é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªå¤šåŠŸèƒ½æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œæ”¯æŒæ„å›¾è¯†åˆ«ã€å¤šè½®å¯¹è¯ã€çŸ¥è¯†åº“æŸ¥è¯¢å’Œäººå·¥è½¬æ¥ã€‚

### 1.2 ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    A[ç”¨æˆ·è¾“å…¥] --> B[æ„å›¾è¯†åˆ«]
    B --> C{æ„å›¾ç±»å‹}
    C -->|FAQ| D[çŸ¥è¯†åº“æŸ¥è¯¢]
    C -->|è®¢å•æŸ¥è¯¢| E[è®¢å•ç³»ç»Ÿ]
    C -->|æŠ•è¯‰å»ºè®®| F[å·¥å•ç³»ç»Ÿ]
    C -->|å¤æ‚é—®é¢˜| G[äººå·¥è½¬æ¥]
    D --> H[ç”Ÿæˆå›å¤]
    E --> H
    F --> H
    G --> I[ç­‰å¾…äººå·¥]
    H --> J[å‘é€å“åº”]
    I --> J
```

### 1.3 å®Œæ•´å®ç°

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Optional, Annotated
import operator
from enum import Enum
from datetime import datetime
import json
import random

# æ„å›¾ç±»å‹å®šä¹‰
class Intent(Enum):
    GREETING = "greeting"
    FAQ = "faq"
    ORDER_QUERY = "order_query"
    COMPLAINT = "complaint"
    HUMAN_TRANSFER = "human_transfer"
    UNKNOWN = "unknown"

# çŠ¶æ€å®šä¹‰
class CustomerServiceState(TypedDict):
    # å¯¹è¯å†å²
    messages: Annotated[List[Dict[str, str]], operator.add]
    # ç”¨æˆ·ä¿¡æ¯
    user_id: str
    session_id: str
    # å½“å‰å¯¹è¯
    user_input: str
    bot_response: str
    # æ„å›¾è¯†åˆ«
    intent: Intent
    intent_confidence: float
    entities: Dict[str, any]
    # ä¸Šä¸‹æ–‡
    context: Dict[str, any]
    conversation_stage: str
    # æ§åˆ¶æ ‡å¿—
    needs_human: bool
    conversation_ended: bool
    satisfaction_score: Optional[float]

# çŸ¥è¯†åº“
class KnowledgeBase:
    """æ¨¡æ‹ŸçŸ¥è¯†åº“"""

    def __init__(self):
        self.faqs = {
            "é€€è´§æ”¿ç­–": "æˆ‘ä»¬æä¾›30å¤©æ— ç†ç”±é€€è´§æœåŠ¡...",
            "é…é€æ—¶é—´": "æ ‡å‡†é…é€éœ€è¦3-5ä¸ªå·¥ä½œæ—¥...",
            "æ”¯ä»˜æ–¹å¼": "æ”¯æŒæ”¯ä»˜å®ã€å¾®ä¿¡ã€ä¿¡ç”¨å¡ç­‰å¤šç§æ”¯ä»˜æ–¹å¼...",
            "ä¼šå‘˜æƒç›Š": "ä¼šå‘˜å¯äº«å—ç§¯åˆ†ã€ä¼˜æƒ åˆ¸ã€ä¸“å±æ´»åŠ¨ç­‰æƒç›Š...",
        }

    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """æœç´¢ç›¸å…³é—®ç­”"""
        results = []
        for question, answer in self.faqs.items():
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            if any(keyword in query for keyword in question):
                results.append({
                    "question": question,
                    "answer": answer,
                    "confidence": 0.8
                })

        return results[:top_k]

# è®¢å•ç³»ç»Ÿ
class OrderSystem:
    """æ¨¡æ‹Ÿè®¢å•ç³»ç»Ÿ"""

    def query_order(self, order_id: str) -> Optional[Dict]:
        """æŸ¥è¯¢è®¢å•"""
        # æ¨¡æ‹Ÿè®¢å•æ•°æ®
        orders = {
            "ORD001": {
                "status": "å·²å‘è´§",
                "tracking_number": "SF1234567890",
                "expected_delivery": "2024-01-15"
            },
            "ORD002": {
                "status": "å¤„ç†ä¸­",
                "tracking_number": None,
                "expected_delivery": "2024-01-18"
            }
        }
        return orders.get(order_id)

# èŠ‚ç‚¹å®ç°
class CustomerServiceNodes:
    def __init__(self):
        self.kb = KnowledgeBase()
        self.order_system = OrderSystem()

    def receive_input(self, state: CustomerServiceState) -> CustomerServiceState:
        """æ¥æ”¶ç”¨æˆ·è¾“å…¥"""
        # è¿™é‡Œå¯ä»¥ä»å®é™…çš„è¾“å…¥æºè·å–
        return {
            "messages": [{
                "role": "user",
                "content": state["user_input"],
                "timestamp": datetime.now().isoformat()
            }]
        }

    def identify_intent(self, state: CustomerServiceState) -> CustomerServiceState:
        """æ„å›¾è¯†åˆ«"""
        user_input = state["user_input"].lower()

        # ç®€å•çš„è§„åˆ™åŒ¹é…ï¼ˆå®é™…åº”ä½¿ç”¨NLPæ¨¡å‹ï¼‰
        if any(word in user_input for word in ["ä½ å¥½", "hello", "hi"]):
            intent = Intent.GREETING
            confidence = 0.95
        elif any(word in user_input for word in ["è®¢å•", "åŒ…è£¹", "å¿«é€’"]):
            intent = Intent.ORDER_QUERY
            confidence = 0.85
            # æå–è®¢å•å·
            entities = self._extract_order_id(user_input)
        elif any(word in user_input for word in ["é€€è´§", "æ¢è´§", "é€€æ¬¾"]):
            intent = Intent.FAQ
            confidence = 0.80
            entities = {"topic": "return_policy"}
        elif any(word in user_input for word in ["æŠ•è¯‰", "ä¸æ»¡æ„", "å·®è¯„"]):
            intent = Intent.COMPLAINT
            confidence = 0.85
            entities = {}
        elif any(word in user_input for word in ["äººå·¥", "å®¢æœ", "è½¬æ¥"]):
            intent = Intent.HUMAN_TRANSFER
            confidence = 0.90
            entities = {}
        else:
            intent = Intent.UNKNOWN
            confidence = 0.3
            entities = {}

        return {
            "intent": intent,
            "intent_confidence": confidence,
            "entities": entities
        }

    def _extract_order_id(self, text: str) -> Dict:
        """æå–è®¢å•å·"""
        import re
        pattern = r'ORD\d+'
        matches = re.findall(pattern, text.upper())
        if matches:
            return {"order_id": matches[0]}
        return {}

    def handle_greeting(self, state: CustomerServiceState) -> CustomerServiceState:
        """å¤„ç†é—®å€™"""
        responses = [
            "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
            "æ¬¢è¿å…‰ä¸´ï¼æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ",
        ]

        return {
            "bot_response": random.choice(responses),
            "conversation_stage": "greeting_completed"
        }

    def query_knowledge_base(self, state: CustomerServiceState) -> CustomerServiceState:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        results = self.kb.search(state["user_input"])

        if results:
            response = f"æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹ä¿¡æ¯ï¼š\n"
            for r in results:
                response += f"\n{r['answer']}"
        else:
            response = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚æ‚¨å¯ä»¥å°è¯•æ¢ä¸ªé—®æ³•ï¼Œæˆ–è€…è½¬æ¥äººå·¥å®¢æœã€‚"

        return {
            "bot_response": response,
            "context": {"kb_results": results}
        }

    def query_order(self, state: CustomerServiceState) -> CustomerServiceState:
        """æŸ¥è¯¢è®¢å•"""
        order_id = state.get("entities", {}).get("order_id")

        if not order_id:
            return {
                "bot_response": "è¯·æä¾›æ‚¨çš„è®¢å•å·ï¼Œæ ¼å¼å¦‚ï¼šORD001",
                "conversation_stage": "waiting_order_id"
            }

        order = self.order_system.query_order(order_id)

        if order:
            response = f"è®¢å• {order_id} ä¿¡æ¯ï¼š\n"
            response += f"çŠ¶æ€ï¼š{order['status']}\n"
            if order['tracking_number']:
                response += f"ç‰©æµå•å·ï¼š{order['tracking_number']}\n"
            response += f"é¢„è®¡é€è¾¾ï¼š{order['expected_delivery']}"
        else:
            response = f"æœªæ‰¾åˆ°è®¢å• {order_id}ï¼Œè¯·æ ¸å¯¹è®¢å•å·æ˜¯å¦æ­£ç¡®ã€‚"

        return {
            "bot_response": response,
            "context": {"order_info": order}
        }

    def handle_complaint(self, state: CustomerServiceState) -> CustomerServiceState:
        """å¤„ç†æŠ•è¯‰"""
        response = "éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ã€‚æ‚¨çš„åé¦ˆå¯¹æˆ‘ä»¬å¾ˆé‡è¦ã€‚\n"
        response += "æˆ‘å·²ç»è®°å½•äº†æ‚¨çš„æŠ•è¯‰ï¼Œå·¥å•å·ï¼šTICKET" + str(random.randint(10000, 99999))
        response += "\næˆ‘ä»¬ä¼šåœ¨24å°æ—¶å†…å¤„ç†å¹¶å›å¤æ‚¨ã€‚"

        return {
            "bot_response": response,
            "conversation_stage": "complaint_recorded"
        }

    def transfer_to_human(self, state: CustomerServiceState) -> CustomerServiceState:
        """è½¬æ¥äººå·¥"""
        response = "æ­£åœ¨ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·ç¨å€™...\n"
        response += "å½“å‰æ’é˜Ÿäººæ•°ï¼š" + str(random.randint(1, 5))
        response += "\né¢„è®¡ç­‰å¾…æ—¶é—´ï¼š2-5åˆ†é’Ÿ"

        return {
            "bot_response": response,
            "needs_human": True,
            "conversation_stage": "waiting_human"
        }

    def generate_response(self, state: CustomerServiceState) -> CustomerServiceState:
        """ç”Ÿæˆæœ€ç»ˆå“åº”"""
        response = state.get("bot_response", "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„é—®é¢˜ã€‚")

        # æ·»åŠ ä¸Šä¸‹æ–‡ç›¸å…³çš„æç¤º
        if state.get("conversation_stage") == "waiting_order_id":
            response += "\n\næ‚¨ä¹Ÿå¯ä»¥ç›´æ¥è¯´'äººå·¥å®¢æœ'è½¬æ¥äººå·¥æœåŠ¡ã€‚"

        return {
            "messages": [{
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now().isoformat()
            }]
        }

    def collect_feedback(self, state: CustomerServiceState) -> CustomerServiceState:
        """æ”¶é›†åé¦ˆ"""
        response = "æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼è¯·ä¸ºæœ¬æ¬¡æœåŠ¡è¯„åˆ†ï¼ˆ1-5åˆ†ï¼‰ï¼š"

        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç­‰å¾…ç”¨æˆ·è¾“å…¥
        satisfaction = random.uniform(3.5, 5.0)

        return {
            "bot_response": response,
            "satisfaction_score": satisfaction,
            "conversation_ended": True
        }

# è·¯ç”±å‡½æ•°
def intent_router(state: CustomerServiceState) -> str:
    """æ ¹æ®æ„å›¾è·¯ç”±"""
    intent = state.get("intent", Intent.UNKNOWN)

    if intent == Intent.GREETING:
        return "greeting"
    elif intent == Intent.FAQ:
        return "knowledge_base"
    elif intent == Intent.ORDER_QUERY:
        return "order_query"
    elif intent == Intent.COMPLAINT:
        return "complaint"
    elif intent == Intent.HUMAN_TRANSFER:
        return "human_transfer"
    else:
        return "knowledge_base"  # é»˜è®¤æŸ¥è¯¢çŸ¥è¯†åº“

def should_continue(state: CustomerServiceState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­å¯¹è¯"""
    if state.get("needs_human"):
        return "human_transfer"
    elif state.get("conversation_ended"):
        return "end"
    elif len(state.get("messages", [])) > 20:  # å¯¹è¯è½®æ¬¡é™åˆ¶
        return "feedback"
    else:
        return "continue"

# åˆ›å»ºå®¢æœç³»ç»Ÿ
def create_customer_service():
    graph = StateGraph(CustomerServiceState)
    nodes = CustomerServiceNodes()

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("receive", nodes.receive_input)
    graph.add_node("intent", nodes.identify_intent)
    graph.add_node("greeting", nodes.handle_greeting)
    graph.add_node("knowledge_base", nodes.query_knowledge_base)
    graph.add_node("order_query", nodes.query_order)
    graph.add_node("complaint", nodes.handle_complaint)
    graph.add_node("human_transfer", nodes.transfer_to_human)
    graph.add_node("response", nodes.generate_response)
    graph.add_node("feedback", nodes.collect_feedback)

    # è®¾ç½®æµç¨‹
    graph.set_entry_point("receive")
    graph.add_edge("receive", "intent")

    # æ„å›¾è·¯ç”±
    graph.add_conditional_edges(
        "intent",
        intent_router,
        {
            "greeting": "greeting",
            "knowledge_base": "knowledge_base",
            "order_query": "order_query",
            "complaint": "complaint",
            "human_transfer": "human_transfer"
        }
    )

    # æ‰€æœ‰å¤„ç†èŠ‚ç‚¹åˆ°å“åº”ç”Ÿæˆ
    for node in ["greeting", "knowledge_base", "order_query", "complaint", "human_transfer"]:
        graph.add_edge(node, "response")

    # å“åº”åçš„è·¯ç”±
    graph.add_conditional_edges(
        "response",
        should_continue,
        {
            "continue": "receive",
            "human_transfer": "human_transfer",
            "feedback": "feedback",
            "end": END
        }
    )

    graph.add_edge("feedback", END)

    # ä½¿ç”¨å†…å­˜ä¿å­˜å¯¹è¯å†å²
    memory = MemorySaver()
    return graph.compile(checkpointer=memory)

# æµ‹è¯•å®¢æœç³»ç»Ÿ
def test_customer_service():
    cs_system = create_customer_service()

    # æ¨¡æ‹Ÿå¯¹è¯
    test_conversations = [
        "ä½ å¥½",
        "æˆ‘æƒ³æŸ¥è¯¢è®¢å•ORD001",
        "é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æˆ‘è¦æŠ•è¯‰ï¼Œäº§å“è´¨é‡å¤ªå·®äº†",
        "è½¬äººå·¥å®¢æœ"
    ]

    config = {"configurable": {"thread_id": "test-session-001"}}
    state = {
        "user_id": "USER123",
        "session_id": "SESSION456",
        "messages": [],
        "context": {}
    }

    print("=" * 50)
    print("æ™ºèƒ½å®¢æœç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)

    for user_input in test_conversations:
        print(f"\nğŸ‘¤ ç”¨æˆ·: {user_input}")
        state["user_input"] = user_input

        result = cs_system.invoke(state, config)
        state.update(result)

        # è·å–æœ€æ–°çš„æœºå™¨äººå“åº”
        bot_messages = [msg for msg in result.get("messages", [])
                       if msg["role"] == "assistant"]
        if bot_messages:
            print(f"ğŸ¤– å®¢æœ: {bot_messages[-1]['content']}")

        if result.get("needs_human"):
            print("\n[ç³»ç»Ÿæç¤º: å·²è½¬æ¥äººå·¥å®¢æœ]")
            break

    print("\n" + "=" * 50)
    print(f"å¯¹è¯ç»“æŸ - æ»¡æ„åº¦è¯„åˆ†: {state.get('satisfaction_score', 'N/A')}")
```

## äºŒã€é¡¹ç›®äºŒï¼šRAG æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ

### 2.1 é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒæ–‡æ¡£å¤„ç†ã€å‘é‡æ£€ç´¢å’Œç­”æ¡ˆç”Ÿæˆã€‚

### 2.2 ç³»ç»Ÿå®ç°

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Optional, Annotated
import operator
import numpy as np
from dataclasses import dataclass

@dataclass
class Document:
    """æ–‡æ¡£ç±»"""
    id: str
    content: str
    metadata: Dict
    embedding: Optional[np.ndarray] = None

class RAGState(TypedDict):
    # æŸ¥è¯¢
    query: str
    query_embedding: Optional[np.ndarray]
    # æ£€ç´¢
    retrieved_docs: List[Document]
    relevance_scores: List[float]
    # ç”Ÿæˆ
    context: str
    answer: str
    # å…ƒæ•°æ®
    sources: List[str]
    confidence: float

class VectorStore:
    """å‘é‡å­˜å‚¨"""

    def __init__(self, dimension=768):
        self.documents = []
        self.embeddings = []
        self.dimension = dimension

    def add_documents(self, documents: List[Document]):
        """æ·»åŠ æ–‡æ¡£"""
        for doc in documents:
            if doc.embedding is None:
                # ç”Ÿæˆæ¨¡æ‹ŸåµŒå…¥
                doc.embedding = np.random.randn(self.dimension)
            self.documents.append(doc)
            self.embeddings.append(doc.embedding)

    def search(self, query_embedding: np.ndarray, top_k: int = 5) -> List[tuple]:
        """å‘é‡æœç´¢"""
        if not self.embeddings:
            return []

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for emb in self.embeddings:
            sim = np.dot(query_embedding, emb) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(emb)
            )
            similarities.append(sim)

        # è·å–top-k
        indices = np.argsort(similarities)[::-1][:top_k]
        results = [(self.documents[i], similarities[i]) for i in indices]

        return results

class RAGPipeline:
    """RAG ç®¡é“"""

    def __init__(self):
        self.vector_store = VectorStore()
        self._load_documents()

    def _load_documents(self):
        """åŠ è½½ç¤ºä¾‹æ–‡æ¡£"""
        docs = [
            Document(
                id="doc1",
                content="LangGraph æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºçŠ¶æ€åŒ–ã€å¤šå‚ä¸è€…åº”ç”¨çš„æ¡†æ¶ã€‚",
                metadata={"source": "docs", "category": "introduction"}
            ),
            Document(
                id="doc2",
                content="StateGraph æ˜¯ LangGraph çš„æ ¸å¿ƒç±»ï¼Œç”¨äºå®šä¹‰å·¥ä½œæµã€‚",
                metadata={"source": "api", "category": "core"}
            ),
            Document(
                id="doc3",
                content="èŠ‚ç‚¹æ˜¯æ‰§è¡Œå…·ä½“é€»è¾‘çš„å•å…ƒï¼Œå¯ä»¥æ˜¯åŒæ­¥æˆ–å¼‚æ­¥å‡½æ•°ã€‚",
                metadata={"source": "guide", "category": "concepts"}
            )
        ]
        self.vector_store.add_documents(docs)

    def embed_query(self, state: RAGState) -> RAGState:
        """ç”ŸæˆæŸ¥è¯¢åµŒå…¥"""
        # æ¨¡æ‹ŸåµŒå…¥ç”Ÿæˆ
        query_embedding = np.random.randn(768)
        return {"query_embedding": query_embedding}

    def retrieve_documents(self, state: RAGState) -> RAGState:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        results = self.vector_store.search(
            state["query_embedding"],
            top_k=3
        )

        retrieved_docs = [doc for doc, _ in results]
        relevance_scores = [score for _, score in results]

        return {
            "retrieved_docs": retrieved_docs,
            "relevance_scores": relevance_scores
        }

    def rerank_documents(self, state: RAGState) -> RAGState:
        """é‡æ’åºæ–‡æ¡£"""
        # åŸºäºç›¸å…³æ€§åˆ†æ•°å’Œå…¶ä»–å› ç´ é‡æ’åº
        docs_with_scores = zip(
            state["retrieved_docs"],
            state["relevance_scores"]
        )

        # ç®€å•çš„é‡æ’åºé€»è¾‘
        reranked = sorted(
            docs_with_scores,
            key=lambda x: x[1],
            reverse=True
        )

        retrieved_docs = [doc for doc, _ in reranked]
        relevance_scores = [score for _, score in reranked]

        return {
            "retrieved_docs": retrieved_docs,
            "relevance_scores": relevance_scores
        }

    def build_context(self, state: RAGState) -> RAGState:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        context_parts = []
        sources = []

        for doc in state["retrieved_docs"][:3]:  # ä½¿ç”¨å‰3ä¸ªæ–‡æ¡£
            context_parts.append(doc.content)
            sources.append(doc.metadata.get("source", "unknown"))

        context = "\n\n".join(context_parts)

        return {
            "context": context,
            "sources": sources
        }

    def generate_answer(self, state: RAGState) -> RAGState:
        """ç”Ÿæˆç­”æ¡ˆ"""
        # æ¨¡æ‹Ÿç­”æ¡ˆç”Ÿæˆ
        prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{state['context']}

é—®é¢˜ï¼š{state['query']}

ç­”æ¡ˆï¼š"""

        # è¿™é‡Œåº”è¯¥è°ƒç”¨ LLM
        answer = f"æ ¹æ®æ–‡æ¡£å†…å®¹ï¼Œ{state['query']} çš„ç­”æ¡ˆæ˜¯ï¼š[åŸºäºä¸Šä¸‹æ–‡çš„å›ç­”]"

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = np.mean(state["relevance_scores"][:3])

        return {
            "answer": answer,
            "confidence": float(confidence)
        }

    def validate_answer(self, state: RAGState) -> RAGState:
        """éªŒè¯ç­”æ¡ˆ"""
        # æ£€æŸ¥ç­”æ¡ˆè´¨é‡
        if state["confidence"] < 0.5:
            state["answer"] = "æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°è¶³å¤Ÿç›¸å…³çš„ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"

        return state

# åˆ›å»º RAG ç³»ç»Ÿ
def create_rag_system():
    graph = StateGraph(RAGState)
    pipeline = RAGPipeline()

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("embed", pipeline.embed_query)
    graph.add_node("retrieve", pipeline.retrieve_documents)
    graph.add_node("rerank", pipeline.rerank_documents)
    graph.add_node("context", pipeline.build_context)
    graph.add_node("generate", pipeline.generate_answer)
    graph.add_node("validate", pipeline.validate_answer)

    # è¿æ¥èŠ‚ç‚¹
    graph.set_entry_point("embed")
    graph.add_edge("embed", "retrieve")
    graph.add_edge("retrieve", "rerank")
    graph.add_edge("rerank", "context")
    graph.add_edge("context", "generate")
    graph.add_edge("generate", "validate")
    graph.add_edge("validate", END)

    return graph.compile()

# æµ‹è¯• RAG ç³»ç»Ÿ
def test_rag_system():
    rag = create_rag_system()

    queries = [
        "ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ",
        "StateGraph çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
        "èŠ‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]

    for query in queries:
        print(f"\né—®é¢˜: {query}")
        result = rag.invoke({"query": query})
        print(f"ç­”æ¡ˆ: {result['answer']}")
        print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}")
        print(f"æ¥æº: {result['sources']}")
```

## ä¸‰ã€é¡¹ç›®ä¸‰ï¼šå·¥ä½œæµè‡ªåŠ¨åŒ–å¼•æ“

### 3.1 é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªçµæ´»çš„å·¥ä½œæµè‡ªåŠ¨åŒ–å¼•æ“ï¼Œæ”¯æŒåŠ¨æ€å·¥ä½œæµå®šä¹‰ã€æ¡ä»¶åˆ†æ”¯å’Œå¹¶è¡Œæ‰§è¡Œã€‚

### 3.2 ç³»ç»Ÿå®ç°

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any, Optional
import yaml
import json
from datetime import datetime
import asyncio

class WorkflowState(TypedDict):
    workflow_id: str
    workflow_definition: Dict
    current_step: str
    completed_steps: List[str]
    step_results: Dict[str, Any]
    variables: Dict[str, Any]
    status: str  # running, completed, failed
    error: Optional[str]

class WorkflowEngine:
    """å·¥ä½œæµå¼•æ“"""

    def __init__(self):
        self.registered_actions = self._register_actions()

    def _register_actions(self) -> Dict:
        """æ³¨å†Œå¯ç”¨çš„åŠ¨ä½œ"""
        return {
            "http_request": self.action_http_request,
            "database_query": self.action_database_query,
            "file_operation": self.action_file_operation,
            "data_transform": self.action_data_transform,
            "notification": self.action_notification,
            "approval": self.action_approval
        }

    async def action_http_request(self, params: Dict) -> Dict:
        """HTTP è¯·æ±‚åŠ¨ä½œ"""
        # æ¨¡æ‹Ÿ HTTP è¯·æ±‚
        return {
            "status_code": 200,
            "response": {"data": "mock response"},
            "timestamp": datetime.now().isoformat()
        }

    async def action_database_query(self, params: Dict) -> Dict:
        """æ•°æ®åº“æŸ¥è¯¢åŠ¨ä½œ"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        return {
            "rows": [
                {"id": 1, "name": "Item 1"},
                {"id": 2, "name": "Item 2"}
            ],
            "count": 2
        }

    async def action_file_operation(self, params: Dict) -> Dict:
        """æ–‡ä»¶æ“ä½œåŠ¨ä½œ"""
        operation = params.get("operation", "read")
        if operation == "read":
            return {"content": "file content"}
        elif operation == "write":
            return {"success": True, "bytes_written": 100}
        return {"error": "Unknown operation"}

    async def action_data_transform(self, params: Dict) -> Dict:
        """æ•°æ®è½¬æ¢åŠ¨ä½œ"""
        transform_type = params.get("type", "json")
        data = params.get("data", {})

        if transform_type == "json":
            return {"transformed": json.dumps(data)}
        elif transform_type == "csv":
            return {"transformed": "csv data"}
        return {"error": "Unknown transform type"}

    async def action_notification(self, params: Dict) -> Dict:
        """å‘é€é€šçŸ¥åŠ¨ä½œ"""
        return {
            "sent": True,
            "channel": params.get("channel", "email"),
            "recipient": params.get("to", "user@example.com")
        }

    async def action_approval(self, params: Dict) -> Dict:
        """å®¡æ‰¹åŠ¨ä½œ"""
        # æ¨¡æ‹Ÿå®¡æ‰¹æµç¨‹
        return {
            "approved": True,
            "approver": "manager@example.com",
            "comments": "Approved automatically for testing"
        }

    def load_workflow(self, state: WorkflowState) -> WorkflowState:
        """åŠ è½½å·¥ä½œæµå®šä¹‰"""
        # ç¤ºä¾‹å·¥ä½œæµå®šä¹‰
        workflow_def = {
            "name": "æ•°æ®å¤„ç†æµç¨‹",
            "version": "1.0",
            "steps": [
                {
                    "id": "fetch_data",
                    "type": "http_request",
                    "params": {
                        "url": "https://api.example.com/data",
                        "method": "GET"
                    },
                    "next": "transform_data"
                },
                {
                    "id": "transform_data",
                    "type": "data_transform",
                    "params": {
                        "type": "json"
                    },
                    "next": "check_data"
                },
                {
                    "id": "check_data",
                    "type": "condition",
                    "condition": "len(data) > 0",
                    "true_branch": "process_data",
                    "false_branch": "notify_empty"
                },
                {
                    "id": "process_data",
                    "type": "database_query",
                    "params": {
                        "query": "INSERT INTO processed_data"
                    },
                    "next": "notify_success"
                },
                {
                    "id": "notify_empty",
                    "type": "notification",
                    "params": {
                        "channel": "email",
                        "message": "No data to process"
                    },
                    "next": "end"
                },
                {
                    "id": "notify_success",
                    "type": "notification",
                    "params": {
                        "channel": "email",
                        "message": "Processing completed"
                    },
                    "next": "end"
                }
            ]
        }

        return {
            "workflow_definition": workflow_def,
            "current_step": workflow_def["steps"][0]["id"]
        }

    async def execute_step(self, state: WorkflowState) -> WorkflowState:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        current_step_id = state["current_step"]
        workflow_def = state["workflow_definition"]

        # æŸ¥æ‰¾å½“å‰æ­¥éª¤
        current_step = None
        for step in workflow_def["steps"]:
            if step["id"] == current_step_id:
                current_step = step
                break

        if not current_step:
            return {
                "status": "failed",
                "error": f"Step {current_step_id} not found"
            }

        step_type = current_step.get("type")

        # æ‰§è¡ŒåŠ¨ä½œ
        if step_type in self.registered_actions:
            action = self.registered_actions[step_type]
            params = current_step.get("params", {})

            # å˜é‡æ›¿æ¢
            params = self._substitute_variables(params, state["variables"])

            try:
                result = await action(params)
                return {
                    "completed_steps": [current_step_id],
                    "step_results": {current_step_id: result},
                    "variables": {**state["variables"], f"{current_step_id}_result": result}
                }
            except Exception as e:
                return {
                    "status": "failed",
                    "error": f"Step {current_step_id} failed: {str(e)}"
                }
        elif step_type == "condition":
            # å¤„ç†æ¡ä»¶åˆ†æ”¯
            condition = current_step.get("condition")
            result = self._evaluate_condition(condition, state["variables"])

            next_step = (
                current_step.get("true_branch") if result
                else current_step.get("false_branch")
            )

            return {
                "current_step": next_step,
                "completed_steps": [current_step_id]
            }

        return state

    def _substitute_variables(self, params: Dict, variables: Dict) -> Dict:
        """å˜é‡æ›¿æ¢"""
        result = {}
        for key, value in params.items():
            if isinstance(value, str) and value.startswith("${"):
                var_name = value[2:-1]
                result[key] = variables.get(var_name, value)
            else:
                result[key] = value
        return result

    def _evaluate_condition(self, condition: str, variables: Dict) -> bool:
        """è¯„ä¼°æ¡ä»¶"""
        try:
            # ç®€å•çš„æ¡ä»¶è¯„ä¼°ï¼ˆå®é™…åº”ä½¿ç”¨å®‰å…¨çš„è¡¨è¾¾å¼è¯„ä¼°ï¼‰
            return eval(condition, {"__builtins__": {}}, variables)
        except:
            return False

    def determine_next_step(self, state: WorkflowState) -> WorkflowState:
        """ç¡®å®šä¸‹ä¸€æ­¥"""
        current_step_id = state.get("current_step")
        workflow_def = state["workflow_definition"]

        # æŸ¥æ‰¾å½“å‰æ­¥éª¤
        for step in workflow_def["steps"]:
            if step["id"] == current_step_id:
                next_step = step.get("next")
                if next_step == "end":
                    return {"status": "completed"}
                elif next_step:
                    return {"current_step": next_step}
                break

        return {"status": "completed"}

# åˆ›å»ºå·¥ä½œæµå¼•æ“
def create_workflow_engine():
    graph = StateGraph(WorkflowState)
    engine = WorkflowEngine()

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("load", engine.load_workflow)
    graph.add_node("execute", engine.execute_step)
    graph.add_node("next", engine.determine_next_step)
    graph.add_node("complete", lambda s: {**s, "status": "completed"})

    # å®šä¹‰æµç¨‹
    graph.set_entry_point("load")
    graph.add_edge("load", "execute")
    graph.add_edge("execute", "next")

    # æ¡ä»¶è·¯ç”±
    def route_next(state: WorkflowState) -> str:
        if state.get("status") == "completed":
            return "complete"
        elif state.get("status") == "failed":
            return "complete"
        else:
            return "execute"

    graph.add_conditional_edges(
        "next",
        route_next,
        {
            "execute": "execute",
            "complete": "complete"
        }
    )

    graph.add_edge("complete", END)

    return graph.compile()

# æµ‹è¯•å·¥ä½œæµå¼•æ“
async def test_workflow_engine():
    engine = create_workflow_engine()

    initial_state = {
        "workflow_id": "WF001",
        "completed_steps": [],
        "step_results": {},
        "variables": {},
        "status": "running"
    }

    print("=" * 50)
    print("å·¥ä½œæµå¼•æ“æµ‹è¯•")
    print("=" * 50)

    result = await engine.ainvoke(initial_state)

    print(f"\nå·¥ä½œæµçŠ¶æ€: {result['status']}")
    print(f"å®Œæˆçš„æ­¥éª¤: {result['completed_steps']}")
    print(f"æ­¥éª¤ç»“æœ: {json.dumps(result['step_results'], indent=2)}")

if __name__ == "__main__":
    # æµ‹è¯•å„ä¸ªç³»ç»Ÿ
    print("\n" + "="*60)
    print("æµ‹è¯•æ™ºèƒ½å®¢æœç³»ç»Ÿ")
    print("="*60)
    test_customer_service()

    print("\n" + "="*60)
    print("æµ‹è¯• RAG ç³»ç»Ÿ")
    print("="*60)
    test_rag_system()

    print("\n" + "="*60)
    print("æµ‹è¯•å·¥ä½œæµå¼•æ“")
    print("="*60)
    asyncio.run(test_workflow_engine())
```

## å››ã€é¡¹ç›®æ€»ç»“

### 4.1 é¡¹ç›®å¯¹æ¯”

| ç‰¹æ€§ | æ™ºèƒ½å®¢æœ | RAGç³»ç»Ÿ | å·¥ä½œæµå¼•æ“ |
|------|---------|---------|-----------|
| **å¤æ‚åº¦** | ä¸­é«˜ | ä¸­ | é«˜ |
| **æ ¸å¿ƒæŠ€æœ¯** | æ„å›¾è¯†åˆ«ã€å¤šè½®å¯¹è¯ | å‘é‡æ£€ç´¢ã€æ–‡æœ¬ç”Ÿæˆ | åŠ¨æ€æ‰§è¡Œã€æ¡ä»¶åˆ†æ”¯ |
| **çŠ¶æ€ç®¡ç†** | å¯¹è¯å†å²ã€ä¸Šä¸‹æ–‡ | æŸ¥è¯¢ã€æ–‡æ¡£ã€ç­”æ¡ˆ | æ­¥éª¤ã€ç»“æœã€å˜é‡ |
| **æ‰©å±•æ€§** | æ˜“äºæ·»åŠ æ„å›¾ | æ˜“äºæ·»åŠ æ–‡æ¡£æº | æ˜“äºæ·»åŠ åŠ¨ä½œ |
| **åº”ç”¨åœºæ™¯** | å®¢æˆ·æœåŠ¡ | çŸ¥è¯†é—®ç­” | æµç¨‹è‡ªåŠ¨åŒ– |

### 4.2 æœ€ä½³å®è·µ

1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†åŠŸèƒ½åˆ†è§£ä¸ºç‹¬ç«‹çš„èŠ‚ç‚¹
2. **é”™è¯¯å¤„ç†**ï¼šæ¯ä¸ªèŠ‚ç‚¹éƒ½è¦è€ƒè™‘å¼‚å¸¸æƒ…å†µ
3. **çŠ¶æ€è®¾è®¡**ï¼šåˆç†åˆ’åˆ†çŠ¶æ€å­—æ®µ
4. **æµ‹è¯•è¦†ç›–**ï¼šç¼–å†™å…¨é¢çš„æµ‹è¯•ç”¨ä¾‹
5. **æ–‡æ¡£å®Œå–„**ï¼šä¿æŒä»£ç å’Œæ–‡æ¡£åŒæ­¥

### 4.3 æ‰©å±•å»ºè®®

1. **æ™ºèƒ½å®¢æœ**ï¼š
   - é›†æˆçœŸå®çš„ NLP æ¨¡å‹
   - æ·»åŠ å¤šè¯­è¨€æ”¯æŒ
   - å®ç°æƒ…æ„Ÿåˆ†æ

2. **RAG ç³»ç»Ÿ**ï¼š
   - ä½¿ç”¨çœŸå®çš„å‘é‡æ•°æ®åº“
   - é›†æˆ LLM è¿›è¡Œç”Ÿæˆ
   - æ·»åŠ æ–‡æ¡£æ›´æ–°æœºåˆ¶

3. **å·¥ä½œæµå¼•æ“**ï¼š
   - æ”¯æŒå¹¶è¡Œæ­¥éª¤
   - æ·»åŠ å›æ»šæœºåˆ¶
   - å®ç°å¯è§†åŒ–ç¼–è¾‘å™¨

---

**ä¸‹ä¸€æ­¥ï¼š** å­¦ä¹  [08.æµ‹è¯•ä¸è°ƒè¯•](./08.æµ‹è¯•ä¸è°ƒè¯•) æŒæ¡æµ‹è¯•å’Œè°ƒè¯•æŠ€å·§ï¼