---
title: LangGraph çŠ¶æ€ç®¡ç†è¯¦è§£
date: 2025-01-30
permalink: /ai/langgraph/state-management.html
categories:
  - AI
  - LangGraph
---

# LangGraph çŠ¶æ€ç®¡ç†è¯¦è§£

## ä¸€ã€çŠ¶æ€ç®¡ç†æ¦‚è¿°

çŠ¶æ€ç®¡ç†æ˜¯ LangGraph çš„æ ¸å¿ƒæœºåˆ¶ï¼Œå†³å®šäº†æ•°æ®å¦‚ä½•åœ¨èŠ‚ç‚¹é—´æµè½¬å’Œæ›´æ–°ã€‚

```mermaid
graph LR
    A[åˆå§‹çŠ¶æ€] --> B[èŠ‚ç‚¹1å¤„ç†]
    B --> C[çŠ¶æ€æ›´æ–°]
    C --> D[èŠ‚ç‚¹2å¤„ç†]
    D --> E[çŠ¶æ€åˆå¹¶]
    E --> F[æœ€ç»ˆçŠ¶æ€]

    style C fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#f9f,stroke:#333,stroke-width:2px
```

## äºŒã€çŠ¶æ€å®šä¹‰æ–¹å¼å¯¹æ¯”

### 2.1 TypedDict vs Pydantic é€‰æ‹©æŒ‡å—

```mermaid
graph TD
    A[é€‰æ‹©çŠ¶æ€å®šä¹‰æ–¹å¼] --> B{æ˜¯å¦éœ€è¦æ•°æ®éªŒè¯?}
    B -->|æ˜¯| C{éªŒè¯å¤æ‚åº¦?}
    B -->|å¦| D[TypedDict]

    C -->|ç®€å•ç±»å‹æ£€æŸ¥| D
    C -->|å¤æ‚ä¸šåŠ¡è§„åˆ™| E[Pydantic]

    D --> F{æ˜¯å¦éœ€è¦åºåˆ—åŒ–?}
    F -->|å¦| G[TypedDict æœ€ä½³é€‰æ‹©]
    F -->|æ˜¯| H{åºåˆ—åŒ–å¤æ‚åº¦?}

    H -->|ç®€å•| I[TypedDict + æ‰‹åŠ¨åºåˆ—åŒ–]
    H -->|å¤æ‚| E

    E --> J{æ€§èƒ½æ•æ„Ÿ?}
    J -->|æ˜¯| K[è¯„ä¼°æ€§èƒ½å¼€é”€]
    J -->|å¦| L[Pydantic æœ€ä½³é€‰æ‹©]

    style G fill:#90EE90
    style L fill:#90EE90
    style K fill:#FFB6C1
```

### 2.2 TypedDict æ–¹å¼

**é€‚ç”¨åœºæ™¯ï¼š**
- âœ… ç®€å•çš„æ•°æ®ç»“æ„ï¼Œä¸»è¦ç”¨äºç±»å‹æç¤º
- âœ… æ€§èƒ½æ•æ„Ÿçš„åº”ç”¨ï¼ˆé›¶è¿è¡Œæ—¶å¼€é”€ï¼‰
- âœ… å¿«é€ŸåŸå‹å¼€å‘
- âœ… ä¸ç°æœ‰å­—å…¸ä»£ç é›†æˆ
- âœ… ä¸éœ€è¦å¤æ‚éªŒè¯çš„åœºæ™¯

**ä¼˜ç‚¹ï¼š**
- ğŸš€ é›¶è¿è¡Œæ—¶æ€§èƒ½å¼€é”€
- ğŸ“¦ è½»é‡çº§ï¼Œæ— é¢å¤–ä¾èµ–
- ğŸ”§ ä¸æ ‡å‡† Python å­—å…¸å®Œå…¨å…¼å®¹
- ğŸ’¡ ç®€å•æ˜“ç”¨ï¼Œå­¦ä¹ æˆæœ¬ä½

**ç¼ºç‚¹ï¼š**
- âŒ ä»…æä¾›é™æ€ç±»å‹æ£€æŸ¥ï¼Œæ— è¿è¡Œæ—¶éªŒè¯
- âŒ ä¸æ”¯æŒæ•°æ®éªŒè¯é€»è¾‘
- âŒ éœ€è¦æ‰‹åŠ¨å¤„ç†åºåˆ—åŒ–/ååºåˆ—åŒ–
- âŒ ç¼ºå°‘é»˜è®¤å€¼å’Œå­—æ®µçº¦æŸ

**ç¤ºä¾‹ï¼š**

```python
from typing import TypedDict, List, Dict, Optional

# ç®€å•çŠ¶æ€ - é€‚åˆè½»é‡çº§åº”ç”¨
class SimpleState(TypedDict):
    message: str
    count: int
    active: bool

# åµŒå¥—çŠ¶æ€ - é€‚åˆæ˜ç¡®ç»“æ„çš„åœºæ™¯
class UserInfo(TypedDict):
    name: str
    email: str
    age: int

class ComplexState(TypedDict):
    user: UserInfo
    messages: List[str]
    metadata: Dict[str, any]
    error: Optional[str]

# å®æˆ˜ç¤ºä¾‹ï¼šèŠå¤©æœºå™¨äººçŠ¶æ€
class ChatState(TypedDict):
    """é€‚åˆå¿«é€Ÿå¼€å‘çš„èŠå¤©çŠ¶æ€"""
    session_id: str
    messages: List[Dict[str, str]]  # [{"role": "user", "content": "..."}]
    context: Dict[str, any]
    response: Optional[str]

def chat_node(state: ChatState) -> ChatState:
    """å¤„ç†èŠå¤© - ç®€å•ç›´æ¥"""
    messages = state["messages"]
    # è°ƒç”¨ LLM
    response = llm.invoke(messages)

    return {
        "response": response,
        "messages": messages + [{"role": "assistant", "content": response}]
    }
```

### 2.3 Pydantic æ–¹å¼

**é€‚ç”¨åœºæ™¯ï¼š**
- âœ… éœ€è¦å¼ºæ•°æ®éªŒè¯çš„ç”Ÿäº§ç¯å¢ƒ
- âœ… å¤æ‚çš„ä¸šåŠ¡è§„åˆ™å’Œçº¦æŸ
- âœ… API æ¥å£æ•°æ®éªŒè¯
- âœ… éœ€è¦åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼ˆJSONã€æ•°æ®åº“ç­‰ï¼‰
- âœ… å¤šå›¢é˜Ÿåä½œï¼Œéœ€è¦ä¸¥æ ¼æ•°æ®å¥‘çº¦
- âœ… å¤–éƒ¨æ•°æ®æºé›†æˆï¼ˆéœ€è¦éªŒè¯è¾“å…¥ï¼‰

**ä¼˜ç‚¹ï¼š**
- âœ… å¼ºå¤§çš„è¿è¡Œæ—¶æ•°æ®éªŒè¯
- âœ… è‡ªåŠ¨ç±»å‹è½¬æ¢å’Œå¼ºåˆ¶
- âœ… ä¸°å¯Œçš„å­—æ®µçº¦æŸï¼ˆèŒƒå›´ã€æ­£åˆ™ã€è‡ªå®šä¹‰éªŒè¯ï¼‰
- âœ… å†…ç½®åºåˆ—åŒ–/ååºåˆ—åŒ–
- âœ… ä¼˜ç§€çš„é”™è¯¯æ¶ˆæ¯
- âœ… æ”¯æŒé»˜è®¤å€¼å·¥å‚

**ç¼ºç‚¹ï¼š**
- âš ï¸ æœ‰è¿è¡Œæ—¶æ€§èƒ½å¼€é”€ï¼ˆéªŒè¯éœ€è¦æ—¶é—´ï¼‰
- âš ï¸ é¢å¤–çš„ä¾èµ–ï¼ˆpydantic åº“ï¼‰
- âš ï¸ å­¦ä¹ æ›²çº¿ç¨é™¡
- âš ï¸ å¯èƒ½è¿‡åº¦è®¾è®¡ç®€å•åœºæ™¯

**ç¤ºä¾‹ï¼š**

```python
from pydantic import BaseModel, Field, validator, root_validator
from typing import List, Optional, Dict
from datetime import datetime
from enum import Enum

class MessageRole(str, Enum):
    """æ¶ˆæ¯è§’è‰²"""
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"

class Message(BaseModel):
    """å•æ¡æ¶ˆæ¯ - ä¸¥æ ¼éªŒè¯"""
    role: MessageRole
    content: str = Field(..., min_length=1, max_length=10000)
    timestamp: datetime = Field(default_factory=datetime.now)

    @validator('content')
    def validate_content(cls, v):
        """è‡ªå®šä¹‰å†…å®¹éªŒè¯"""
        if v.strip() == "":
            raise ValueError('æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©ºç™½')
        return v.strip()

class PydanticChatState(BaseModel):
    """ç”Ÿäº§çº§èŠå¤©çŠ¶æ€ - å®Œæ•´éªŒè¯"""

    session_id: str = Field(..., regex=r'^[a-zA-Z0-9-]+$')
    user_id: str = Field(..., description="ç”¨æˆ·å”¯ä¸€æ ‡è¯†")

    messages: List[Message] = Field(default_factory=list, max_items=1000)

    # å…ƒæ•°æ®éªŒè¯
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: int = Field(default=2000, gt=0, le=32000)

    # çŠ¶æ€æ ‡è®°
    is_completed: bool = Field(default=False)
    error: Optional[str] = Field(None, max_length=500)

    # ç»Ÿè®¡ä¿¡æ¯
    token_usage: Dict[str, int] = Field(default_factory=lambda: {
        "prompt_tokens": 0,
        "completion_tokens": 0,
        "total_tokens": 0
    })

    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)

    @validator('messages')
    def validate_message_count(cls, v):
        """éªŒè¯æ¶ˆæ¯æ•°é‡"""
        if len(v) > 100:
            raise ValueError('å•æ¬¡ä¼šè¯æ¶ˆæ¯ä¸èƒ½è¶…è¿‡100æ¡')
        return v

    @root_validator
    def validate_state(cls, values):
        """å…¨å±€çŠ¶æ€éªŒè¯"""
        if values.get('is_completed') and not values.get('messages'):
            raise ValueError('å®ŒæˆçŠ¶æ€å¿…é¡»åŒ…å«æ¶ˆæ¯')
        return values

    class Config:
        # åºåˆ—åŒ–é…ç½®
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }
        # å…è®¸ä»»æ„ç±»å‹ï¼ˆç”¨äº LangGraph é›†æˆï¼‰
        arbitrary_types_allowed = True

def validated_chat_node(state: Dict) -> Dict:
    """å¸¦éªŒè¯çš„èŠå¤©èŠ‚ç‚¹"""
    try:
        # éªŒè¯è¾“å…¥çŠ¶æ€
        validated_state = PydanticChatState(**state)

        # ä¸šåŠ¡é€»è¾‘
        new_message = Message(
            role=MessageRole.ASSISTANT,
            content="è¿™æ˜¯å›å¤"
        )

        validated_state.messages.append(new_message)
        validated_state.updated_at = datetime.now()

        # è½¬å›å­—å…¸
        return validated_state.dict()

    except ValidationError as e:
        # è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        return {
            "error": str(e),
            "is_completed": True
        }
```

### 2.4 åœºæ™¯å¯¹æ¯”è¯¦è§£

#### åœºæ™¯1ï¼šå¿«é€ŸåŸå‹å¼€å‘

```python
# âœ… æ¨èï¼šTypedDict - å¿«é€Ÿç®€å•
class PrototypeState(TypedDict):
    query: str
    result: Optional[str]

# âŒ è¿‡åº¦è®¾è®¡ï¼šPydantic - å¢åŠ å¤æ‚åº¦
class OverengineeredState(BaseModel):
    query: str = Field(..., min_length=1)
    result: Optional[str] = None
```

#### åœºæ™¯2ï¼šç”Ÿäº§ç¯å¢ƒ API

```python
# âŒ ä¸æ¨èï¼šTypedDict - ç¼ºå°‘éªŒè¯
class WeakAPIState(TypedDict):
    user_input: str  # å¯èƒ½åŒ…å«æ¶æ„å†…å®¹
    score: float     # å¯èƒ½è¶…å‡ºèŒƒå›´

# âœ… æ¨èï¼šPydantic - ä¸¥æ ¼éªŒè¯
class SecureAPIState(BaseModel):
    user_input: str = Field(..., max_length=1000, regex=r'^[a-zA-Z0-9\s]+$')
    score: float = Field(..., ge=0.0, le=1.0)

    @validator('user_input')
    def sanitize_input(cls, v):
        # XSS é˜²æŠ¤
        return html.escape(v.strip())
```

#### åœºæ™¯3ï¼šé«˜æ€§èƒ½æ‰¹å¤„ç†

```python
# âœ… æ¨èï¼šTypedDict - é›¶å¼€é”€
class BatchState(TypedDict):
    items: List[Dict[str, any]]
    processed_count: int

# å¤„ç† 100ä¸‡æ¡è®°å½•æ—¶ï¼ŒTypedDict å‡ ä¹æ— æ€§èƒ½å½±å“
# Pydantic æ¯æ¬¡éªŒè¯éƒ½æœ‰å¼€é”€

# âš ï¸ å¦‚æœç¡®éœ€ Pydanticï¼Œä½¿ç”¨æ€§èƒ½ä¼˜åŒ–
class OptimizedBatchState(BaseModel):
    items: List[Dict[str, any]]
    processed_count: int

    class Config:
        # è·³è¿‡éªŒè¯ï¼ˆä»…åœ¨ç¡®ä¿¡æ•°æ®å®‰å…¨æ—¶ï¼‰
        validate_assignment = False
```

#### åœºæ™¯4ï¼šå¤–éƒ¨æ•°æ®é›†æˆ

```python
# âŒ ä¸æ¨èï¼šTypedDict - æ— æ³•å¤„ç†è„æ•°æ®
class UnsafeIntegrationState(TypedDict):
    external_data: Dict  # æœªçŸ¥ç»“æ„
    timestamp: str       # å¯èƒ½æ ¼å¼ä¸å¯¹

# âœ… æ¨èï¼šPydantic - è‡ªåŠ¨è½¬æ¢å’ŒéªŒè¯
class SafeIntegrationState(BaseModel):
    external_data: Dict
    timestamp: datetime

    @validator('timestamp', pre=True)
    def parse_timestamp(cls, v):
        """å¤„ç†å¤šç§æ—¶é—´æ ¼å¼"""
        if isinstance(v, str):
            # å°è¯•å¤šç§æ ¼å¼
            for fmt in ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y-%m-%dT%H:%M:%S']:
                try:
                    return datetime.strptime(v, fmt)
                except ValueError:
                    continue
            raise ValueError(f'æ— æ³•è§£ææ—¶é—´: {v}')
        return v
```

### 2.5 æ€§èƒ½å¯¹æ¯”

```python
import time
from typing import TypedDict
from pydantic import BaseModel

# TypedDict ç‰ˆæœ¬
class TypedDictState(TypedDict):
    value: int
    name: str

# Pydantic ç‰ˆæœ¬
class PydanticState(BaseModel):
    value: int
    name: str

# æ€§èƒ½æµ‹è¯•
def benchmark():
    iterations = 100000

    # TypedDict - é›¶å¼€é”€
    start = time.time()
    for i in range(iterations):
        state = {"value": i, "name": f"item_{i}"}
    typeddict_time = time.time() - start

    # Pydantic - æœ‰éªŒè¯å¼€é”€
    start = time.time()
    for i in range(iterations):
        state = PydanticState(value=i, name=f"item_{i}")
    pydantic_time = time.time() - start

    print(f"TypedDict: {typeddict_time:.3f}s")
    print(f"Pydantic:  {pydantic_time:.3f}s")
    print(f"Pydantic æ…¢ {pydantic_time/typeddict_time:.1f}x")

# å…¸å‹ç»“æœï¼š
# TypedDict: 0.012s
# Pydantic:  0.156s
# Pydantic æ…¢ 13.0x
```

### 2.6 æ··åˆä½¿ç”¨ç­–ç•¥

```python
from typing import TypedDict, Annotated
from pydantic import BaseModel, Field

# ç­–ç•¥1ï¼šå¤–å±‚ç”¨ TypedDictï¼Œå†…éƒ¨å…³é”®æ•°æ®ç”¨ Pydantic
class UserInput(BaseModel):
    """ä»…éªŒè¯ç”¨æˆ·è¾“å…¥"""
    query: str = Field(..., min_length=1, max_length=500)
    max_results: int = Field(default=10, ge=1, le=100)

class HybridState(TypedDict):
    """ä¸»çŠ¶æ€ç”¨ TypedDict ä¿æŒæ€§èƒ½"""
    user_input: UserInput  # å…³é”®éƒ¨åˆ†ç”¨ Pydantic
    results: List[Dict]    # å†…éƒ¨æ•°æ®ç”¨å­—å…¸
    cache: Dict[str, any]  # ç¼“å­˜ä¸éœ€éªŒè¯

# ç­–ç•¥2ï¼šå¼€å‘ç”¨ TypedDictï¼Œç”Ÿäº§åˆ‡æ¢ Pydantic
if ENVIRONMENT == "development":
    class AppState(TypedDict):
        data: Dict
        count: int
else:
    class AppState(BaseModel):
        data: Dict
        count: int = Field(..., ge=0)
```

### 2.7 é€‰æ‹©å»ºè®®æ€»ç»“

| åœºæ™¯ | æ¨èæ–¹å¼ | åŸå›  |
|------|---------|------|
| å¿«é€ŸåŸå‹ | TypedDict | ç®€å•å¿«é€Ÿï¼Œé›¶å¼€é”€ |
| ç”Ÿäº§ç¯å¢ƒ | Pydantic | ä¸¥æ ¼éªŒè¯ï¼Œå‡å°‘ Bug |
| é«˜æ€§èƒ½æ‰¹å¤„ç† | TypedDict | æ€§èƒ½å…³é”® |
| API æ¥å£ | Pydantic | æ•°æ®éªŒè¯å¿…éœ€ |
| å†…éƒ¨å·¥å…· | TypedDict | ç®€å•å¤Ÿç”¨ |
| å¤–éƒ¨é›†æˆ | Pydantic | å¤„ç†è„æ•°æ® |
| å›¢é˜Ÿåä½œ | Pydantic | æ˜ç¡®æ•°æ®å¥‘çº¦ |
| ä¸ªäººé¡¹ç›® | TypedDict | çµæ´»ä¾¿æ· |

**ä¸€å¥è¯æ€»ç»“ï¼š**
- ğŸ¯ **ç®€å•åœºæ™¯ç”¨ TypedDictï¼Œå¤æ‚åœºæ™¯ç”¨ Pydantic**
- ğŸ¯ **å†…éƒ¨å¯æ§ç”¨ TypedDictï¼Œå¤–éƒ¨è¾“å…¥ç”¨ Pydantic**
- ğŸ¯ **æ€§èƒ½ä¼˜å…ˆç”¨ TypedDictï¼Œå®‰å…¨ä¼˜å…ˆç”¨ Pydantic**

### 2.8 ä¸ Reducer ç»“åˆä½¿ç”¨

```python
from typing import TypedDict, Annotated
import operator

class HybridState(TypedDict):
    """æ··åˆä½¿ç”¨ä¸åŒçš„çŠ¶æ€ç®¡ç†æ–¹å¼"""

    # æ™®é€šå­—æ®µ
    user_id: str

    # å¸¦ Reducer çš„å­—æ®µ
    messages: Annotated[List[str], operator.add]

    # è‡ªå®šä¹‰ Reducer
    latest_action: Annotated[str, lambda x, y: y]

    # å¤æ‚ Reducer
    stats: Annotated[Dict[str, int], lambda old, new: {
        **old,
        **new,
        "total": old.get("total", 0) + new.get("count", 0)
    }]
```

## ä¸‰ã€Reducer æœºåˆ¶è¯¦è§£

### 3.1 å†…ç½® Reducer

```python
import operator
from typing import Annotated

class BuiltinReducers(TypedDict):
    # åŠ æ³•ï¼ˆåˆ—è¡¨è¿æ¥ã€æ•°å­—ç›¸åŠ ï¼‰
    concat_list: Annotated[List, operator.add]
    sum_number: Annotated[int, operator.add]

    # ä¹˜æ³•
    product: Annotated[int, operator.mul]

    # é€»è¾‘è¿ç®—
    all_true: Annotated[bool, operator.and_]
    any_true: Annotated[bool, operator.or_]

    # ä½è¿ç®—
    bitwise_or: Annotated[int, operator.or_]
    bitwise_and: Annotated[int, operator.and_]
```

### 3.2 è‡ªå®šä¹‰ Reducer

```python
from typing import Any, List, Dict

# ä¿ç•™æœ€æ–°å€¼
def keep_latest(old: Any, new: Any) -> Any:
    """æ€»æ˜¯ä½¿ç”¨æ–°å€¼"""
    return new

# ä¿ç•™æœ€å¤§å€¼
def keep_max(old: float, new: float) -> float:
    """ä¿ç•™è¾ƒå¤§çš„å€¼"""
    return max(old, new) if old is not None else new

# å»é‡åˆå¹¶åˆ—è¡¨
def merge_unique(old: List, new: List) -> List:
    """åˆå¹¶åˆ—è¡¨å¹¶å»é‡"""
    return list(set(old + new))

# æ·±åº¦åˆå¹¶å­—å…¸
def deep_merge_dict(old: Dict, new: Dict) -> Dict:
    """é€’å½’åˆå¹¶å­—å…¸"""
    result = old.copy()

    for key, value in new.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge_dict(result[key], value)
        else:
            result[key] = value

    return result

# åº”ç”¨è‡ªå®šä¹‰ Reducer
class CustomReducerState(TypedDict):
    latest_value: Annotated[str, keep_latest]
    max_score: Annotated[float, keep_max]
    unique_items: Annotated[List, merge_unique]
    config: Annotated[Dict, deep_merge_dict]
```

### 3.3 æ¡ä»¶ Reducer

```python
def conditional_reducer(condition_key: str):
    """æ ¹æ®æ¡ä»¶é€‰æ‹©æ›´æ–°ç­–ç•¥"""
    def reducer(old: Any, new: Dict) -> Any:
        if new.get(condition_key):
            return new.get("value")
        return old
    return reducer

class ConditionalState(TypedDict):
    value: Annotated[Any, conditional_reducer("should_update")]
    should_update: bool
```

## å››ã€çŠ¶æ€æ›´æ–°æ¨¡å¼

### 4.1 å…¨é‡æ›´æ–°

```python
def full_update_node(state: State) -> State:
    """è¿”å›å®Œæ•´çš„æ–°çŠ¶æ€"""
    return {
        "field1": "new_value1",
        "field2": "new_value2",
        "field3": state["field3"] + 1  # åŸºäºæ—§å€¼è®¡ç®—
    }
```

### 4.2 éƒ¨åˆ†æ›´æ–°

```python
def partial_update_node(state: State) -> Dict:
    """åªè¿”å›éœ€è¦æ›´æ–°çš„å­—æ®µ"""
    return {
        "updated_field": "new_value",
        # å…¶ä»–å­—æ®µä¿æŒä¸å˜
    }
```

### 4.3 æ¡ä»¶æ›´æ–°

```python
def conditional_update_node(state: State) -> Dict:
    """æ ¹æ®æ¡ä»¶å†³å®šæ›´æ–°å†…å®¹"""
    updates = {}

    if state.get("condition1"):
        updates["field1"] = "value1"

    if state.get("condition2"):
        updates["field2"] = "value2"

    return updates if updates else {}
```

## äº”ã€é«˜çº§çŠ¶æ€ç®¡ç†æ¨¡å¼

### 5.1 çŠ¶æ€ç‰ˆæœ¬æ§åˆ¶

```python
from typing import TypedDict, List, Annotated
import operator
from datetime import datetime
import copy

class VersionedState(TypedDict):
    current: Dict
    history: Annotated[List[Dict], operator.add]
    version: int

def versioned_update(state: VersionedState, updates: Dict) -> VersionedState:
    """åˆ›å»ºæ–°ç‰ˆæœ¬çš„çŠ¶æ€"""
    # ä¿å­˜å½“å‰çŠ¶æ€åˆ°å†å²
    history_entry = {
        "version": state["version"],
        "data": copy.deepcopy(state["current"]),
        "timestamp": datetime.now().isoformat()
    }

    # åº”ç”¨æ›´æ–°
    new_current = {**state["current"], **updates}

    return {
        "current": new_current,
        "history": [history_entry],
        "version": state["version"] + 1
    }
```

### 5.2 çŠ¶æ€åˆ†åŒº

```python
class PartitionedState(TypedDict):
    """å°†çŠ¶æ€åˆ†åŒºç®¡ç†"""
    # ç”¨æˆ·æ•°æ®åˆ†åŒº
    user_data: Dict[str, Any]

    # ç³»ç»ŸçŠ¶æ€åˆ†åŒº
    system_state: Dict[str, Any]

    # ä¸´æ—¶æ•°æ®åˆ†åŒºï¼ˆä¸æŒä¹…åŒ–ï¼‰
    temp_data: Dict[str, Any]

    # å…±äº«æ•°æ®åˆ†åŒº
    shared_data: Annotated[Dict[str, Any], operator.add]

def user_node(state: PartitionedState) -> Dict:
    """åªæ›´æ–°ç”¨æˆ·æ•°æ®åˆ†åŒº"""
    return {
        "user_data": {
            **state["user_data"],
            "last_action": "user_update"
        }
    }

def system_node(state: PartitionedState) -> Dict:
    """åªæ›´æ–°ç³»ç»ŸçŠ¶æ€åˆ†åŒº"""
    return {
        "system_state": {
            **state["system_state"],
            "process_count": state["system_state"].get("process_count", 0) + 1
        }
    }
```

### 5.3 çŠ¶æ€éªŒè¯

```python
from typing import TypedDict, List
import jsonschema

class ValidatedState(TypedDict):
    data: Dict
    errors: List[str]
    valid: bool

# å®šä¹‰çŠ¶æ€æ¨¡å¼
STATE_SCHEMA = {
    "type": "object",
    "properties": {
        "name": {"type": "string", "minLength": 1},
        "age": {"type": "integer", "minimum": 0, "maximum": 120},
        "email": {"type": "string", "format": "email"}
    },
    "required": ["name", "age"]
}

def validate_state(state: Dict) -> ValidatedState:
    """éªŒè¯çŠ¶æ€æ˜¯å¦ç¬¦åˆæ¨¡å¼"""
    errors = []

    try:
        jsonschema.validate(state, STATE_SCHEMA)
        return {
            "data": state,
            "errors": [],
            "valid": True
        }
    except jsonschema.ValidationError as e:
        errors.append(str(e))
        return {
            "data": state,
            "errors": errors,
            "valid": False
        }
```

## å…­ã€çŠ¶æ€æŒä¹…åŒ–

### 6.1 ä½¿ç”¨ Checkpointer

```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.checkpoint.sqlite import SqliteSaver

# å†…å­˜æŒä¹…åŒ–
memory_saver = MemorySaver()

# SQLite æŒä¹…åŒ–
sqlite_saver = SqliteSaver.from_conn_string("state.db")

# ç¼–è¯‘æ—¶æŒ‡å®š checkpointer
app = graph.compile(checkpointer=sqlite_saver)

# ä½¿ç”¨ thread_id ç®¡ç†ä¼šè¯
config = {"configurable": {"thread_id": "session-001"}}
result = app.invoke(initial_state, config=config)
```

### 6.2 è‡ªå®šä¹‰æŒä¹…åŒ–

```python
import json
import redis
from typing import Optional, Dict, Any

class RedisCheckpointer:
    """Redis çŠ¶æ€æŒä¹…åŒ–"""

    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    def save_state(self, thread_id: str, state: Dict) -> None:
        """ä¿å­˜çŠ¶æ€"""
        key = f"langgraph:state:{thread_id}"
        value = json.dumps(state)
        self.redis.set(key, value)

        # æ·»åŠ åˆ°å†å²
        history_key = f"langgraph:history:{thread_id}"
        self.redis.lpush(history_key, value)

    def load_state(self, thread_id: str) -> Optional[Dict]:
        """åŠ è½½çŠ¶æ€"""
        key = f"langgraph:state:{thread_id}"
        value = self.redis.get(key)

        if value:
            return json.loads(value)
        return None

    def get_history(self, thread_id: str, limit: int = 10) -> List[Dict]:
        """è·å–å†å²çŠ¶æ€"""
        history_key = f"langgraph:history:{thread_id}"
        history = self.redis.lrange(history_key, 0, limit - 1)

        return [json.loads(h) for h in history]
```

## ä¸ƒã€çŠ¶æ€ä¼˜åŒ–æŠ€å·§

### 7.1 å‡å°‘çŠ¶æ€å¤§å°

```python
class OptimizedState(TypedDict):
    # ä½¿ç”¨ ID å¼•ç”¨è€Œä¸æ˜¯åµŒå…¥å¤§å¯¹è±¡
    user_id: str  # è€Œä¸æ˜¯ user: UserObject

    # ä½¿ç”¨å‹ç¼©æ ¼å¼
    compressed_data: str  # base64 ç¼–ç çš„å‹ç¼©æ•°æ®

    # é™åˆ¶åˆ—è¡¨å¤§å°
    recent_messages: Annotated[List[str], lambda old, new: (old + new)[-10:]]
```

### 7.2 æ‡’åŠ è½½

```python
class LazyState(TypedDict):
    data_loaded: bool
    data: Optional[Dict]

def lazy_load_node(state: LazyState) -> LazyState:
    """æŒ‰éœ€åŠ è½½æ•°æ®"""
    if not state.get("data_loaded"):
        # åŠ è½½æ•°æ®
        data = load_heavy_data()
        return {
            "data": data,
            "data_loaded": True
        }
    return state
```

### 7.3 çŠ¶æ€ç¼“å­˜

```python
from functools import lru_cache
import hashlib

class CachedState(TypedDict):
    input_hash: str
    cached_result: Optional[Any]

@lru_cache(maxsize=128)
def expensive_computation(input_hash: str) -> Any:
    """æ˜‚è´µçš„è®¡ç®—ï¼Œç»“æœä¼šè¢«ç¼“å­˜"""
    # æ‰§è¡Œè®¡ç®—
    return result

def cached_node(state: CachedState) -> CachedState:
    """ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—"""
    input_data = state.get("input_data")
    input_hash = hashlib.md5(str(input_data).encode()).hexdigest()

    if state.get("input_hash") == input_hash and state.get("cached_result"):
        # ä½¿ç”¨ç¼“å­˜ç»“æœ
        return state

    # è®¡ç®—æ–°ç»“æœ
    result = expensive_computation(input_hash)

    return {
        "input_hash": input_hash,
        "cached_result": result
    }
```

## å…«ã€å®æˆ˜æ¡ˆä¾‹ï¼šå¤æ‚çŠ¶æ€ç®¡ç†

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Annotated, Optional
import operator
from datetime import datetime
from enum import Enum

# å®šä¹‰å¤æ‚çŠ¶æ€
class ProcessingStatus(Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class TaskState(TypedDict):
    id: str
    status: ProcessingStatus
    created_at: str
    updated_at: str
    data: Dict

class WorkflowState(TypedDict):
    # ä»»åŠ¡é˜Ÿåˆ—
    task_queue: Annotated[List[TaskState], operator.add]

    # å½“å‰å¤„ç†çš„ä»»åŠ¡
    current_task: Optional[TaskState]

    # å·²å®Œæˆä»»åŠ¡
    completed_tasks: Annotated[List[str], operator.add]

    # å¤±è´¥ä»»åŠ¡åŠé”™è¯¯ä¿¡æ¯
    failed_tasks: Annotated[Dict[str, str], lambda old, new: {**old, **new}]

    # ç»Ÿè®¡ä¿¡æ¯
    stats: Annotated[Dict[str, int], lambda old, new: {
        "total": old.get("total", 0) + new.get("total", 0),
        "processed": old.get("processed", 0) + new.get("processed", 0),
        "failed": old.get("failed", 0) + new.get("failed", 0)
    }]

    # é…ç½®ä¿¡æ¯ï¼ˆä¿æŒæœ€æ–°ï¼‰
    config: Annotated[Dict, lambda old, new: {**old, **new}]

# èŠ‚ç‚¹å‡½æ•°
def fetch_task(state: WorkflowState) -> WorkflowState:
    """ä»é˜Ÿåˆ—è·å–ä»»åŠ¡"""
    if state["task_queue"]:
        task = state["task_queue"][0]
        remaining_queue = state["task_queue"][1:]

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task["status"] = ProcessingStatus.PROCESSING
        task["updated_at"] = datetime.now().isoformat()

        return {
            "current_task": task,
            "task_queue": remaining_queue,  # ä¼šè¢«è¦†ç›–ï¼Œå› ä¸ºæ²¡æœ‰ reducer
            "stats": {"total": 1}
        }

    return {"current_task": None}

def process_task(state: WorkflowState) -> WorkflowState:
    """å¤„ç†ä»»åŠ¡"""
    task = state["current_task"]

    if not task:
        return state

    try:
        # æ¨¡æ‹Ÿå¤„ç†
        if "error" in task["data"]:
            raise Exception(task["data"]["error"])

        # æˆåŠŸå¤„ç†
        return {
            "completed_tasks": [task["id"]],
            "stats": {"processed": 1},
            "current_task": None
        }

    except Exception as e:
        # å¤„ç†å¤±è´¥
        return {
            "failed_tasks": {task["id"]: str(e)},
            "stats": {"failed": 1},
            "current_task": None
        }

def generate_report(state: WorkflowState) -> WorkflowState:
    """ç”ŸæˆæŠ¥å‘Š"""
    report = {
        "summary": {
            "total_tasks": state["stats"].get("total", 0),
            "processed": state["stats"].get("processed", 0),
            "failed": state["stats"].get("failed", 0),
            "success_rate": (
                state["stats"].get("processed", 0) /
                state["stats"].get("total", 1) * 100
                if state["stats"].get("total", 0) > 0 else 0
            )
        },
        "completed_tasks": state["completed_tasks"],
        "failed_tasks": state["failed_tasks"]
    }

    print("=" * 50)
    print("å·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Š")
    print("=" * 50)
    print(f"æ€»ä»»åŠ¡æ•°: {report['summary']['total_tasks']}")
    print(f"æˆåŠŸ: {report['summary']['processed']}")
    print(f"å¤±è´¥: {report['summary']['failed']}")
    print(f"æˆåŠŸç‡: {report['summary']['success_rate']:.1f}%")

    return state

# è·¯ç”±å‡½æ•°
def should_continue(state: WorkflowState) -> str:
    if state["current_task"]:
        return "process"
    elif state["task_queue"]:
        return "fetch"
    else:
        return "report"

# åˆ›å»ºå·¥ä½œæµ
def create_workflow():
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("fetch", fetch_task)
    graph.add_node("process", process_task)
    graph.add_node("report", generate_report)

    # æ·»åŠ è¾¹
    graph.add_edge("fetch", "process")

    graph.add_conditional_edges(
        "process",
        should_continue,
        {
            "fetch": "fetch",
            "report": "report"
        }
    )

    graph.add_edge("report", END)

    # è®¾ç½®å…¥å£
    graph.set_entry_point("fetch")

    return graph.compile()

# æµ‹è¯•
def test_workflow():
    workflow = create_workflow()

    # å‡†å¤‡æµ‹è¯•ä»»åŠ¡
    tasks = [
        TaskState(
            id=f"task_{i}",
            status=ProcessingStatus.PENDING,
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            data={"value": i} if i % 3 != 0 else {"error": f"Task {i} error"}
        )
        for i in range(1, 6)
    ]

    # åˆå§‹çŠ¶æ€
    initial_state = {
        "task_queue": tasks,
        "current_task": None,
        "completed_tasks": [],
        "failed_tasks": {},
        "stats": {"total": 0, "processed": 0, "failed": 0},
        "config": {"max_retries": 3, "timeout": 30}
    }

    # æ‰§è¡Œå·¥ä½œæµ
    result = workflow.invoke(initial_state)

    print("\næœ€ç»ˆçŠ¶æ€:")
    print(f"å®Œæˆçš„ä»»åŠ¡: {result['completed_tasks']}")
    print(f"å¤±è´¥çš„ä»»åŠ¡: {result['failed_tasks']}")

if __name__ == "__main__":
    test_workflow()
```

## ä¹ã€çŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ

### 9.1 è®¾è®¡åŸåˆ™

1. **æœ€å°åŒ–åŸåˆ™**ï¼šåªåœ¨çŠ¶æ€ä¸­ä¿å­˜å¿…è¦çš„ä¿¡æ¯
2. **ä¸å¯å˜åŸåˆ™**ï¼šé¿å…ç›´æ¥ä¿®æ”¹çŠ¶æ€ï¼Œè¿”å›æ–°çš„æ›´æ–°
3. **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨ TypedDict æˆ– Pydantic ç¡®ä¿ç±»å‹å®‰å…¨
4. **æ¸…æ™°å‘½å**ï¼šä½¿ç”¨æè¿°æ€§çš„å­—æ®µåç§°
5. **åˆç†åˆ†åŒº**ï¼šå°†ç›¸å…³çš„çŠ¶æ€å­—æ®µç»„ç»‡åœ¨ä¸€èµ·

### 9.2 æ€§èƒ½å»ºè®®

1. **é¿å…æ·±æ‹·è´**ï¼šåªåœ¨å¿…è¦æ—¶è¿›è¡Œæ·±æ‹·è´
2. **ä½¿ç”¨å¼•ç”¨**ï¼šå¤§å¯¹è±¡ä½¿ç”¨ ID å¼•ç”¨è€Œä¸æ˜¯åµŒå…¥
3. **é™åˆ¶å¤§å°**ï¼šé™åˆ¶åˆ—è¡¨å’Œå­—ç¬¦ä¸²å­—æ®µçš„å¤§å°
4. **æ‡’åŠ è½½**ï¼šå»¶è¿ŸåŠ è½½å¤§å‹æ•°æ®
5. **ç¼“å­˜ç»“æœ**ï¼šç¼“å­˜æ˜‚è´µçš„è®¡ç®—ç»“æœ

### 9.3 è°ƒè¯•æŠ€å·§

1. **çŠ¶æ€æ—¥å¿—**ï¼šè®°å½•æ¯æ¬¡çŠ¶æ€å˜æ›´
2. **éªŒè¯æ£€æŸ¥**ï¼šåœ¨å…³é”®èŠ‚ç‚¹éªŒè¯çŠ¶æ€
3. **å¯è§†åŒ–**ï¼šä½¿ç”¨å·¥å…·å¯è§†åŒ–çŠ¶æ€æµè½¬
4. **æ–­ç‚¹è°ƒè¯•**ï¼šåœ¨èŠ‚ç‚¹å‡½æ•°ä¸­è®¾ç½®æ–­ç‚¹
5. **å•å…ƒæµ‹è¯•**ï¼šä¸ºçŠ¶æ€æ›´æ–°é€»è¾‘ç¼–å†™æµ‹è¯•

## åã€æ€»ç»“

çŠ¶æ€ç®¡ç†æ˜¯ LangGraph çš„æ ¸å¿ƒï¼ŒæŒæ¡å¥½çŠ¶æ€ç®¡ç†èƒ½è®©ä½ ï¼š

- âœ… è®¾è®¡æ¸…æ™°çš„æ•°æ®æµ
- âœ… å®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘
- âœ… ä¼˜åŒ–æ€§èƒ½å’Œå†…å­˜ä½¿ç”¨
- âœ… æé«˜ä»£ç çš„å¯ç»´æŠ¤æ€§
- âœ… æ›´å®¹æ˜“è°ƒè¯•å’Œæµ‹è¯•

---

**ä¸‹ä¸€æ­¥ï¼š** å­¦ä¹  [05.è·¯ç”±ä¸æ§åˆ¶æµ](./05.è·¯ç”±ä¸æ§åˆ¶æµ.md) æŒæ¡æµç¨‹æ§åˆ¶æŠ€å·§ï¼