---
title: LangGraph实战教程(第22章):生产部署实践
date: 2025-02-15
permalink: /ai/langgraph/22.生产部署实践.html
categories:
  - LangGraph
tags:
  - LangGraph
---

# 生产部署实践

## 一、部署架构

```mermaid
graph TB
    A[负载均衡器] --> B[API服务集群]
    B --> C[LangGraph应用]
    C --> D[向量数据库]
    C --> E[关系数据库]
    C --> F[缓存层 Redis]
    C --> G[消息队列]

    H[监控系统] --> B
    H --> C
    H --> D
    H --> E

    I[日志聚合] --> B
    I --> C

    J[配置中心] --> B
    J --> C

    style A fill:#e1f5fe
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style H fill:#ffb74d
    style I fill:#81c784
```

## 二、容器化部署

### 2.1 Dockerfile

```dockerfile
# Dockerfile
FROM python:3.11-slim

# 设置工作目录
WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .

# 安装 Python 依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 创建非 root 用户
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# 暴露端口
EXPOSE 8000

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2.2 docker-compose.yml

```yaml
version: '3.8'

services:
  # LangGraph 应用
  langgraph-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_URL=postgresql://user:password@postgres:5432/langgraph
      - REDIS_URL=redis://redis:6379/0
      - LOG_LEVEL=INFO
    depends_on:
      - postgres
      - redis
    volumes:
      - ./data:/app/data
    restart: unless-stopped
    networks:
      - langgraph-network

  # PostgreSQL 数据库
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=langgraph
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - langgraph-network

  # Redis 缓存
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - langgraph-network

  # Nginx 反向代理
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - langgraph-app
    networks:
      - langgraph-network

volumes:
  postgres-data:
  redis-data:

networks:
  langgraph-network:
    driver: bridge
```

### 2.3 应用代码

```python
# main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langgraph.graph import StateGraph, END
from typing import TypedDict, Optional
import logging

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="LangGraph API")

# 请求模型
class GraphRequest(BaseModel):
    input: str
    config: Optional[dict] = None

class GraphResponse(BaseModel):
    output: str
    status: str

# LangGraph 应用
class State(TypedDict):
    input: str
    output: str

def process_node(state: State) -> dict:
    """处理节点"""
    # 实际业务逻辑
    output = f"Processed: {state['input']}"
    return {"output": output}

# 创建图
graph = StateGraph(State)
graph.add_node("process", process_node)
graph.set_entry_point("process")
graph.add_edge("process", END)
graph_app = graph.compile()

# API 端点
@app.get("/health")
async def health_check():
    """健康检查"""
    return {"status": "healthy"}

@app.post("/process", response_model=GraphResponse)
async def process_request(request: GraphRequest):
    """处理请求"""
    try:
        logger.info(f"Processing request: {request.input}")

        result = graph_app.invoke({
            "input": request.input,
            "output": ""
        })

        logger.info(f"Request completed: {result['output']}")

        return GraphResponse(
            output=result["output"],
            status="success"
        )

    except Exception as e:
        logger.error(f"Error processing request: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/metrics")
async def metrics():
    """暴露指标"""
    return {
        "requests_total": 100,
        "requests_success": 95,
        "requests_failed": 5,
        "avg_response_time": 0.5
    }
```

## 三、Kubernetes 部署

### 3.1 Deployment

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langgraph-app
  labels:
    app: langgraph
spec:
  replicas: 3
  selector:
    matchLabels:
      app: langgraph
  template:
    metadata:
      labels:
        app: langgraph
    spec:
      containers:
      - name: langgraph
        image: your-registry/langgraph:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: langgraph-secrets
              key: openai-api-key
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: langgraph-secrets
              key: database-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

### 3.2 Service

```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: langgraph-service
spec:
  selector:
    app: langgraph
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

### 3.3 ConfigMap

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: langgraph-config
data:
  LOG_LEVEL: "INFO"
  MAX_WORKERS: "4"
  TIMEOUT: "30"
```

### 3.4 Secrets

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: langgraph-secrets
type: Opaque
stringData:
  openai-api-key: "sk-..."
  database-url: "postgresql://..."
```

### 3.5 HPA 自动扩缩容

```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: langgraph-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: langgraph-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## 四、监控与可观测性

### 4.1 Prometheus 监控

```python
# monitoring.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from fastapi import Response
import time

# 定义指标
request_count = Counter(
    'langgraph_requests_total',
    'Total requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'langgraph_request_duration_seconds',
    'Request duration',
    ['method', 'endpoint']
)

active_requests = Gauge(
    'langgraph_active_requests',
    'Active requests'
)

llm_calls = Counter(
    'langgraph_llm_calls_total',
    'Total LLM API calls',
    ['model', 'status']
)

# 中间件
class MetricsMiddleware:
    def __init__(self, app):
        self.app = app

    async def __call__(self, scope, receive, send):
        if scope["type"] != "http":
            return await self.app(scope, receive, send)

        method = scope["method"]
        path = scope["path"]

        active_requests.inc()
        start_time = time.time()

        try:
            await self.app(scope, receive, send)
            status = "success"
        except Exception as e:
            status = "error"
            raise
        finally:
            duration = time.time() - start_time
            active_requests.dec()

            request_count.labels(
                method=method,
                endpoint=path,
                status=status
            ).inc()

            request_duration.labels(
                method=method,
                endpoint=path
            ).observe(duration)

# 添加到 FastAPI
from main import app

app.add_middleware(MetricsMiddleware)

@app.get("/metrics")
async def metrics():
    """Prometheus 指标端点"""
    return Response(
        content=generate_latest(),
        media_type="text/plain"
    )
```

### 4.2 日志聚合

```python
# logging_config.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    """JSON 格式日志"""

    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }

        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)

        return json.dumps(log_data)

# 配置日志
def setup_logging():
    handler = logging.StreamHandler()
    handler.setFormatter(JSONFormatter())

    logger = logging.getLogger()
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

# 使用
setup_logging()
logger = logging.getLogger(__name__)

logger.info("Application started", extra={
    "version": "1.0.0",
    "environment": "production"
})
```

### 4.3 分布式追踪

```python
# tracing.py
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

# 配置追踪
def setup_tracing(app):
    # 创建追踪器
    trace.set_tracer_provider(TracerProvider())
    tracer = trace.get_tracer(__name__)

    # 配置 Jaeger 导出器
    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=6831,
    )

    # 添加处理器
    trace.get_tracer_provider().add_span_processor(
        BatchSpanProcessor(jaeger_exporter)
    )

    # 自动追踪 FastAPI
    FastAPIInstrumentor.instrument_app(app)

    return tracer

# 使用
from main import app

tracer = setup_tracing(app)

# 在代码中添加追踪
def process_with_tracing(input_data):
    with tracer.start_as_current_span("process_data") as span:
        span.set_attribute("input.length", len(input_data))

        # 处理逻辑
        result = process(input_data)

        span.set_attribute("output.length", len(result))
        return result
```

## 五、CI/CD 流程

### 5.1 GitHub Actions

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Run tests
        run: |
          pytest --cov=src tests/

      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ secrets.REGISTRY_URL }}
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_PASSWORD }}

      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.REGISTRY_URL }}/langgraph:latest
            ${{ secrets.REGISTRY_URL }}/langgraph:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBECONFIG }}" > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/langgraph-app \
            langgraph=${{ secrets.REGISTRY_URL }}/langgraph:${{ github.sha }}
          kubectl rollout status deployment/langgraph-app

      - name: Verify deployment
        run: |
          kubectl get pods -l app=langgraph
```

## 六、环境配置管理

### 6.1 配置文件

```python
# config.py
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    """应用配置"""

    # 应用设置
    app_name: str = "LangGraph API"
    environment: str = "production"
    debug: bool = False

    # API 密钥
    openai_api_key: str
    anthropic_api_key: str = ""

    # 数据库
    database_url: str
    database_pool_size: int = 10

    # Redis
    redis_url: str
    redis_ttl: int = 3600

    # 日志
    log_level: str = "INFO"
    log_format: str = "json"

    # 性能
    max_workers: int = 4
    request_timeout: int = 30

    # 监控
    enable_metrics: bool = True
    enable_tracing: bool = True

    class Config:
        env_file = ".env"
        case_sensitive = False

@lru_cache()
def get_settings() -> Settings:
    """获取配置（单例）"""
    return Settings()

# 使用
settings = get_settings()
```

### 6.2 环境变量

```bash
# .env.production
APP_NAME=LangGraph API
ENVIRONMENT=production
DEBUG=false

OPENAI_API_KEY=sk-...
DATABASE_URL=postgresql://user:pass@host:5432/db
REDIS_URL=redis://redis:6379/0

LOG_LEVEL=INFO
LOG_FORMAT=json

MAX_WORKERS=4
REQUEST_TIMEOUT=30

ENABLE_METRICS=true
ENABLE_TRACING=true
```

## 七、安全加固

### 7.1 API 认证

```python
# security.py
from fastapi import Depends, HTTPException, Security
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt
from datetime import datetime, timedelta

security = HTTPBearer()

SECRET_KEY = "your-secret-key"
ALGORITHM = "HS256"

def create_token(user_id: str) -> str:
    """创建 JWT Token"""
    payload = {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=24)
    }
    return jwt.encode(payload, SECRET_KEY, algorithm=ALGORITHM)

def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    """验证 Token"""
    try:
        payload = jwt.decode(
            credentials.credentials,
            SECRET_KEY,
            algorithms=[ALGORITHM]
        )
        return payload["user_id"]
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")

# 在端点中使用
from main import app

@app.post("/protected")
async def protected_endpoint(user_id: str = Depends(verify_token)):
    return {"message": f"Hello {user_id}"}
```

### 7.2 速率限制

```python
# rate_limit.py
from fastapi import HTTPException
from collections import defaultdict
import time

class RateLimiter:
    """简单的速率限制器"""

    def __init__(self, requests: int, window: int):
        self.requests = requests
        self.window = window
        self.clients = defaultdict(list)

    def check(self, client_id: str):
        """检查是否超限"""
        now = time.time()
        requests = self.clients[client_id]

        # 清理过期请求
        requests = [req for req in requests if now - req < self.window]

        if len(requests) >= self.requests:
            raise HTTPException(
                status_code=429,
                detail="Too many requests"
            )

        requests.append(now)
        self.clients[client_id] = requests

# 使用
limiter = RateLimiter(requests=100, window=60)

@app.middleware("http")
async def rate_limit_middleware(request, call_next):
    client_ip = request.client.host
    limiter.check(client_ip)
    return await call_next(request)
```

## 八、灾难恢复

### 8.1 数据备份

```bash
#!/bin/bash
# backup.sh

# 配置
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="langgraph"

# 备份数据库
pg_dump -h postgres -U user -d $DB_NAME > $BACKUP_DIR/db_$DATE.sql

# 备份向量存储
tar -czf $BACKUP_DIR/vectors_$DATE.tar.gz /data/vectors/

# 上传到 S3
aws s3 cp $BACKUP_DIR/ s3://backups/langgraph/ --recursive

# 清理旧备份（保留7天）
find $BACKUP_DIR -mtime +7 -delete

echo "Backup completed: $DATE"
```

### 8.2 恢复流程

```bash
#!/bin/bash
# restore.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: ./restore.sh <backup_file>"
    exit 1
fi

# 停止服务
kubectl scale deployment/langgraph-app --replicas=0

# 恢复数据库
psql -h postgres -U user -d langgraph < $BACKUP_FILE

# 恢复向量存储
tar -xzf vectors_backup.tar.gz -C /data/

# 重启服务
kubectl scale deployment/langgraph-app --replicas=3

echo "Restore completed"
```

## 九、部署检查清单

### 9.1 部署前检查

- ✅ 所有测试通过
- ✅ 代码审查完成
- ✅ 配置文件更新
- ✅ 密钥安全存储
- ✅ 数据库迁移准备
- ✅ 回滚计划就绪
- ✅ 监控配置完成
- ✅ 备份策略实施

### 9.2 部署后验证

- ✅ 健康检查通过
- ✅ 核心功能测试
- ✅ 性能指标正常
- ✅ 错误率在阈值内
- ✅ 日志正常输出
- ✅ 监控告警配置
- ✅ 文档更新

---

**下一步:** 查看 [14.企业级案例](./14.企业级案例) 学习实战案例！
