---
title: 大数据量下数据库分库分表方案
date: 2025-09-23
permalink: /system-design/sharding.html
categories:
  - Architecture
  - System Design
---

## 1. 分库分表概述

### 1.1 为什么需要分库分表

#### 1.1.1 数据量增长的挑战
- **单表数据量过大**：当单表数据量超过千万级别时，查询性能急剧下降
  - MySQL InnoDB 单表建议不超过 2000 万行
  - 单表大小不超过 10GB
  - 索引深度过深导致查询效率降低

#### 1.1.2 并发访问的限制
- **数据库连接数限制**：单库并发连接数有限，影响系统吞吐量
  - MySQL 默认最大连接数为 151
  - 高并发场景下连接池容易耗尽
  - 锁等待时间增加，影响用户体验

#### 1.1.3 硬件资源瓶颈
- **IO瓶颈**：单机磁盘IO成为系统瓶颈
  - 磁盘 IOPS 达到上限
  - 网络带宽饱和
  - CPU 使用率过高

- **内存限制**：单机内存无法容纳所有热点数据
  - Buffer Pool 命中率下降
  - 频繁的磁盘IO操作
  - 查询响应时间增长

#### 1.1.4 数据库层面的问题
- **锁竞争**：大表上的锁竞争严重影响并发性能
  - 表级锁影响并发写入
  - 行级锁等待时间过长
  - 死锁问题频发

- **备份恢复困难**：大表的备份和恢复时间过长
  - 全量备份时间超过业务窗口
  - 增量备份复杂度增加
  - 故障恢复时间不可控

### 1.2 分库分表的类型

#### 1.2.1 垂直分库分表

**垂直分库（按业务拆分）**
- **定义**：按业务模块将不同表分配到不同数据库
- **应用场景**：
  - 电商系统：用户库、商品库、订单库、支付库
  - 社交系统：用户库、内容库、消息库、推荐库
  - 金融系统：账户库、交易库、风控库、报表库

- **优点**：
  - 业务解耦，各模块独立部署
  - 减少单库压力，提高并发能力
  - 便于不同团队维护
  - 可以针对不同业务选择合适的数据库类型

- **缺点**：
  - 跨库事务处理复杂
  - 跨库关联查询困难
  - 数据一致性保证困难

**垂直分表（按字段拆分）**
- **定义**：将一个表的不同字段拆分到多个表中
- **拆分策略**：
  - 按访问频率：热点字段和冷门字段分离
  - 按字段大小：大字段（TEXT、BLOB）独立存储
  - 按业务逻辑：基础信息和扩展信息分离

```sql
-- 原始用户表
CREATE TABLE user (
    id BIGINT PRIMARY KEY,
    username VARCHAR(50),
    email VARCHAR(100),
    phone VARCHAR(20),
    profile_image BLOB,
    description TEXT,
    created_at TIMESTAMP
);

-- 垂直分表后
-- 基础信息表（热点数据）
CREATE TABLE user_basic (
    id BIGINT PRIMARY KEY,
    username VARCHAR(50),
    email VARCHAR(100),
    phone VARCHAR(20),
    created_at TIMESTAMP
);

-- 扩展信息表（冷数据）
CREATE TABLE user_profile (
    id BIGINT PRIMARY KEY,
    profile_image BLOB,
    description TEXT,
    updated_at TIMESTAMP
);
```

#### 1.2.2 水平分库分表

**水平分库（数据量拆分）**
- **定义**：将同一个表的数据按照某种规则分散到多个数据库中
- **适用场景**：
  - 单表数据量过大（千万级以上）
  - 单库并发压力过大
  - 需要提升系统整体吞吐量

**水平分表（同库拆分）**
- **定义**：将同一个表的数据分散到同一数据库的多个表中
- **适用场景**：
  - 单表数据量大但数据库压力可控
  - 减少单表锁竞争
  - 提高查询性能

#### 1.2.3 混合分片策略

**垂直+水平分片**
```sql
-- 先垂直分库：订单库独立
-- 再水平分表：按订单ID分表
order_db_1:
  - order_2024_01
  - order_2024_02
  - order_2024_03

order_db_2:
  - order_2024_04
  - order_2024_05
  - order_2024_06
```

**多维度分片**
```sql
-- 先按地区分库，再按时间分表
db_north:
  - order_202401
  - order_202402

db_south:
  - order_202401
  - order_202402
```

## 2. 分库分表策略详解

### 2.1 分片键选择原则与实践

#### 2.1.1 核心选择原则

1. **业务相关性强**：选择与业务查询高度相关的字段
   - 80% 以上的查询都包含该字段
   - 与业务逻辑紧密相关
   - 能够支持主要的业务场景

2. **数据分布均匀**：避免热点数据集中
   - 字段值的分布要相对均匀
   - 避免某些值出现频率过高
   - 考虑业务发展的数据倾斜风险

3. **查询友好**：大部分查询都能带上分片键
   - 减少跨分片查询的概率
   - 支持高效的路由算法
   - 便于SQL优化和索引设计

4. **扩展性好**：便于后续扩容
   - 支持平滑的数据迁移
   - 不依赖于固定的分片数量
   - 能够适应业务增长需求

#### 2.1.2 常见分片键对比分析

**按用户ID分片**
```java
// 用户ID分片示例
public class UserIdSharding {
    private static final int SHARD_COUNT = 16;

    public String getShardKey(Long userId) {
        return "user_" + (userId % SHARD_COUNT);
    }
}
```

| 优点 | 缺点 | 适用场景 |
|------|------|----------|
| 用户数据天然隔离 | 某些用户数据量可能很大 | 用户中心、个人信息管理 |
| 查询性能稳定 | 跨用户查询困难 | 社交应用、个人账户系统 |
| 数据分布相对均匀 | 新用户可能集中在某些分片 | 内容管理系统 |

**按订单ID分片**
```java
// 订单ID分片示例
public class OrderIdSharding {
    private static final int SHARD_COUNT = 32;

    public String getShardKey(String orderId) {
        // 订单ID格式：yyyyMMddHHmmss + 6位随机数
        return "order_" + (orderId.hashCode() % SHARD_COUNT);
    }
}
```

| 优点 | 缺点 | 适用场景 |
|------|------|----------|
| 订单数据完整性好 | 按用户查询需要遍历分片 | 电商订单系统 |
| 支持订单详情查询 | 统计分析困难 | 交易系统 |
| 分布相对均匀 | 时间范围查询复杂 | 支付系统 |

**按时间分片**
```java
// 时间分片示例
public class TimeBasedSharding {
    public String getShardKey(Date createTime) {
        SimpleDateFormat sdf = new SimpleDateFormat("yyyyMM");
        return "data_" + sdf.format(createTime);
    }
}
```

| 优点 | 缺点 | 适用场景 |
|------|------|----------|
| 支持时间范围查询 | 容易产生热点 | 日志系统 |
| 历史数据可归档 | 当前时间分片压力大 | 监控系统 |
| 便于数据清理 | 跨时间查询复杂 | 报表系统 |

**按租户分片**
```java
// 租户分片示例
public class TenantSharding {
    private static final Map<String, String> TENANT_SHARD_MAP = new HashMap<>();

    public String getShardKey(String tenantId) {
        return TENANT_SHARD_MAP.getOrDefault(tenantId, "default_shard");
    }
}
```

| 优点 | 缺点 | 适用场景 |
|------|------|----------|
| 租户数据完全隔离 | 租户规模差异大 | SaaS多租户系统 |
| 支持租户级别运维 | 大租户成为瓶颈 | 企业级应用 |
| 便于租户迁移 | 跨租户功能困难 | 云服务平台 |

### 2.2 分片算法详解与比较

#### 2.2.1 取模算法（Modulo Sharding）

**算法实现**
```java
/**
 * 取模分片算法实现
 */
public class ModuloSharding {
    private final int shardCount;

    public ModuloSharding(int shardCount) {
        this.shardCount = shardCount;
    }

    /**
     * 根据用户ID计算分片
     */
    public int getShardIndex(Long userId) {
        return (int) (userId % shardCount);
    }

    /**
     * 根据字符串key计算分片
     */
    public int getShardIndex(String key) {
        return Math.abs(key.hashCode()) % shardCount;
    }

    /**
     * 获取分片数据源名称
     */
    public String getDataSourceName(Long userId) {
        int shardIndex = getShardIndex(userId);
        return String.format("db_%02d", shardIndex);
    }
}
```

**使用示例**
```java
// 在业务代码中使用
public class UserService {
    private ModuloSharding sharding = new ModuloSharding(16);

    public User getUserById(Long userId) {
        String dataSource = sharding.getDataSourceName(userId);
        // 切换到对应的数据源
        DataSourceContextHolder.setDataSource(dataSource);
        return userMapper.selectById(userId);
    }
}
```

**优缺点分析**

| 方面 | 详细说明 |
|------|----------|
| **优点** | • 实现简单，易于理解和维护<br>• 数据分布相对均匀<br>• 查询路由直接，性能好<br>• 适合大部分OLTP场景 |
| **缺点** | • 扩容困难，需要重新哈希和数据迁移<br>• 分片数量固定，不够灵活<br>• 某些业务场景可能出现热点 |
| **适用场景** | • 分片数量相对固定的场景<br>• 对扩容要求不高的系统<br>• 数据分布相对均匀的业务 |
| **不适用场景** | • 需要频繁扩容的系统<br>• 业务增长不可预测<br>• 对动态伸缩要求高的场景 |

#### 2.2.2 范围分片（Range Sharding）

**算法实现**
```java
/**
 * 范围分片算法实现
 */
public class RangeSharding {

    /**
     * 按时间范围分片
     */
    public static class TimeRangeSharding {
        private static final Map<String, String> TIME_SHARD_MAP = new HashMap<>();

        static {
            TIME_SHARD_MAP.put("2024-Q1", "shard_202401");
            TIME_SHARD_MAP.put("2024-Q2", "shard_202402");
            TIME_SHARD_MAP.put("2024-Q3", "shard_202403");
            TIME_SHARD_MAP.put("2024-Q4", "shard_202404");
        }

        public String getShardKey(Date createTime) {
            Calendar cal = Calendar.getInstance();
            cal.setTime(createTime);
            int year = cal.get(Calendar.YEAR);
            int quarter = (cal.get(Calendar.MONTH) / 3) + 1;

            String quarterKey = year + "-Q" + quarter;
            return TIME_SHARD_MAP.getOrDefault(quarterKey, "shard_default");
        }

        /**
         * 支持范围查询的分片路由
         */
        public Set<String> getShardsForRange(Date startTime, Date endTime) {
            Set<String> shards = new HashSet<>();

            Calendar start = Calendar.getInstance();
            start.setTime(startTime);
            Calendar end = Calendar.getInstance();
            end.setTime(endTime);

            // 遍历时间范围内的所有季度
            while (start.before(end) || start.equals(end)) {
                shards.add(getShardKey(start.getTime()));
                start.add(Calendar.MONTH, 3); // 下一个季度
            }

            return shards;
        }
    }

    /**
     * 按ID范围分片
     */
    public static class IdRangeSharding {
        private final List<RangeConfig> rangeConfigs;

        public IdRangeSharding() {
            this.rangeConfigs = Arrays.asList(
                new RangeConfig(1L, 1000000L, "shard_01"),
                new RangeConfig(1000001L, 2000000L, "shard_02"),
                new RangeConfig(2000001L, 3000000L, "shard_03"),
                new RangeConfig(3000001L, Long.MAX_VALUE, "shard_04")
            );
        }

        public String getShardKey(Long id) {
            return rangeConfigs.stream()
                .filter(config -> id >= config.getMinValue() && id <= config.getMaxValue())
                .map(RangeConfig::getShardName)
                .findFirst()
                .orElse("shard_default");
        }

        private static class RangeConfig {
            private final Long minValue;
            private final Long maxValue;
            private final String shardName;

            public RangeConfig(Long minValue, Long maxValue, String shardName) {
                this.minValue = minValue;
                this.maxValue = maxValue;
                this.shardName = shardName;
            }

            // getters...
            public Long getMinValue() { return minValue; }
            public Long getMaxValue() { return maxValue; }
            public String getShardName() { return shardName; }
        }
    }
}
```

**业务场景应用**
```java
// 日志系统按时间分片
public class LogService {
    private TimeRangeSharding sharding = new TimeRangeSharding();

    public void saveLog(LogEntry log) {
        String shard = sharding.getShardKey(log.getCreateTime());
        DataSourceContextHolder.setDataSource(shard);
        logMapper.insert(log);
    }

    public List<LogEntry> queryLogsByTimeRange(Date start, Date end) {
        Set<String> shards = sharding.getShardsForRange(start, end);
        List<LogEntry> results = new ArrayList<>();

        for (String shard : shards) {
            DataSourceContextHolder.setDataSource(shard);
            results.addAll(logMapper.selectByTimeRange(start, end));
        }

        return results;
    }
}
```

**优缺点详细分析**

| 方面 | 详细说明 |
|------|----------|
| **优点** | • 扩容简单，只需添加新的范围分片<br>• 天然支持范围查询，查询效率高<br>• 历史数据便于归档和清理<br>• 便于按时间或业务范围进行运维 |
| **缺点** | • 容易产生热点问题（如当前时间分片）<br>• 数据分布可能不均匀<br>• 需要预先规划好范围边界<br>• 范围调整可能需要数据迁移 |
| **适用场景** | • 日志存储和查询系统<br>• 时序数据处理<br>• 历史数据归档需求<br>• 按时间周期的业务分析 |
| **最佳实践** | • 结合业务周期性规律设计范围<br>• 考虑热点数据的处理策略<br>• 预留扩容空间<br>• 建立自动化的分片管理机制 |

#### 2.2.3 一致性哈希（Consistent Hashing）

**算法原理与实现**
```java
/**
 * 一致性哈希算法实现
 */
public class ConsistentHashing {
    private final TreeMap<Long, String> ring = new TreeMap<>();
    private final int virtualNodes;
    private final MessageDigest md5;

    public ConsistentHashing(int virtualNodes) {
        this.virtualNodes = virtualNodes;
        try {
            this.md5 = MessageDigest.getInstance("MD5");
        } catch (NoSuchAlgorithmException e) {
            throw new RuntimeException("MD5 algorithm not found", e);
        }
    }

    /**
     * 添加物理节点
     */
    public void addNode(String nodeId) {
        for (int i = 0; i < virtualNodes; i++) {
            String virtualNodeId = nodeId + "#" + i;
            Long hash = hash(virtualNodeId);
            ring.put(hash, nodeId);
        }
        System.out.println("Added node: " + nodeId + " with " + virtualNodes + " virtual nodes");
    }

    /**
     * 移除物理节点
     */
    public void removeNode(String nodeId) {
        for (int i = 0; i < virtualNodes; i++) {
            String virtualNodeId = nodeId + "#" + i;
            Long hash = hash(virtualNodeId);
            ring.remove(hash);
        }
        System.out.println("Removed node: " + nodeId);
    }

    /**
     * 根据key查找对应的节点
     */
    public String getNode(String key) {
        if (ring.isEmpty()) {
            return null;
        }

        Long hash = hash(key);
        Map.Entry<Long, String> entry = ring.ceilingEntry(hash);

        // 如果没有找到大于等于hash的节点，则返回第一个节点（环形特性）
        if (entry == null) {
            entry = ring.firstEntry();
        }

        return entry.getValue();
    }

    /**
     * 计算哈希值
     */
    private Long hash(String key) {
        md5.reset();
        md5.update(key.getBytes());
        byte[] digest = md5.digest();

        long hash = 0;
        for (int i = 0; i < 4; i++) {
            hash <<= 8;
            hash |= ((int) digest[i]) & 0xFF;
        }

        return hash;
    }

    /**
     * 获取数据分布情况
     */
    public Map<String, Integer> getDistribution(List<String> keys) {
        Map<String, Integer> distribution = new HashMap<>();

        for (String key : keys) {
            String node = getNode(key);
            distribution.put(node, distribution.getOrDefault(node, 0) + 1);
        }

        return distribution;
    }

    /**
     * 获取需要迁移的数据
     */
    public List<String> getDataToMigrate(String newNode, List<String> allKeys) {
        List<String> toMigrate = new ArrayList<>();

        for (String key : allKeys) {
            if (newNode.equals(getNode(key))) {
                toMigrate.add(key);
            }
        }

        return toMigrate;
    }
}
```

**使用示例**
```java
/**
 * 分布式缓存中的一致性哈希应用
 */
public class DistributedCache {
    private final ConsistentHashing consistentHash;
    private final Map<String, CacheNode> cacheNodes;

    public DistributedCache() {
        this.consistentHash = new ConsistentHashing(150);
        this.cacheNodes = new HashMap<>();

        // 初始化缓存节点
        initializeCacheNodes();
    }

    private void initializeCacheNodes() {
        String[] nodeIds = {"cache-node-1", "cache-node-2", "cache-node-3", "cache-node-4"};

        for (String nodeId : nodeIds) {
            CacheNode node = new CacheNode(nodeId);
            cacheNodes.put(nodeId, node);
            consistentHash.addNode(nodeId);
        }
    }

    public void put(String key, Object value) {
        String nodeId = consistentHash.getNode(key);
        CacheNode node = cacheNodes.get(nodeId);
        node.put(key, value);
    }

    public Object get(String key) {
        String nodeId = consistentHash.getNode(key);
        CacheNode node = cacheNodes.get(nodeId);
        return node.get(key);
    }

    /**
     * 动态添加缓存节点
     */
    public void addCacheNode(String nodeId) {
        CacheNode node = new CacheNode(nodeId);
        cacheNodes.put(nodeId, node);
        consistentHash.addNode(nodeId);

        // 这里可以添加数据迁移逻辑
        migrateDataToNewNode(nodeId);
    }

    private void migrateDataToNewNode(String newNodeId) {
        // 实现数据迁移逻辑
        System.out.println("Migrating data to new node: " + newNodeId);
    }

    private static class CacheNode {
        private final String nodeId;
        private final Map<String, Object> data = new ConcurrentHashMap<>();

        public CacheNode(String nodeId) {
            this.nodeId = nodeId;
        }

        public void put(String key, Object value) {
            data.put(key, value);
        }

        public Object get(String key) {
            return data.get(key);
        }
    }
}
```

**优缺点深入分析**

| 方面 | 详细说明 |
|------|----------|
| **优点** | • 扩容时只需迁移 1/N 的数据（N为节点数）<br>• 数据分布相对均匀（通过虚拟节点）<br>• 支持动态扩容和缩容<br>• 节点失效时影响范围有限 |
| **缺点** | • 实现复杂度较高<br>• 可能存在数据热点<br>• 虚拟节点管理开销<br>• 负载均衡不够精确 |
| **适用场景** | • 分布式缓存系统<br>• 分布式存储系统<br>• 需要动态扩容的场景<br>• 对数据迁移成本敏感的系统 |
| **关键参数** | • 虚拟节点数量：一般设置为 100-200<br>• 哈希函数选择：MD5、SHA1等<br>• 负载均衡阈值设置 |

#### 2.2.4 地理位置分片（Geographic Sharding）

**算法实现**
```java
/**
 * 地理位置分片算法实现
 */
public class GeographicSharding {

    // 地理区域配置
    public enum Region {
        NORTH("华北", Arrays.asList("北京", "天津", "河北", "山西", "内蒙古")),
        EAST("华东", Arrays.asList("上海", "江苏", "浙江", "安徽", "福建", "江西", "山东")),
        SOUTH("华南", Arrays.asList("广东", "广西", "海南")),
        CENTRAL("华中", Arrays.asList("河南", "湖北", "湖南")),
        SOUTHWEST("西南", Arrays.asList("重庆", "四川", "贵州", "云南", "西藏")),
        NORTHWEST("西北", Arrays.asList("陕西", "甘肃", "青海", "宁夏", "新疆")),
        NORTHEAST("东北", Arrays.asList("辽宁", "吉林", "黑龙江"));

        private final String regionName;
        private final List<String> provinces;

        Region(String regionName, List<String> provinces) {
            this.regionName = regionName;
            this.provinces = provinces;
        }

        public String getRegionName() { return regionName; }
        public List<String> getProvinces() { return provinces; }
    }

    private final Map<String, Region> provinceToRegion;
    private final Map<Region, String> regionToShard;

    public GeographicSharding() {
        this.provinceToRegion = new HashMap<>();
        this.regionToShard = new HashMap<>();

        initializeMapping();
    }

    private void initializeMapping() {
        // 初始化省份到区域的映射
        for (Region region : Region.values()) {
            for (String province : region.getProvinces()) {
                provinceToRegion.put(province, region);
            }
            // 区域到分片的映射
            regionToShard.put(region, "shard_" + region.name().toLowerCase());
        }
    }

    /**
     * 根据省份获取分片
     */
    public String getShardByProvince(String province) {
        Region region = provinceToRegion.get(province);
        if (region == null) {
            return "shard_default";
        }
        return regionToShard.get(region);
    }

    /**
     * 根据IP地址获取分片（需要IP地址库支持）
     */
    public String getShardByIP(String ipAddress) {
        // 这里需要集成IP地址库，如GeoIP2
        String province = getProvinceByIP(ipAddress);
        return getShardByProvince(province);
    }

    /**
     * 根据用户选择的城市获取分片
     */
    public String getShardByCity(String city) {
        // 城市到省份的映射（简化示例）
        Map<String, String> cityToProvince = Map.of(
            "北京", "北京",
            "上海", "上海",
            "广州", "广东",
            "深圳", "广东",
            "杭州", "浙江",
            "南京", "江苏"
        );

        String province = cityToProvince.getOrDefault(city, "未知");
        return getShardByProvince(province);
    }

    /**
     * 获取跨区域查询需要访问的分片列表
     */
    public Set<String> getShardsForCrossRegionQuery() {
        return new HashSet<>(regionToShard.values());
    }

    /**
     * 获取特定区域的分片
     */
    public Set<String> getShardsForRegions(Set<Region> regions) {
        return regions.stream()
                .map(regionToShard::get)
                .collect(Collectors.toSet());
    }

    // 模拟IP地址解析（实际需要使用IP地址库）
    private String getProvinceByIP(String ipAddress) {
        // 这里应该调用真实的IP地址解析服务
        // 如MaxMind GeoIP2、纯真IP库等
        return "北京"; // 示例返回
    }
}
```

**实际应用示例**
```java
/**
 * 基于地理位置的用户服务
 */
public class GeoUserService {
    private final GeographicSharding geoSharding;
    private final Map<String, DataSource> regionDataSources;

    public GeoUserService() {
        this.geoSharding = new GeographicSharding();
        this.regionDataSources = initializeDataSources();
    }

    /**
     * 根据用户IP注册用户
     */
    public void registerUser(User user, String clientIP) {
        String shard = geoSharding.getShardByIP(clientIP);
        user.setRegion(shard);

        DataSourceContextHolder.setDataSource(shard);
        userMapper.insert(user);

        // 记录用户地理位置信息
        logUserLocation(user.getId(), clientIP, shard);
    }

    /**
     * 根据用户选择的城市切换数据存储
     */
    public void updateUserLocation(Long userId, String newCity) {
        String newShard = geoSharding.getShardByCity(newCity);
        String oldShard = getCurrentUserShard(userId);

        if (!newShard.equals(oldShard)) {
            // 需要迁移用户数据
            migrateUserData(userId, oldShard, newShard);
        }
    }

    /**
     * 跨区域查询用户（管理员功能）
     */
    public List<User> searchUsersGlobally(String keyword) {
        Set<String> allShards = geoSharding.getShardsForCrossRegionQuery();
        List<User> results = new ArrayList<>();

        for (String shard : allShards) {
            DataSourceContextHolder.setDataSource(shard);
            List<User> shardResults = userMapper.searchByKeyword(keyword);
            results.addAll(shardResults);
        }

        return results;
    }

    private String getCurrentUserShard(Long userId) {
        // 查询用户当前所在的分片
        return "shard_north"; // 示例
    }

    private void migrateUserData(Long userId, String fromShard, String toShard) {
        // 实现用户数据迁移逻辑
        System.out.println(String.format(
            "Migrating user %d from %s to %s", userId, fromShard, toShard));
    }

    private void logUserLocation(Long userId, String ip, String shard) {
        // 记录用户位置信息用于分析
        System.out.println(String.format(
            "User %d from IP %s assigned to %s", userId, ip, shard));
    }

    private Map<String, DataSource> initializeDataSources() {
        // 初始化各区域的数据源
        return new HashMap<>();
    }
}
```

**深入优缺点分析**

| 方面 | 详细说明 |
|------|----------|
| **优点** | • **低延迟访问**：用户就近访问数据，网络延迟最小<br>• **数据本地化**：符合数据主权和隐私法规要求<br>• **灾难隔离**：单个区域故障不影响其他区域<br>• **运维便利**：可以按区域进行独立运维和升级 |
| **缺点** | • **数据分布不均**：不同地区用户数量差异巨大<br>• **跨区域查询复杂**：全局查询需要访问多个分片<br>• **热点区域**：经济发达地区可能成为瓶颈<br>• **迁移成本高**：用户搬迁时数据迁移复杂 |
| **适用场景** | • **全球化应用**：跨国或跨地区的大型应用<br>• **内容分发**：CDN、视频、图片等内容服务<br>• **本地化服务**：O2O、外卖、打车等位置相关服务<br>• **合规要求**：需要满足数据本地化法规的场景 |
| **技术挑战** | • **IP地址解析精度**：需要高质量的IP地址库<br>• **跨区域同步**：某些业务数据需要跨区域同步<br>• **负载均衡**：需要在区域内部进一步分片<br>• **一致性保证**：跨区域数据一致性挑战 |

**最佳实践建议**
1. **多级分片**：地理位置 + 其他维度的组合分片
2. **智能路由**：结合用户行为和网络状况动态路由
3. **缓存策略**：热点数据在多个区域部署缓存
4. **监控告警**：建立跨区域的监控和故障转移机制

## 3. 分库分表策略详细对比分析

### 3.1 按租户分片 vs 按用户分片 vs 按订单分片

#### 3.1.1 按租户分片策略详解

**适用场景：SaaS多租户系统**

```java
/**
 * 租户分片策略实现
 */
public class TenantShardingStrategy {
    // 租户到分片的映射配置
    private final Map<String, String> tenantShardMapping;
    // 租户权重配置（大租户独立分片）
    private final Map<String, Integer> tenantWeights;

    public TenantShardingStrategy() {
        this.tenantShardMapping = new HashMap<>();
        this.tenantWeights = new HashMap<>();
        initializeTenantMapping();
    }

    private void initializeTenantMapping() {
        // 大租户独立分片
        tenantShardMapping.put("enterprise_001", "shard_enterprise_01");
        tenantShardMapping.put("enterprise_002", "shard_enterprise_02");

        // 中等租户共享分片
        tenantShardMapping.put("medium_001", "shard_medium_01");
        tenantShardMapping.put("medium_002", "shard_medium_01");
        tenantShardMapping.put("medium_003", "shard_medium_02");

        // 小租户共享分片
        for (int i = 1; i <= 100; i++) {
            String tenantId = String.format("small_%03d", i);
            String shardId = "shard_small_" + String.format("%02d", (i % 8) + 1);
            tenantShardMapping.put(tenantId, shardId);
        }
    }

    public String getShardByTenant(String tenantId) {
        return tenantShardMapping.getOrDefault(tenantId, "shard_default");
    }

    /**
     * 动态租户分片调整
     */
    public void rebalanceTenant(String tenantId, String newShardId) {
        String oldShardId = tenantShardMapping.get(tenantId);
        if (!newShardId.equals(oldShardId)) {
            // 执行租户数据迁移
            migrateTenantData(tenantId, oldShardId, newShardId);
            tenantShardMapping.put(tenantId, newShardId);
        }
    }

    private void migrateTenantData(String tenantId, String fromShard, String toShard) {
        System.out.println(String.format(
            "Migrating tenant %s from %s to %s", tenantId, fromShard, toShard));
        // 实现数据迁移逻辑
    }
}
```

**租户分片的优缺点对比**

| 维度 | 优点 | 缺点 | 解决方案 |
|------|------|------|----------|
| **数据隔离** | 完全的租户数据隔离 | 大租户可能独占资源 | 大租户独立分片 |
| **性能** | 单租户性能稳定 | 租户间负载不均 | 权重调度算法 |
| **扩展性** | 便于按租户扩容 | 跨租户功能复杂 | 共享服务层设计 |
| **运维** | 便于租户级运维 | 运维复杂度增加 | 自动化运维工具 |

#### 3.1.2 按用户分片策略详解

**适用场景：用户中心系统、社交平台**

```java
/**
 * 用户分片策略实现
 */
public class UserShardingStrategy {
    private final int shardCount;
    private final ConsistentHashing consistentHash;

    public UserShardingStrategy(int shardCount) {
        this.shardCount = shardCount;
        this.consistentHash = new ConsistentHashing(150);
        initializeShards();
    }

    private void initializeShards() {
        for (int i = 0; i < shardCount; i++) {
            consistentHash.addNode("user_shard_" + i);
        }
    }

    /**
     * 基于用户ID的分片路由
     */
    public String getShardByUserId(Long userId) {
        return consistentHash.getNode(userId.toString());
    }

    /**
     * 基于用户特征的分片路由（考虑用户活跃度）
     */
    public String getShardByUserProfile(Long userId, UserProfile profile) {
        if (profile.isVipUser()) {
            // VIP用户使用高性能分片
            return "user_shard_vip_" + (userId % 4);
        } else if (profile.isActiveUser()) {
            // 活跃用户均匀分布
            return "user_shard_active_" + (userId % 8);
        } else {
            // 普通用户使用标准分片
            return "user_shard_normal_" + (userId % 16);
        }
    }

    /**
     * 处理用户数据热点
     */
    public String getShardWithHotspotHandling(Long userId) {
        String baseShard = getShardByUserId(userId);

        // 检查是否为热点用户
        if (isHotUser(userId)) {
            // 热点用户使用专门的分片
            return "user_shard_hot_" + (userId % 2);
        }

        return baseShard;
    }

    private boolean isHotUser(Long userId) {
        // 检查用户是否为热点用户（如大V、KOL等）
        return false; // 示例实现
    }
}
```

**用户分片的特点分析**

| 特点 | 说明 | 最佳实践 |
|------|------|----------|
| **数据完整性** | 用户相关数据聚合在一起 | 用户维度的事务保证 |
| **查询效率** | 用户相关查询只需访问一个分片 | 优化用户画像查询 |
| **热点处理** | 某些用户（如大V）可能成为热点 | 热点用户独立分片 |
| **扩容策略** | 一致性哈希支持平滑扩容 | 渐进式数据迁移 |

#### 3.1.3 按订单分片策略详解

**适用场景：电商订单系统、交易系统**

```java
/**
 * 订单分片策略实现
 */
public class OrderShardingStrategy {

    /**
     * 按订单ID分片（雪花算法生成的订单ID）
     */
    public static class OrderIdSharding {
        private final int shardCount;

        public OrderIdSharding(int shardCount) {
            this.shardCount = shardCount;
        }

        public String getShardByOrderId(String orderId) {
            // 订单ID格式：yyyyMMddHHmmss + 机器ID + 序列号
            // 使用订单ID的后几位进行分片，确保分布均匀
            long orderIdNum = Long.parseLong(orderId.substring(orderId.length() - 6));
            return "order_shard_" + (orderIdNum % shardCount);
        }
    }

    /**
     * 按时间+用户ID复合分片
     */
    public static class TimeUserCompositeSharding {

        public String getShardByTimeAndUser(Date orderTime, Long userId) {
            // 按月分库
            SimpleDateFormat monthFormat = new SimpleDateFormat("yyyyMM");
            String monthStr = monthFormat.format(orderTime);

            // 按用户ID分表
            int tableIndex = (int) (userId % 32);

            return String.format("order_%s_t%02d", monthStr, tableIndex);
        }

        /**
         * 支持时间范围查询的分片路由
         */
        public Set<String> getShardsForTimeRange(Date startTime, Date endTime, Long userId) {
            Set<String> shards = new HashSet<>();

            Calendar start = Calendar.getInstance();
            start.setTime(startTime);
            Calendar end = Calendar.getInstance();
            end.setTime(endTime);

            while (start.before(end) || start.equals(end)) {
                String shard = getShardByTimeAndUser(start.getTime(), userId);
                shards.add(shard);
                start.add(Calendar.MONTH, 1);
            }

            return shards;
        }
    }

    /**
     * 按订单状态分片（适用于不同状态的订单访问模式差异很大的场景）
     */
    public static class OrderStatusSharding {

        public String getShardByStatus(String orderId, OrderStatus status) {
            switch (status) {
                case PENDING:
                case PROCESSING:
                    // 活跃订单使用高性能分片
                    return "order_active_" + (orderId.hashCode() % 8);
                case COMPLETED:
                    // 已完成订单使用归档分片
                    return "order_completed_" + (orderId.hashCode() % 16);
                case CANCELLED:
                    // 取消订单使用冷存储分片
                    return "order_cancelled_" + (orderId.hashCode() % 4);
                default:
                    return "order_default_" + (orderId.hashCode() % 8);
            }
        }
    }

    public enum OrderStatus {
        PENDING, PROCESSING, COMPLETED, CANCELLED
    }
}
```

**订单分片策略对比**

| 分片策略 | 适用场景 | 优点 | 缺点 | 推荐指数 |
|----------|----------|------|------|---------|
| **按订单ID** | 订单详情查询为主 | 分布均匀，查询快速 | 用户维度查询需要扫全表 | ⭐⭐⭐⭐ |
| **按时间+用户** | 用户订单查询频繁 | 支持用户和时间维度查询 | 实现复杂，可能有热点 | ⭐⭐⭐⭐⭐ |
| **按订单状态** | 不同状态访问模式差异大 | 便于状态相关优化 | 状态变更需要数据迁移 | ⭐⭐⭐ |

### 3.2 按时间分片的深度分析

#### 3.2.1 不同时间粒度的分片策略

```java
/**
 * 多级时间分片策略
 */
public class TimeBasedShardingStrategies {

    /**
     * 按日分片（适用于大数据量且查询主要集中在近期的场景）
     */
    public static class DailySharding {
        public String getShardByDate(Date date) {
            SimpleDateFormat format = new SimpleDateFormat("yyyyMMdd");
            return "data_daily_" + format.format(date);
        }

        /**
         * 自动分片管理（创建新分片和清理旧分片）
         */
        public void autoManageShards() {
            // 创建未来7天的分片
            for (int i = 0; i < 7; i++) {
                Date futureDate = new Date(System.currentTimeMillis() + i * 24 * 3600 * 1000L);
                String shardName = getShardByDate(futureDate);
                createShardIfNotExists(shardName);
            }

            // 归档90天前的数据
            Date archiveDate = new Date(System.currentTimeMillis() - 90 * 24 * 3600 * 1000L);
            String archiveShard = getShardByDate(archiveDate);
            archiveOldShard(archiveShard);
        }

        private void createShardIfNotExists(String shardName) {
            // 实现分片创建逻辑
        }

        private void archiveOldShard(String shardName) {
            // 实现数据归档逻辑
        }
    }

    /**
     * 按周分片（平衡数据量和管理复杂度）
     */
    public static class WeeklySharding {
        public String getShardByDate(Date date) {
            Calendar cal = Calendar.getInstance();
            cal.setTime(date);
            int year = cal.get(Calendar.YEAR);
            int week = cal.get(Calendar.WEEK_OF_YEAR);
            return String.format("data_weekly_%04d_w%02d", year, week);
        }
    }

    /**
     * 按月分片（最常用的时间分片策略）
     */
    public static class MonthlySharding {
        public String getShardByDate(Date date) {
            SimpleDateFormat format = new SimpleDateFormat("yyyyMM");
            return "data_monthly_" + format.format(date);
        }

        /**
         * 处理月度数据倾斜问题
         */
        public String getShardWithBalancing(Date date, String businessKey) {
            String baseShard = getShardByDate(date);

            // 对于热点月份，进一步细分
            if (isHotMonth(date)) {
                int subShardIndex = Math.abs(businessKey.hashCode()) % 4;
                return baseShard + "_sub_" + subShardIndex;
            }

            return baseShard;
        }

        private boolean isHotMonth(Date date) {
            Calendar cal = Calendar.getInstance();
            cal.setTime(date);
            int month = cal.get(Calendar.MONTH) + 1;
            // 假设11月、12月是热点月份（如双11、双12）
            return month == 11 || month == 12;
        }
    }

    /**
     * 按季度分片（适用于历史数据分析）
     */
    public static class QuarterlySharding {
        public String getShardByDate(Date date) {
            Calendar cal = Calendar.getInstance();
            cal.setTime(date);
            int year = cal.get(Calendar.YEAR);
            int quarter = (cal.get(Calendar.MONTH) / 3) + 1;
            return String.format("data_quarterly_%04d_q%d", year, quarter);
        }
    }
}
```

#### 3.2.2 时间分片的热点处理策略

```java
/**
 * 时间分片热点处理
 */
public class TimeShardingHotspotHandler {

    /**
     * 基于业务周期的动态分片
     */
    public static class BusinessCycleSharding {
        // 业务高峰期配置
        private final Set<String> peakPeriods = Set.of(
            "1111", "1212", "0618", "0101" // 双11、双12、618、元旦
        );

        public String getShardWithPeakHandling(Date date, String orderId) {
            SimpleDateFormat dayFormat = new SimpleDateFormat("MMdd");
            String dayStr = dayFormat.format(date);

            if (peakPeriods.contains(dayStr)) {
                // 高峰期使用更细粒度的分片
                SimpleDateFormat hourFormat = new SimpleDateFormat("yyyyMMddHH");
                String hourStr = hourFormat.format(date);
                int shardIndex = Math.abs(orderId.hashCode()) % 8;
                return String.format("order_peak_%s_%02d", hourStr, shardIndex);
            } else {
                // 普通时期按天分片
                SimpleDateFormat dayFormat2 = new SimpleDateFormat("yyyyMMdd");
                return "order_normal_" + dayFormat2.format(date);
            }
        }
    }

    /**
     * 预分片策略
     */
    public static class PreShardingStrategy {

        /**
         * 根据历史数据预测和预分片
         */
        public void preCreateShardsForUpcomingPeak() {
            // 根据历史数据预测即将到来的高峰期
            List<Date> upcomingPeaks = predictUpcomingPeaks();

            for (Date peakDate : upcomingPeaks) {
                // 为高峰期预创建更多分片
                createPeakShards(peakDate);
            }
        }

        private List<Date> predictUpcomingPeaks() {
            // 基于历史数据和业务规律预测
            return Arrays.asList(
                // 即将到来的购物节
            );
        }

        private void createPeakShards(Date peakDate) {
            SimpleDateFormat format = new SimpleDateFormat("yyyyMMdd");
            String dateStr = format.format(peakDate);

            // 为高峰期创建多个分片
            for (int i = 0; i < 16; i++) {
                String shardName = String.format("order_peak_%s_%02d", dateStr, i);
                // 执行分片创建
                System.out.println("Pre-creating shard: " + shardName);
            }
        }
    }
}
```

### 3.3 数据倾斜问题的成因与影响

#### 3.3.1 数据倾斜的主要成因

**分片键选择不当**
```java
// 错误示例：按性别分片
public class BadShardingExample {
    public String getShardByGender(String gender) {
        // 这种分片方式会导致严重的数据倾斜
        // 因为性别只有两个值，分布极不均匀
        return "user_" + gender.toLowerCase();
    }

    // 错误示例：按用户类型分片
    public String getShardByUserType(UserType userType) {
        // 普通用户占99%，VIP用户占1%，分布极不均匀
        return "user_" + userType.name().toLowerCase();
    }
}
```

**业务特性导致的倾斜**
```java
/**
 * 业务倾斜场景分析
 */
public class BusinessSkewAnalysis {

    /**
     * 电商场景的数据倾斜
     */
    public static class EcommerceSkew {
        // 某些大商家的订单量远超其他商家
        private final Set<String> bigMerchants = Set.of(
            "tmall_flagship", "jd_self", "suning_official"
        );

        public boolean isBigMerchant(String merchantId) {
            return bigMerchants.contains(merchantId);
        }

        // 热门商品的访问量集中
        public boolean isHotProduct(String productId) {
            // 检查商品是否为热门商品（如iPhone新品发布）
            return getProductPopularity(productId) > 10000;
        }

        private int getProductPopularity(String productId) {
            // 模拟商品热度计算
            return 0;
        }
    }

    /**
     * 社交媒体的数据倾斜
     */
    public static class SocialMediaSkew {
        // 大V用户的数据量远超普通用户
        public boolean isInfluencer(Long userId) {
            return getUserFollowerCount(userId) > 1000000;
        }

        // 热门话题的参与度集中
        public boolean isTrendingTopic(String topicId) {
            return getTopicEngagement(topicId) > 50000;
        }

        private int getUserFollowerCount(Long userId) {
            return 0; // 模拟实现
        }

        private int getTopicEngagement(String topicId) {
            return 0; // 模拟实现
        }
    }
}
```

**时间特性导致的倾斜**
```java
/**
 * 时间倾斜分析与处理
 */
public class TimeSkewAnalysis {

    /**
     * 工作日vs周末的数据倾斜
     */
    public double getWorkdayMultiplier(Date date) {
        Calendar cal = Calendar.getInstance();
        cal.setTime(date);
        int dayOfWeek = cal.get(Calendar.DAY_OF_WEEK);

        // 工作日数据量通常是周末的2-3倍
        if (dayOfWeek >= Calendar.MONDAY && dayOfWeek <= Calendar.FRIDAY) {
            return 2.5; // 工作日倍数
        } else {
            return 1.0; // 周末基准
        }
    }

    /**
     * 一天内不同时段的数据倾斜
     */
    public double getHourlyMultiplier(int hour) {
        // 9-11点和14-17点是高峰期
        if ((hour >= 9 && hour <= 11) || (hour >= 14 && hour <= 17)) {
            return 3.0;
        }
        // 21-23点是次高峰期
        else if (hour >= 21 && hour <= 23) {
            return 2.0;
        }
        // 凌晨时段数据量最少
        else if (hour >= 1 && hour <= 6) {
            return 0.2;
        }
        else {
            return 1.0;
        }
    }

    /**
     * 节假日的数据倾斜
     */
    public double getHolidayMultiplier(Date date) {
        if (isShoppingFestival(date)) {
            return 10.0; // 购物节数据量暴增
        } else if (isNationalHoliday(date)) {
            return 1.5; // 法定假日略有增长
        } else {
            return 1.0;
        }
    }

    private boolean isShoppingFestival(Date date) {
        // 检查是否为购物节（双11、618等）
        SimpleDateFormat format = new SimpleDateFormat("MMdd");
        String dateStr = format.format(date);
        return Set.of("1111", "0618", "1212").contains(dateStr);
    }

    private boolean isNationalHoliday(Date date) {
        // 检查是否为法定假日
        return false; // 简化实现
    }
}
```

#### 3.3.2 数据倾斜的具体影响

**性能层面的影响**
```java
/**
 * 数据倾斜性能影响分析
 */
public class SkewPerformanceImpact {

    public class ShardPerformanceMetrics {
        private final String shardId;
        private final long dataSize;
        private final int qps;
        private final double avgResponseTime;
        private final double cpuUsage;
        private final double memoryUsage;

        public ShardPerformanceMetrics(String shardId, long dataSize,
                int qps, double avgResponseTime, double cpuUsage, double memoryUsage) {
            this.shardId = shardId;
            this.dataSize = dataSize;
            this.qps = qps;
            this.avgResponseTime = avgResponseTime;
            this.cpuUsage = cpuUsage;
            this.memoryUsage = memoryUsage;
        }

        // getters...
        public String getShardId() { return shardId; }
        public long getDataSize() { return dataSize; }
        public int getQps() { return qps; }
        public double getAvgResponseTime() { return avgResponseTime; }
        public double getCpuUsage() { return cpuUsage; }
        public double getMemoryUsage() { return memoryUsage; }
    }

    /**
     * 计算数据倾斜对性能的影响
     */
    public SkewImpactReport analyzeSkewImpact(List<ShardPerformanceMetrics> metrics) {
        // 计算各项指标的倾斜程度
        double dataSizeSkew = calculateSkewFactor(
            metrics.stream().mapToLong(ShardPerformanceMetrics::getDataSize).boxed().collect(Collectors.toList())
        );

        double qpsSkew = calculateSkewFactor(
            metrics.stream().mapToInt(ShardPerformanceMetrics::getQps).boxed().collect(Collectors.toList())
        );

        double responseTimeSkew = calculateSkewFactor(
            metrics.stream().mapToDouble(ShardPerformanceMetrics::getAvgResponseTime).boxed().collect(Collectors.toList())
        );

        return new SkewImpactReport(dataSizeSkew, qpsSkew, responseTimeSkew);
    }

    private double calculateSkewFactor(List<? extends Number> values) {
        if (values.isEmpty()) return 0;

        double sum = values.stream().mapToDouble(Number::doubleValue).sum();
        double avg = sum / values.size();
        double max = values.stream().mapToDouble(Number::doubleValue).max().orElse(0);

        return max / avg; // 倾斜因子：最大值与平均值的比率
    }

    public static class SkewImpactReport {
        private final double dataSizeSkew;
        private final double qpsSkew;
        private final double responseTimeSkew;

        public SkewImpactReport(double dataSizeSkew, double qpsSkew, double responseTimeSkew) {
            this.dataSizeSkew = dataSizeSkew;
            this.qpsSkew = qpsSkew;
            this.responseTimeSkew = responseTimeSkew;
        }

        public String generateReport() {
            StringBuilder report = new StringBuilder();
            report.append("=== 数据倾斜影响报告 ===\n");
            report.append(String.format("数据量倾斜因子: %.2f\n", dataSizeSkew));
            report.append(String.format("QPS倾斜因子: %.2f\n", qpsSkew));
            report.append(String.format("响应时间倾斜因子: %.2f\n", responseTimeSkew));

            // 影响等级评估
            String impactLevel = getImpactLevel(Math.max(Math.max(dataSizeSkew, qpsSkew), responseTimeSkew));
            report.append(String.format("整体影响等级: %s\n", impactLevel));

            return report.toString();
        }

        private String getImpactLevel(double maxSkew) {
            if (maxSkew > 5.0) return "严重";
            else if (maxSkew > 3.0) return "中等";
            else if (maxSkew > 2.0) return "轻微";
            else return "正常";
        }
    }
}
```

**业务层面的影响**
1. **用户体验不一致**：部分用户响应快，部分用户响应慢
2. **资源利用率低**：部分服务器空闲，部分服务器过载
3. **扩容成本高**：热点分片需要单独扩容，资源浪费
4. **运维复杂度增加**：需要针对不同分片制定不同的运维策略
5. **系统稳定性风险**：热点分片容易成为系统故障点

## 4. 数据倾斜的预防策略

### 4.1 分片键设计优化策略

#### 4.1.1 复合分片键设计

**多维度组合分片键**
```java
/**
 * 复合分片键策略实现
 */
public class CompositeShardingKey {

    /**
     * 用户ID + 时间戳组合分片
     */
    public static class UserTimeComposite {

        public String getShardKey(Long userId, Date timestamp) {
            // 时间维度：按天分桶
            long dayBucket = timestamp.getTime() / (24 * 3600 * 1000L);

            // 组合键：用户维度 + 时间维度
            String combinedKey = userId + "_" + dayBucket;

            // 使用一致性哈希确保分布均匀
            return "shard_" + (Math.abs(combinedKey.hashCode()) % 16);
        }

        /**
         * 支持用户维度查询的路由
         */
        public Set<String> getShardsForUser(Long userId, Date startDate, Date endDate) {
            Set<String> shards = new HashSet<>();

            long startDay = startDate.getTime() / (24 * 3600 * 1000L);
            long endDay = endDate.getTime() / (24 * 3600 * 1000L);

            for (long day = startDay; day <= endDay; day++) {
                String combinedKey = userId + "_" + day;
                String shard = "shard_" + (Math.abs(combinedKey.hashCode()) % 16);
                shards.add(shard);
            }

            return shards;
        }
    }

    /**
     * 业务类型 + 地理位置组合分片
     */
    public static class BusinessGeoComposite {

        public String getShardKey(String businessType, String region, String subKey) {
            // 业务类型权重
            int businessWeight = getBusinessWeight(businessType);

            // 地理位置编码
            int regionCode = getRegionCode(region);

            // 子键哈希
            int subKeyHash = Math.abs(subKey.hashCode());

            // 复合计算
            int compositeHash = (businessWeight * 1000 + regionCode * 100 + subKeyHash) % 64;

            return String.format("shard_%s_%s_%02d", businessType, region, compositeHash % 8);
        }

        private int getBusinessWeight(String businessType) {
            // 根据业务类型分配权重
            Map<String, Integer> weights = Map.of(
                "order", 10,
                "payment", 20,
                "logistics", 15,
                "user", 5
            );
            return weights.getOrDefault(businessType, 1);
        }

        private int getRegionCode(String region) {
            // 地理位置编码
            Map<String, Integer> codes = Map.of(
                "north", 1,
                "south", 2,
                "east", 3,
                "west", 4
            );
            return codes.getOrDefault(region, 0);
        }
    }
}
```

#### 4.1.2 加盐算法优化

**动态加盐策略**
```java
/**
 * 动态加盐分片算法
 */
public class DynamicSaltingSharding {
    private final int baseShardCount;
    private final int saltCount;
    private final Map<String, Integer> hotKeyDetector;

    public DynamicSaltingSharding(int baseShardCount, int saltCount) {
        this.baseShardCount = baseShardCount;
        this.saltCount = saltCount;
        this.hotKeyDetector = new ConcurrentHashMap<>();
    }

    /**
     * 基础加盐分片
     */
    public String getSaltedShardKey(String key) {
        // 为key加盐
        int salt = Math.abs(key.hashCode()) % saltCount;
        String saltedKey = key + "_salt_" + salt;

        // 计算分片
        int shardIndex = Math.abs(saltedKey.hashCode()) % baseShardCount;
        return "shard_" + String.format("%02d", shardIndex);
    }

    /**
     * 热点key检测和特殊处理
     */
    public String getShardKeyWithHotspotHandling(String key) {
        // 记录key的访问频率
        hotKeyDetector.merge(key, 1, Integer::sum);

        // 检查是否为热点key
        if (isHotKey(key)) {
            return getHotKeyShardStrategy(key);
        } else {
            return getSaltedShardKey(key);
        }
    }

    /**
     * 热点key专用分片策略
     */
    private String getHotKeyShardStrategy(String key) {
        // 热点key使用更多的盐值，进一步分散
        int hotSaltCount = saltCount * 4; // 热点key使用4倍的盐值
        int salt = Math.abs(key.hashCode()) % hotSaltCount;
        String saltedKey = key + "_hot_salt_" + salt;

        // 热点分片使用专门的分片池
        int shardIndex = Math.abs(saltedKey.hashCode()) % (baseShardCount / 2);
        return "hot_shard_" + String.format("%02d", shardIndex);
    }

    private boolean isHotKey(String key) {
        Integer accessCount = hotKeyDetector.get(key);
        return accessCount != null && accessCount > 1000; // 阈值可配置
    }

    /**
     * 读取时的分片路由
     */
    public Set<String> getAllPossibleShards(String key) {
        Set<String> shards = new HashSet<>();

        // 普通分片的所有可能位置
        for (int salt = 0; salt < saltCount; salt++) {
            String saltedKey = key + "_salt_" + salt;
            int shardIndex = Math.abs(saltedKey.hashCode()) % baseShardCount;
            shards.add("shard_" + String.format("%02d", shardIndex));
        }

        // 如果可能是热点key，还要检查热点分片
        if (isHotKey(key)) {
            int hotSaltCount = saltCount * 4;
            for (int salt = 0; salt < hotSaltCount; salt++) {
                String saltedKey = key + "_hot_salt_" + salt;
                int shardIndex = Math.abs(saltedKey.hashCode()) % (baseShardCount / 2);
                shards.add("hot_shard_" + String.format("%02d", shardIndex));
            }
        }

        return shards;
    }
}
```

#### 4.1.3 自适应分片键策略

```java
/**
 * 自适应分片键选择策略
 */
public class AdaptiveShardingStrategy {
    private final Map<String, ShardingMetrics> shardMetrics;
    private final AtomicReference<ShardingAlgorithm> currentAlgorithm;

    public AdaptiveShardingStrategy() {
        this.shardMetrics = new ConcurrentHashMap<>();
        this.currentAlgorithm = new AtomicReference<>(new ModuloSharding(16));
    }

    /**
     * 根据实时负载选择分片策略
     */
    public String getAdaptiveShardKey(String key, Map<String, Object> context) {
        ShardingAlgorithm algorithm = currentAlgorithm.get();

        // 获取当前系统负载状况
        SystemLoadMetrics loadMetrics = getCurrentSystemLoad();

        // 根据负载情况选择合适的分片策略
        if (loadMetrics.getSkewFactor() > 3.0) {
            // 高倾斜情况，使用一致性哈希
            algorithm = new ConsistentHashingSharding();
        } else if (loadMetrics.getHotspotRatio() > 0.2) {
            // 热点较多，使用加盐策略
            algorithm = new SaltedSharding();
        } else {
            // 正常情况，使用模运算
            algorithm = new ModuloSharding(16);
        }

        // 更新当前算法
        currentAlgorithm.set(algorithm);

        return algorithm.getShardKey(key, context);
    }

    /**
     * 获取当前系统负载指标
     */
    private SystemLoadMetrics getCurrentSystemLoad() {
        // 计算当前所有分片的负载指标
        List<Double> loads = shardMetrics.values().stream()
            .mapToDouble(ShardingMetrics::getLoad)
            .boxed()
            .collect(Collectors.toList());

        double avgLoad = loads.stream().mapToDouble(Double::doubleValue).average().orElse(0);
        double maxLoad = loads.stream().mapToDouble(Double::doubleValue).max().orElse(0);
        double skewFactor = maxLoad / avgLoad;

        // 计算热点比例
        long hotspotCount = shardMetrics.values().stream()
            .mapToLong(metrics -> metrics.getLoad() > avgLoad * 2 ? 1 : 0)
            .sum();
        double hotspotRatio = (double) hotspotCount / shardMetrics.size();

        return new SystemLoadMetrics(skewFactor, hotspotRatio, avgLoad, maxLoad);
    }

    // 分片算法接口
    public interface ShardingAlgorithm {
        String getShardKey(String key, Map<String, Object> context);
    }

    // 具体算法实现
    public static class ModuloSharding implements ShardingAlgorithm {
        private final int shardCount;

        public ModuloSharding(int shardCount) {
            this.shardCount = shardCount;
        }

        @Override
        public String getShardKey(String key, Map<String, Object> context) {
            return "shard_" + (Math.abs(key.hashCode()) % shardCount);
        }
    }

    public static class ConsistentHashingSharding implements ShardingAlgorithm {
        @Override
        public String getShardKey(String key, Map<String, Object> context) {
            // 一致性哈希实现
            return "consistent_shard_" + (Math.abs(key.hashCode()) % 16);
        }
    }

    public static class SaltedSharding implements ShardingAlgorithm {
        @Override
        public String getShardKey(String key, Map<String, Object> context) {
            int salt = Math.abs(key.hashCode()) % 8;
            String saltedKey = key + "_" + salt;
            return "salted_shard_" + (Math.abs(saltedKey.hashCode()) % 16);
        }
    }

    // 系统负载指标
    public static class SystemLoadMetrics {
        private final double skewFactor;
        private final double hotspotRatio;
        private final double avgLoad;
        private final double maxLoad;

        public SystemLoadMetrics(double skewFactor, double hotspotRatio, double avgLoad, double maxLoad) {
            this.skewFactor = skewFactor;
            this.hotspotRatio = hotspotRatio;
            this.avgLoad = avgLoad;
            this.maxLoad = maxLoad;
        }

        // getters
        public double getSkewFactor() { return skewFactor; }
        public double getHotspotRatio() { return hotspotRatio; }
        public double getAvgLoad() { return avgLoad; }
        public double getMaxLoad() { return maxLoad; }
    }

    // 分片指标
    public static class ShardingMetrics {
        private final String shardId;
        private final double load;
        private final long dataCount;
        private final double qps;

        public ShardingMetrics(String shardId, double load, long dataCount, double qps) {
            this.shardId = shardId;
            this.load = load;
            this.dataCount = dataCount;
            this.qps = qps;
        }

        // getters
        public String getShardId() { return shardId; }
        public double getLoad() { return load; }
        public long getDataCount() { return dataCount; }
        public double getQps() { return qps; }
    }
}

### 4.2 高级分片算法优化

#### 4.2.1 加权轮询算法

**基于负载的动态权重调整**
```java
/**
 * 加权轮询分片算法
 */
public class WeightedRoundRobinSharding {
    private final List<ShardNode> shardNodes;
    private final AtomicInteger currentIndex;
    private final Map<String, Integer> currentWeights;

    public WeightedRoundRobinSharding(Map<String, Integer> shardWeights) {
        this.shardNodes = new ArrayList<>();
        this.currentIndex = new AtomicInteger(0);
        this.currentWeights = new ConcurrentHashMap<>();

        // 初始化分片节点
        shardWeights.forEach((shardId, weight) -> {
            shardNodes.add(new ShardNode(shardId, weight));
            currentWeights.put(shardId, 0);
        });
    }

    /**
     * 基于权重的分片选择
     */
    public String getWeightedShard() {
        if (shardNodes.isEmpty()) {
            return "default_shard";
        }

        synchronized (this) {
            int totalWeight = shardNodes.stream().mapToInt(ShardNode::getWeight).sum();

            // 更新当前权重
            for (ShardNode node : shardNodes) {
                String shardId = node.getShardId();
                int currentWeight = currentWeights.get(shardId) + node.getWeight();
                currentWeights.put(shardId, currentWeight);
            }

            // 找到权重最大的分片
            String selectedShard = currentWeights.entrySet().stream()
                .max(Map.Entry.comparingByValue())
                .map(Map.Entry::getKey)
                .orElse("default_shard");

            // 减去总权重
            currentWeights.put(selectedShard, currentWeights.get(selectedShard) - totalWeight);

            return selectedShard;
        }
    }

    /**
     * 动态调整分片权重
     */
    public void adjustShardWeight(String shardId, int newWeight) {
        shardNodes.stream()
            .filter(node -> node.getShardId().equals(shardId))
            .findFirst()
            .ifPresent(node -> node.setWeight(newWeight));
    }

    /**
     * 基于实时负载自动调整权重
     */
    public void autoAdjustWeights() {
        for (ShardNode node : shardNodes) {
            ShardLoadMetrics metrics = getShardLoadMetrics(node.getShardId());

            // 根据负载情况调整权重
            int adjustedWeight = calculateAdjustedWeight(node.getWeight(), metrics);
            node.setWeight(adjustedWeight);
        }
    }

    private int calculateAdjustedWeight(int originalWeight, ShardLoadMetrics metrics) {
        double loadFactor = metrics.getCpuUsage() * 0.4 +
                           metrics.getMemoryUsage() * 0.3 +
                           metrics.getIoWait() * 0.3;

        // 负载高的分片降低权重，负载低的分片提高权重
        if (loadFactor > 0.8) {
            return Math.max(1, originalWeight / 2);
        } else if (loadFactor < 0.3) {
            return originalWeight * 2;
        } else {
            return originalWeight;
        }
    }

    private ShardLoadMetrics getShardLoadMetrics(String shardId) {
        // 从监控系统获取分片负载指标
        return new ShardLoadMetrics(0.5, 0.6, 0.2); // 示例数据
    }

    // 分片节点类
    public static class ShardNode {
        private final String shardId;
        private volatile int weight;

        public ShardNode(String shardId, int weight) {
            this.shardId = shardId;
            this.weight = weight;
        }

        // getters and setters
        public String getShardId() { return shardId; }
        public int getWeight() { return weight; }
        public void setWeight(int weight) { this.weight = weight; }
    }

    // 分片负载指标
    public static class ShardLoadMetrics {
        private final double cpuUsage;
        private final double memoryUsage;
        private final double ioWait;

        public ShardLoadMetrics(double cpuUsage, double memoryUsage, double ioWait) {
            this.cpuUsage = cpuUsage;
            this.memoryUsage = memoryUsage;
            this.ioWait = ioWait;
        }

        // getters
        public double getCpuUsage() { return cpuUsage; }
        public double getMemoryUsage() { return memoryUsage; }
        public double getIoWait() { return ioWait; }
    }
}
```

#### 4.2.2 动态负载均衡分片

**实时负载感知的分片路由**
```java
/**
 * 动态负载均衡分片算法
 */
public class DynamicLoadBalancingSharding {
    private final Map<String, ShardLoadInfo> shardLoads;
    private final Map<String, String> keyToShardMapping;
    private final ScheduledExecutorService loadMonitor;
    private final LoadBalancingStrategy strategy;

    public DynamicLoadBalancingSharding(LoadBalancingStrategy strategy) {
        this.shardLoads = new ConcurrentHashMap<>();
        this.keyToShardMapping = new ConcurrentHashMap<>();
        this.strategy = strategy;
        this.loadMonitor = Executors.newScheduledThreadPool(1);

        // 启动负载监控
        startLoadMonitoring();
    }

    /**
     * 根据实时负载选择分片
     */
    public String routeRequest(String key) {
        // 检查是否已有映射
        String existingShard = keyToShardMapping.get(key);
        if (existingShard != null && isShardHealthy(existingShard)) {
            return existingShard;
        }

        // 选择负载最低的健康分片
        String selectedShard = strategy.selectShard(shardLoads);

        // 更新映射关系
        keyToShardMapping.put(key, selectedShard);

        // 更新分片负载
        updateShardLoad(selectedShard, 1);

        return selectedShard;
    }

    /**
     * 启动负载监控
     */
    private void startLoadMonitoring() {
        loadMonitor.scheduleAtFixedRate(() -> {
            // 更新所有分片的负载信息
            updateAllShardLoads();

            // 检查是否需要重新平衡
            if (needRebalancing()) {
                performRebalancing();
            }
        }, 0, 30, TimeUnit.SECONDS);
    }

    /**
     * 更新所有分片负载
     */
    private void updateAllShardLoads() {
        for (String shardId : getAllShardIds()) {
            ShardLoadInfo loadInfo = collectShardLoadInfo(shardId);
            shardLoads.put(shardId, loadInfo);
        }
    }

    /**
     * 判断是否需要重新平衡
     */
    private boolean needRebalancing() {
        if (shardLoads.size() < 2) return false;

        List<Double> loads = shardLoads.values().stream()
            .mapToDouble(ShardLoadInfo::getTotalLoad)
            .sorted()
            .boxed()
            .collect(Collectors.toList());

        double minLoad = loads.get(0);
        double maxLoad = loads.get(loads.size() - 1);

        // 如果最大负载是最小负载的3倍以上，则需要重新平衡
        return maxLoad > minLoad * 3.0;
    }

    /**
     * 执行负载重新平衡
     */
    private void performRebalancing() {
        System.out.println("Starting load rebalancing...");

        // 找出过载的分片和空闲的分片
        List<String> overloadedShards = findOverloadedShards();
        List<String> underloadedShards = findUnderloadedShards();

        // 制定迁移计划
        List<MigrationPlan> plans = createMigrationPlans(overloadedShards, underloadedShards);

        // 执行迁移
        executeMigrationPlans(plans);
    }

    private List<String> findOverloadedShards() {
        double avgLoad = shardLoads.values().stream()
            .mapToDouble(ShardLoadInfo::getTotalLoad)
            .average().orElse(0);

        return shardLoads.entrySet().stream()
            .filter(entry -> entry.getValue().getTotalLoad() > avgLoad * 1.5)
            .map(Map.Entry::getKey)
            .collect(Collectors.toList());
    }

    private List<String> findUnderloadedShards() {
        double avgLoad = shardLoads.values().stream()
            .mapToDouble(ShardLoadInfo::getTotalLoad)
            .average().orElse(0);

        return shardLoads.entrySet().stream()
            .filter(entry -> entry.getValue().getTotalLoad() < avgLoad * 0.7)
            .map(Map.Entry::getKey)
            .collect(Collectors.toList());
    }

    private List<MigrationPlan> createMigrationPlans(List<String> overloaded, List<String> underloaded) {
        List<MigrationPlan> plans = new ArrayList<>();

        for (String fromShard : overloaded) {
            for (String toShard : underloaded) {
                // 计算需要迁移的数据量
                int migrateCount = calculateMigrationCount(fromShard, toShard);
                if (migrateCount > 0) {
                    plans.add(new MigrationPlan(fromShard, toShard, migrateCount));
                }
            }
        }

        return plans;
    }

    private void executeMigrationPlans(List<MigrationPlan> plans) {
        for (MigrationPlan plan : plans) {
            // 执行异步数据迁移
            CompletableFuture.runAsync(() -> {
                migrateData(plan.getFromShard(), plan.getToShard(), plan.getDataCount());
            });
        }
    }

    // 辅助方法实现...
    private boolean isShardHealthy(String shardId) {
        ShardLoadInfo load = shardLoads.get(shardId);
        return load != null && load.getTotalLoad() < 0.9;
    }

    private void updateShardLoad(String shardId, int increment) {
        shardLoads.computeIfPresent(shardId, (id, load) -> {
            load.incrementLoad(increment);
            return load;
        });
    }

    private Set<String> getAllShardIds() {
        return Set.of("shard_01", "shard_02", "shard_03", "shard_04"); // 示例
    }

    private ShardLoadInfo collectShardLoadInfo(String shardId) {
        // 从监控系统获取分片负载信息
        return new ShardLoadInfo(0.5, 1000, 50); // 示例数据
    }

    private int calculateMigrationCount(String fromShard, String toShard) {
        ShardLoadInfo fromLoad = shardLoads.get(fromShard);
        ShardLoadInfo toLoad = shardLoads.get(toShard);

        if (fromLoad == null || toLoad == null) return 0;

        // 计算需要迁移的数据量以达到负载平衡
        double loadDiff = fromLoad.getTotalLoad() - toLoad.getTotalLoad();
        return (int) (loadDiff * fromLoad.getDataCount() / fromLoad.getTotalLoad() / 4);
    }

    private void migrateData(String fromShard, String toShard, int dataCount) {
        System.out.println(String.format(
            "Migrating %d records from %s to %s", dataCount, fromShard, toShard));
        // 实现实际的数据迁移逻辑
    }

    // 负载均衡策略接口
    public interface LoadBalancingStrategy {
        String selectShard(Map<String, ShardLoadInfo> shardLoads);
    }

    // 最小负载策略
    public static class MinLoadStrategy implements LoadBalancingStrategy {
        @Override
        public String selectShard(Map<String, ShardLoadInfo> shardLoads) {
            return shardLoads.entrySet().stream()
                .min(Map.Entry.comparingByValue(
                    Comparator.comparingDouble(ShardLoadInfo::getTotalLoad)))
                .map(Map.Entry::getKey)
                .orElse("default_shard");
        }
    }

    // 分片负载信息
    public static class ShardLoadInfo {
        private volatile double totalLoad;
        private volatile long dataCount;
        private volatile double qps;

        public ShardLoadInfo(double totalLoad, long dataCount, double qps) {
            this.totalLoad = totalLoad;
            this.dataCount = dataCount;
            this.qps = qps;
        }

        public void incrementLoad(int increment) {
            this.totalLoad += increment * 0.01; // 示例增量计算
        }

        // getters
        public double getTotalLoad() { return totalLoad; }
        public long getDataCount() { return dataCount; }
        public double getQps() { return qps; }
    }

    // 迁移计划
    public static class MigrationPlan {
        private final String fromShard;
        private final String toShard;
        private final int dataCount;

        public MigrationPlan(String fromShard, String toShard, int dataCount) {
            this.fromShard = fromShard;
            this.toShard = toShard;
            this.dataCount = dataCount;
        }

        // getters
        public String getFromShard() { return fromShard; }
        public String getToShard() { return toShard; }
        public int getDataCount() { return dataCount; }
    }
}
```

### 4.3 预分片策略

```sql
-- 预分片：提前创建足够多的分片
-- 避免后续扩容时的数据迁移
CREATE TABLE user_0001 (id BIGINT, name VARCHAR(50), ...);
CREATE TABLE user_0002 (id BIGINT, name VARCHAR(50), ...);
...
CREATE TABLE user_1024 (id BIGINT, name VARCHAR(50), ...);
```

## 5. 数据倾斜的监控方案

### 5.1 监控指标设计

#### 5.1.1 基础指标
```python
# 关键监控指标
class ShardingMetrics:
    def __init__(self):
        self.metrics = {
            'shard_row_count': {},      # 各分片数据量
            'shard_data_size': {},      # 各分片数据大小
            'shard_qps': {},            # 各分片QPS
            'shard_response_time': {},  # 各分片响应时间
            'shard_cpu_usage': {},      # 各分片CPU使用率
            'shard_memory_usage': {},   # 各分片内存使用率
            'shard_io_wait': {}         # 各分片IO等待时间
        }

    def calculate_skew_factor(self, values):
        """计算倾斜因子"""
        if not values:
            return 0

        avg_value = sum(values) / len(values)
        max_value = max(values)
        return max_value / avg_value if avg_value > 0 else 0
```

#### 5.1.2 倾斜检测算法
```python
class SkewDetector:
    def __init__(self, threshold=2.0):
        self.threshold = threshold  # 倾斜阈值

    def detect_data_skew(self, shard_metrics):
        """检测数据倾斜"""
        alerts = []

        # 检测数据量倾斜
        row_counts = list(shard_metrics['shard_row_count'].values())
        if self.calculate_skew_factor(row_counts) > self.threshold:
            alerts.append({
                'type': 'DATA_SKEW',
                'severity': 'HIGH',
                'message': f'数据量倾斜超过阈值: {self.threshold}'
            })

        # 检测访问倾斜
        qps_values = list(shard_metrics['shard_qps'].values())
        if self.calculate_skew_factor(qps_values) > self.threshold:
            alerts.append({
                'type': 'ACCESS_SKEW',
                'severity': 'HIGH',
                'message': f'访问倾斜超过阈值: {self.threshold}'
            })

        return alerts
```

### 5.2 监控系统架构

#### 5.2.1 数据采集层
```python
class MetricsCollector:
    def collect_database_metrics(self, shard_configs):
        """采集数据库指标"""
        metrics = {}

        for shard_id, config in shard_configs.items():
            conn = connect_to_database(config)

            # 采集数据量指标
            row_count = self.get_table_row_count(conn)
            data_size = self.get_table_data_size(conn)

            # 采集性能指标
            qps = self.get_queries_per_second(conn)
            avg_response_time = self.get_avg_response_time(conn)

            metrics[shard_id] = {
                'row_count': row_count,
                'data_size': data_size,
                'qps': qps,
                'response_time': avg_response_time,
                'timestamp': time.time()
            }

        return metrics
```

#### 5.2.2 实时预警系统
```python
class AlertManager:
    def __init__(self):
        self.alert_rules = [
            {
                'name': 'high_data_skew',
                'condition': lambda metrics: self.check_data_skew(metrics) > 3.0,
                'action': 'send_alert',
                'severity': 'CRITICAL'
            },
            {
                'name': 'moderate_access_skew',
                'condition': lambda metrics: self.check_access_skew(metrics) > 2.0,
                'action': 'send_warning',
                'severity': 'WARNING'
            }
        ]

    def process_alerts(self, metrics):
        """处理告警"""
        for rule in self.alert_rules:
            if rule['condition'](metrics):
                self.trigger_alert(rule, metrics)
```

### 5.3 可视化监控面板

```python
# Grafana Dashboard 配置示例
dashboard_config = {
    "dashboard": {
        "title": "分库分表监控面板",
        "panels": [
            {
                "title": "各分片数据量分布",
                "type": "graph",
                "targets": [
                    {
                        "expr": "shard_row_count",
                        "legendFormat": "Shard {{shard_id}}"
                    }
                ]
            },
            {
                "title": "分片负载热力图",
                "type": "heatmap",
                "targets": [
                    {
                        "expr": "shard_qps",
                        "format": "time_series"
                    }
                ]
            },
            {
                "title": "数据倾斜因子趋势",
                "type": "stat",
                "targets": [
                    {
                        "expr": "data_skew_factor",
                        "legendFormat": "倾斜因子"
                    }
                ]
            }
        ]
    }
}
```

## 6. 数据倾斜的处理方案

### 6.1 热点数据识别

#### 6.1.1 热点检测算法
```python
class HotspotDetector:
    def __init__(self, window_size=300, threshold=0.8):
        self.window_size = window_size  # 时间窗口（秒）
        self.threshold = threshold      # 热点阈值
        self.access_log = []

    def detect_hotspots(self, access_logs):
        """检测热点数据"""
        current_time = time.time()

        # 统计时间窗口内的访问频率
        recent_logs = [
            log for log in access_logs
            if current_time - log['timestamp'] <= self.window_size
        ]

        # 按分片键统计访问次数
        access_count = {}
        for log in recent_logs:
            key = log['shard_key']
            access_count[key] = access_count.get(key, 0) + 1

        # 计算热点
        total_access = sum(access_count.values())
        hotspots = []

        for key, count in access_count.items():
            access_ratio = count / total_access if total_access > 0 else 0
            if access_ratio > self.threshold / len(access_count):
                hotspots.append({
                    'key': key,
                    'access_count': count,
                    'access_ratio': access_ratio
                })

        return hotspots
```

### 6.2 数据重新分布

#### 6.2.1 在线数据迁移
```python
class OnlineDataMigration:
    def __init__(self, source_shard, target_shards):
        self.source_shard = source_shard
        self.target_shards = target_shards
        self.migration_status = {}

    def migrate_data_gradually(self, batch_size=1000):
        """渐进式数据迁移"""
        # 1. 创建迁移任务
        migration_tasks = self.create_migration_tasks(batch_size)

        for task in migration_tasks:
            try:
                # 2. 读取源数据
                source_data = self.read_source_data(task)

                # 3. 写入目标分片
                target_shard = self.calculate_target_shard(source_data)
                self.write_target_data(target_shard, source_data)

                # 4. 验证数据一致性
                if self.verify_data_consistency(source_data, target_shard):
                    # 5. 删除源数据
                    self.delete_source_data(task)
                    self.update_migration_progress(task, 'COMPLETED')
                else:
                    self.update_migration_progress(task, 'FAILED')

            except Exception as e:
                self.handle_migration_error(task, e)
                self.update_migration_progress(task, 'FAILED')

    def create_migration_tasks(self, batch_size):
        """创建迁移任务"""
        # 根据主键范围创建迁移批次
        min_id, max_id = self.get_id_range()
        tasks = []

        for start_id in range(min_id, max_id + 1, batch_size):
            end_id = min(start_id + batch_size - 1, max_id)
            tasks.append({
                'start_id': start_id,
                'end_id': end_id,
                'status': 'PENDING'
            })

        return tasks
```

#### 6.2.2 双写策略
```python
class DualWriteStrategy:
    def __init__(self, old_sharding, new_sharding):
        self.old_sharding = old_sharding
        self.new_sharding = new_sharding
        self.migration_ratio = 0.0  # 迁移进度

    def write_data(self, data):
        """双写策略"""
        results = {}

        # 写入旧分片
        old_shard = self.old_sharding.get_shard(data['key'])
        results['old_shard'] = self.write_to_shard(old_shard, data)

        # 根据迁移进度决定是否写入新分片
        if random.random() < self.migration_ratio:
            new_shard = self.new_sharding.get_shard(data['key'])
            results['new_shard'] = self.write_to_shard(new_shard, data)

        return results

    def read_data(self, key):
        """读取数据（优先从新分片读取）"""
        # 先尝试从新分片读取
        if random.random() < self.migration_ratio:
            new_shard = self.new_sharding.get_shard(key)
            data = self.read_from_shard(new_shard, key)
            if data:
                return data

        # 从旧分片读取
        old_shard = self.old_sharding.get_shard(key)
        return self.read_from_shard(old_shard, key)
```

### 6.3 热点数据处理

#### 6.3.1 热点数据缓存
```python
class HotDataCache:
    def __init__(self, cache_size=10000, ttl=3600):
        self.cache = {}
        self.cache_size = cache_size
        self.ttl = ttl
        self.access_count = {}
        self.last_access = {}

    def get(self, key):
        """获取缓存数据"""
        current_time = time.time()

        # 检查缓存是否过期
        if key in self.cache:
            if current_time - self.last_access.get(key, 0) < self.ttl:
                self.access_count[key] = self.access_count.get(key, 0) + 1
                self.last_access[key] = current_time
                return self.cache[key]
            else:
                # 过期删除
                self.remove(key)

        return None

    def put(self, key, value):
        """添加缓存数据"""
        # 检查缓存容量
        if len(self.cache) >= self.cache_size:
            self.evict_least_recently_used()

        current_time = time.time()
        self.cache[key] = value
        self.access_count[key] = 1
        self.last_access[key] = current_time

    def evict_least_recently_used(self):
        """LRU淘汰策略"""
        if not self.last_access:
            return

        # 找到最久未访问的key
        lru_key = min(self.last_access.items(), key=lambda x: x[1])[0]
        self.remove(lru_key)
```

#### 6.3.2 热点数据分离
```python
class HotDataSeparation:
    def __init__(self, hot_threshold=1000):
        self.hot_threshold = hot_threshold
        self.hot_data_store = {}  # 热点数据单独存储
        self.normal_data_store = {}  # 普通数据正常分片

    def route_data(self, key, access_count):
        """根据访问频率路由数据"""
        if access_count > self.hot_threshold:
            # 热点数据存储到专门的热点分片
            return self.get_hot_data_shard(key)
        else:
            # 普通数据正常分片
            return self.get_normal_shard(key)

    def get_hot_data_shard(self, key):
        """获取热点数据分片"""
        # 热点数据可以使用多副本、SSD存储等优化
        return f"hot_shard_{hash(key) % 4}"  # 4个热点分片

    def get_normal_shard(self, key):
        """获取普通数据分片"""
        return f"normal_shard_{hash(key) % 16}"  # 16个普通分片
```

### 6.4 分片重新平衡

#### 6.4.1 自动重平衡算法
```python
class AutoRebalancer:
    def __init__(self, imbalance_threshold=0.3):
        self.imbalance_threshold = imbalance_threshold

    def check_and_rebalance(self, shard_metrics):
        """检查并执行重平衡"""
        imbalance_factor = self.calculate_imbalance(shard_metrics)

        if imbalance_factor > self.imbalance_threshold:
            rebalance_plan = self.create_rebalance_plan(shard_metrics)
            self.execute_rebalance(rebalance_plan)

    def calculate_imbalance(self, shard_metrics):
        """计算不平衡因子"""
        loads = [metrics['load'] for metrics in shard_metrics.values()]
        if not loads:
            return 0

        avg_load = sum(loads) / len(loads)
        max_deviation = max(abs(load - avg_load) for load in loads)

        return max_deviation / avg_load if avg_load > 0 else 0

    def create_rebalance_plan(self, shard_metrics):
        """创建重平衡计划"""
        # 找出负载过高和过低的分片
        avg_load = sum(m['load'] for m in shard_metrics.values()) / len(shard_metrics)

        overloaded_shards = [
            (shard_id, metrics) for shard_id, metrics in shard_metrics.items()
            if metrics['load'] > avg_load * (1 + self.imbalance_threshold)
        ]

        underloaded_shards = [
            (shard_id, metrics) for shard_id, metrics in shard_metrics.items()
            if metrics['load'] < avg_load * (1 - self.imbalance_threshold)
        ]

        # 生成数据迁移计划
        migration_plan = []
        for overloaded_shard, _ in overloaded_shards:
            for underloaded_shard, _ in underloaded_shards:
                migration_plan.append({
                    'from_shard': overloaded_shard,
                    'to_shard': underloaded_shard,
                    'data_amount': self.calculate_migration_amount(
                        shard_metrics[overloaded_shard],
                        shard_metrics[underloaded_shard]
                    )
                })

        return migration_plan
```

## 7. 最佳实践与注意事项

### 7.1 设计阶段最佳实践

1. **充分的容量规划**
   - 预估3-5年的数据增长量
   - 考虑业务峰值场景的数据分布
   - 预留足够的扩容空间

2. **合理的分片键选择**
   - 选择区分度高的字段作为分片键
   - 避免使用会产生热点的字段
   - 考虑业务查询模式

3. **分片数量规划**
   - 初始分片数应为2的幂次，便于扩容
   - 单分片数据量控制在合理范围内
   - 考虑硬件资源的限制

### 7.2 运维阶段注意事项

1. **监控告警**
   - 建立完善的监控体系
   - 设置合理的告警阈值
   - 定期分析数据分布情况

2. **性能优化**
   - 定期分析慢查询
   - 优化索引策略
   - 调整分片间的负载均衡

3. **数据一致性**
   - 确保分布式事务的一致性
   - 处理跨分片查询的复杂性
   - 建立数据校验机制

### 7.3 故障处理

1. **分片故障**
   - 建立主从复制机制
   - 准备快速故障切换方案
   - 定期备份关键数据

2. **数据倾斜处理**
   - 快速识别和定位热点
   - 制定数据迁移计划
   - 最小化对业务的影响

3. **扩容策略**
   - 制定详细的扩容方案
   - 测试数据迁移流程
   - 准备回滚机制

通过以上的分库分表方案和数据倾斜处理策略，可以有效应对大数据量场景下的数据库性能挑战，确保系统的高可用性和可扩展性。